{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e94e4e-8ca0-462a-9f41-95a2f41a944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers # requires transformers==4.35.2\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1668d6c1-d608-4f91-8741-b33693e83d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.43.3\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c100275b-9db8-432f-bbec-b88c715ac61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "draft_model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "draft_model = AutoModelForCausalLM.from_pretrained(draft_model_name, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.float16, use_flash_attention_2=True)#, load_in_4bit=True)\n",
    "print(draft_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e27a50-63e6-45c1-88c2-e43d2fa94bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2932ad4c5714e898d8bf8124d741a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.float16, use_flash_attention_2=True)#, load_in_4bit=True)#  , use_flash_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebaeb3f8-710f-4813-81f4-df9386f21790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nuprl/CanItEdit\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0929b62b-bb7d-41a8-9216-80907072ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_candidate_pred_tokens(input_ids, max_ngram_size=3, num_pred_tokens=10):\n",
    "    input_length = input_ids.size(1)\n",
    "\n",
    "    # Ensure max_ngram_size and num_pred_tokens are valid\n",
    "    if max_ngram_size <= 0 or num_pred_tokens <= 0 or max_ngram_size > input_length:\n",
    "        raise ValueError(\"Invalid max_ngram_size or num_pred_tokens\")\n",
    "\n",
    "    for ngram_size in range(max_ngram_size, 0, -1):\n",
    "        # Extract the last n tokens as our search ngram\n",
    "        ngram = input_ids[0, -ngram_size:].tolist()\n",
    "\n",
    "        # Create sliding windows of size ngram_size\n",
    "        windows = input_ids.unfold(dimension=1, size=ngram_size, step=1)\n",
    "\n",
    "        # Convert ngram to a tensor for comparison\n",
    "        ngram_tensor = torch.tensor(ngram, device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Find where the windows match the ngram\n",
    "        matches = (windows == ngram_tensor).all(dim=2)\n",
    "\n",
    "        # Get the indices of matches\n",
    "        match_indices = matches.nonzero(as_tuple=True)[1]\n",
    "\n",
    "        # Iterate through match indices to find a valid continuation\n",
    "        for idx in match_indices:\n",
    "            start_idx = idx + ngram_size\n",
    "            end_idx = start_idx + num_pred_tokens\n",
    "            # Ensure we don't go beyond the length of input_ids and avoid self-match\n",
    "            # if end_idx <= input_length and start_idx < input_length - ngram_size:\n",
    "            #     return input_ids[0, start_idx:end_idx]\n",
    "            if start_idx < input_length - ngram_size:\n",
    "                return input_ids[0, start_idx:min(end_idx, input_length)]\n",
    "\n",
    "    # If no match is found, return an empty tensor\n",
    "    return torch.tensor([100], dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_candidate_pred_tokens_diff(input_ids, code_ids, orig_input_len=0, ngram_size=3, num_pred_tokens=10):\n",
    "    # print(input_ids, code_ids)\n",
    "    \n",
    "    # start_time = time.perf_counter()\n",
    "    input_length = input_ids.size(1)\n",
    "    code_length = len(code_ids)\n",
    "\n",
    "    # Ensure max_ngram_size and num_pred_tokens are valid\n",
    "    if ngram_size <= 0 or ngram_size > input_length:\n",
    "        raise ValueError(\"Invalid max_ngram_size or num_pred_tokens\")\n",
    "\n",
    "    sm = difflib.SequenceMatcher(None, code_ids, input_ids[0, orig_input_len:].tolist())\n",
    "    \n",
    "    deleted = added = changed = same = last_deleted = 0\n",
    "    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "        if tag == 'replace':\n",
    "            changed += i2 - i1\n",
    "        elif tag == 'delete':\n",
    "            deleted += i2 - i1\n",
    "            last_deleted = i2 - i1\n",
    "        elif tag == 'insert':\n",
    "            added += j2 - j1\n",
    "        elif tag == 'equal':\n",
    "            same += i2 - i1\n",
    "    \n",
    "    approx_tokens_original = changed + deleted + same - last_deleted\n",
    "\n",
    "    lookback_start = max(input_length - ngram_size, orig_input_len)\n",
    "    search_ngram = input_ids[0, lookback_start:].tolist()\n",
    "\n",
    "    for ngram_start in range(max(0, approx_tokens_original - ngram_size), len(code_ids)):\n",
    "        # if there is a match, return the entire rest of the tokens.\n",
    "        if ngram_start + len(search_ngram) >= len(code_ids):\n",
    "            break\n",
    "        if search_ngram == code_ids[ngram_start:ngram_start + len(search_ngram)]:\n",
    "            return torch.tensor(code_ids[ngram_start + len(search_ngram):max(ngram_start + len(search_ngram) + num_pred_tokens, len(code_ids))], dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "    # If no match is found, return what the answer would be otherwise\n",
    "    # print(\"Diff searching took: \", time.perf_counter() - start_time)\n",
    "    return find_candidate_pred_tokens(input_ids, ngram_size, num_pred_tokens)\n",
    "    # return torch.tensor([], dtype=torch.long, device=input_ids.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7dfe19b-9c65-4420-856b-c3bdb3175f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.candidate_generator import CandidateGenerator, _crop_past_key_values\n",
    "from transformers.generation.stopping_criteria import StoppingCriteria\n",
    "from transformers.generation.configuration_utils import GenerationConfig\n",
    "from typing import Tuple, Optional\n",
    "import time\n",
    "\n",
    "class DiffPromptLookupCandidateGenerator(CandidateGenerator):\n",
    "    def __init__(self, input_ids, code_ids, ngram_size=3, num_pred_tokens=10):\n",
    "        self.code_ids = code_ids\n",
    "        self.orig_input_len = input_ids.shape[-1]\n",
    "        self.ngram_size = ngram_size\n",
    "        self.num_pred_tokens = num_pred_tokens\n",
    "    \n",
    "    def get_candidates(self, input_ids: torch.LongTensor) -> Tuple[torch.LongTensor, Optional[torch.FloatTensor]]:\n",
    "        # print(\"Getting candidates\")\n",
    "        return torch.cat(\n",
    "            (\n",
    "                input_ids,\n",
    "                find_candidate_pred_tokens_diff(input_ids, self.code_ids, self.orig_input_len, self.ngram_size, self.num_pred_tokens).unsqueeze(0)\n",
    "            ),\n",
    "            dim=-1\n",
    "        ), None\n",
    "    \n",
    "    def update_candidate_strategy(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, num_matches: int): # Maybe use the number of matches/scores to have a threshold\n",
    "        pass \n",
    "\n",
    "class NumRunsStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, max_num_runs=4):\n",
    "        self.max_num_runs = 4\n",
    "        self.num_runs = 0\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.BoolTensor:\n",
    "        self.num_runs += 1\n",
    "        return self.num_runs >= self.max_num_runs\n",
    "\n",
    "class NewlineStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, prompt_tokens: int, newline_count=5):\n",
    "        self.newline_token = tokenizer.encode(\"\"\"\n",
    "\"\"\")[-1]\n",
    "        self.newline_count = newline_count\n",
    "        self.prompt_tokens = prompt_tokens\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.BoolTensor:\n",
    "        considered_tokens = tokenizer.batch_decode(input_ids[:, self.prompt_tokens:])[0]\n",
    "        newline_list = \"\\n\"*self.newline_count\n",
    "        # print(newline_list, considered_tokens)\n",
    "        return newline_list in considered_tokens\n",
    "\n",
    "class ScoreStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, min_score, start_token_index):\n",
    "        self.min_score = min_score\n",
    "        self.start_token_index = start_token_index\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.BoolTensor:\n",
    "        if not(scores):\n",
    "            # print(\"No scores\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Got scores scores stopping: \", scores[0].shape, len(scores))\n",
    "        scores_tensor = torch.stack(scores, dim=0)\n",
    "        softmax_scores = F.softmax(scores_tensor, 2)\n",
    "        print(softmax_scores)\n",
    "        return (softmax_scores.max(dim=2).values < self.min_score).any().item()\n",
    "\n",
    "def _get_default_candidate_generator_generator(generator: CandidateGenerator):\n",
    "    def _get_candidate_generator(self, **kwargs):\n",
    "        return generator\n",
    "    return _get_candidate_generator\n",
    "\n",
    "class TwoLayerLookupCandidateGenerator(CandidateGenerator):\n",
    "    def __init__(self, tokenizer, prompt_tokens, draft_model, input_ids, code_ids, num_runs=4, **diff_prompt_args):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt_tokens = prompt_tokens\n",
    "        self.draft_model = draft_model\n",
    "        self.input_ids = input_ids\n",
    "        self.code_ids = code_ids\n",
    "        self.candidate_generator = DiffPromptLookupCandidateGenerator(\n",
    "            self.input_ids, \n",
    "            self.code_ids,\n",
    "            **diff_prompt_args\n",
    "        )\n",
    "        self.draft_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "        \n",
    "        self.past_key_values = None\n",
    "        self.num_runs = num_runs\n",
    "\n",
    "        self.draft_model._get_candidate_generator = (_get_default_candidate_generator_generator(self.candidate_generator)).__get__(self.draft_model, type(self.draft_model))\n",
    "\n",
    "        self.min_score = 1\n",
    "        self.start_token_index = self.input_ids.shape[-1]\n",
    "\n",
    "        self.min_score = 0\n",
    "        self.scores_count = 0\n",
    "    \n",
    "    def get_candidates(self, input_ids: torch.LongTensor) -> Tuple[torch.LongTensor, Optional[torch.FloatTensor]]:\n",
    "        if self.past_key_values:\n",
    "            self.past_key_values = _crop_past_key_values(self.draft_model, self.past_key_values, input_ids.shape[-1] - 1)\n",
    "\n",
    "        starting_input_length = input_ids.shape[-1]\n",
    "        # print(\"Getting draft candidates\")\n",
    "        \n",
    "        generation = self.draft_model.generate(\n",
    "            inputs=input_ids,\n",
    "            attention_mask=torch.ones(input_ids.shape[-1], device=input_ids.device).unsqueeze(0),\n",
    "            prompt_lookup_num_tokens=1,\n",
    "            max_new_tokens=1000,\n",
    "            stopping_criteria=[NumRunsStoppingCriteria(self.num_runs), \n",
    "                               # NewlineStoppingCriteria(self.tokenizer, self.prompt_tokens), \n",
    "                               ScoreStoppingCriteria(self.min_score, starting_input_length)\n",
    "                              ],\n",
    "            past_key_values=self.past_key_values,\n",
    "            use_cache=True,\n",
    "            # output_logits=True,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "\n",
    "        # print(\"Scores: \", generation.scores)\n",
    "\n",
    "        self.pred_tokens_count = generation.sequences.shape[-1] - input_ids.shape[-1]\n",
    "        self.past_key_values = generation.past_key_values\n",
    "        self.past_top_scores = torch.stack(generation.scores, dim=1).max(dim=1)\n",
    "\n",
    "        return generation.sequences, torch.stack(generation.scores, dim=1)\n",
    "\n",
    "    def update_candidate_strategy(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, num_matches: int):\n",
    "        if num_matches == self.pred_tokens_count:\n",
    "            if self.scores_count == 0:\n",
    "                self.min_score = 0\n",
    "            else:\n",
    "                self.min_score = (self.scores_count / self.scores_count + 1) * (self.min_score)\n",
    "        else:\n",
    "            if self.scores_count == 0:\n",
    "                self.min_score = self.past_top_scores[-num_matches]\n",
    "            else:\n",
    "                self.min_score = (self.scores_count / (self.scores_count + 1)) * (self.min_score) + (1 / (self.scores_count + 1)) * (self.past_top_scores[-1])\n",
    "        self.scores_count += 1\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a969129-dfd9-4c64-a164-6406f41c32d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                               | 0/105 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\n",
      "### Instruction:\n",
      "## Code Before:\n",
      "class CSVParser:\n",
      "    def __init__(self, csv: str):\n",
      "        self.csv = csv\n",
      "\n",
      "    def contents(self) -> list[list[str]]:\n",
      "        lines = self.csv.split(\"\\n\")\n",
      "        output = []\n",
      "        for line in lines:\n",
      "            output.append(line.split(\",\"))\n",
      "        return output\n",
      "## Change requested: Add a function called `header` which returns the first row of a csv file as a list of strings, where\n",
      "every element in the list is a column in the row.\n",
      "## Rewrite the code to incorporate the change.\n",
      "\n",
      "### Response:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.7692e-12, 3.0322e-06, 6.9014e-05,  ..., 8.2923e-18,\n",
      "          9.1073e-18, 8.5555e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 84\n",
      "tensor([[[2.7692e-12, 3.0322e-06, 6.9014e-05,  ..., 8.2923e-18,\n",
      "          9.1073e-18, 8.5555e-18]],\n",
      "\n",
      "        [[1.1250e-19, 1.6752e-11, 4.9029e-13,  ..., 4.1157e-21,\n",
      "          4.1157e-21, 4.0125e-21]],\n",
      "\n",
      "        [[1.2026e-20, 8.4183e-16, 3.8704e-14,  ..., 2.8522e-18,\n",
      "          3.0361e-18, 3.0361e-18]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.2504e-19, 8.2109e-13, 3.1971e-12,  ..., 8.3779e-22,\n",
      "          7.9320e-22, 8.7117e-22]],\n",
      "\n",
      "        [[2.8343e-21, 3.7525e-12, 1.5276e-14,  ..., 1.5084e-20,\n",
      "          1.5084e-20, 1.6310e-20]],\n",
      "\n",
      "        [[2.3817e-10, 1.1840e-08, 2.9936e-09,  ..., 6.2938e-16,\n",
      "          6.4936e-16, 6.4936e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0032e-02, 1.7732e-08, 8.9161e-09,  ..., 2.4759e-09,\n",
      "          2.6356e-09, 2.5545e-09]]], device='cuda:0')\n",
      "Sure, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4158e-10, 2.0050e-07, 2.2054e-10,  ..., 2.0780e-16,\n",
      "          2.2121e-16, 2.2121e-16]]], device='cuda:0')\n",
      "here is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.6353e-13, 3.0575e-09, 7.8973e-11,  ..., 4.1980e-18,\n",
      "          4.3313e-18, 4.6106e-18]]], device='cuda:0')\n",
      "the updated Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.9071e-10, 6.4779e-07, 2.5118e-08,  ..., 5.9249e-16,\n",
      "          6.1130e-16, 6.5072e-16]]], device='cuda:0')\n",
      "code:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.6144e-09, 7.6144e-09, 7.6903e-08,  ..., 2.0122e-14,\n",
      "          2.0761e-14, 1.9503e-14]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0022e-10, 4.5813e-08, 2.6364e-07,  ..., 1.1390e-16,\n",
      "          1.1390e-16, 1.1040e-16]]], device='cuda:0')\n",
      "\n",
      "```python\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.8555e-13, 5.9467e-09, 1.3806e-05,  ..., 9.7516e-19,\n",
      "          9.7516e-19, 9.4516e-19]]], device='cuda:0')\n",
      "class Got scores scores stopping:  torch.Size([1, 32256]) 51\n",
      "tensor([[[5.5927e-21, 1.1572e-16, 8.6362e-15,  ..., 8.5638e-19,\n",
      "          8.8357e-19, 9.1162e-19]],\n",
      "\n",
      "        [[8.8171e-20, 3.4757e-15, 1.2641e-13,  ..., 1.7913e-20,\n",
      "          2.1107e-20, 2.0618e-20]],\n",
      "\n",
      "        [[1.6968e-16, 4.0644e-13, 3.3312e-11,  ..., 5.6923e-20,\n",
      "          5.7819e-20, 5.7819e-20]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.2001e-16, 2.2193e-11, 2.5148e-11,  ..., 4.8039e-19,\n",
      "          4.6198e-19, 5.1137e-19]],\n",
      "\n",
      "        [[2.1855e-20, 2.1750e-13, 2.9729e-13,  ..., 2.1301e-22,\n",
      "          2.0525e-22, 2.2323e-22]],\n",
      "\n",
      "        [[3.6896e-17, 9.1236e-10, 4.6015e-16,  ..., 6.8642e-19,\n",
      "          6.8642e-19, 6.6012e-19]]], device='cuda:0')\n",
      "CSVParser:\n",
      "    def __init__(self, csv: str):\n",
      "        self.csv = csv\n",
      "\n",
      "    def contents(self) -> list[list[str]]:\n",
      "        lines = Got scores scores stopping:  torch.Size([1, 32256]) 30\n",
      "tensor([[[2.9445e-14, 4.7379e-07, 4.5537e-11,  ..., 1.5629e-18,\n",
      "          1.4230e-18, 1.4682e-18]],\n",
      "\n",
      "        [[4.6974e-14, 6.8924e-10, 2.2824e-08,  ..., 1.5122e-18,\n",
      "          1.5122e-18, 1.5603e-18]],\n",
      "\n",
      "        [[2.7314e-20, 2.6244e-13, 9.7360e-10,  ..., 3.5474e-22,\n",
      "          3.2809e-22, 3.5267e-22]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.1383e-20, 5.2192e-13, 4.5797e-12,  ..., 1.6792e-21,\n",
      "          1.5806e-21, 1.7427e-21]],\n",
      "\n",
      "        [[2.1731e-21, 2.5690e-12, 1.2664e-14,  ..., 1.3106e-20,\n",
      "          1.2902e-20, 1.4170e-20]],\n",
      "\n",
      "        [[9.3339e-11, 1.9343e-09, 2.1918e-09,  ..., 2.7950e-16,\n",
      "          2.8837e-16, 2.9753e-16]]], device='cuda:0')\n",
      "self.csv.split(\"\\n\")\n",
      "        output = []\n",
      "        for line in lines:\n",
      "            output.append(line.split(\",\"))\n",
      "        return output\n",
      "\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[7.6779e-15, 9.3395e-11, 3.7250e-06,  ..., 6.0573e-20,\n",
      "          5.8710e-20, 5.8710e-20]],\n",
      "\n",
      "        [[5.6209e-18, 3.1930e-12, 3.4328e-11,  ..., 7.0863e-23,\n",
      "          7.0863e-23, 7.7827e-23]],\n",
      "\n",
      "        [[1.0136e-17, 2.4241e-11, 4.8764e-13,  ..., 2.7910e-22,\n",
      "          2.7910e-22, 2.7910e-22]]], device='cuda:0')\n",
      "    def Got scores scores stopping:  torch.Size([1, 32256]) 7\n",
      "tensor([[[1.9229e-16, 3.6645e-14, 4.9519e-12,  ..., 2.2774e-21,\n",
      "          2.3497e-21, 2.3497e-21]],\n",
      "\n",
      "        [[7.7589e-13, 2.9115e-11, 1.1051e-11,  ..., 1.6998e-18,\n",
      "          1.7538e-18, 1.8094e-18]],\n",
      "\n",
      "        [[1.6777e-14, 2.2226e-14, 3.1297e-11,  ..., 1.0635e-19,\n",
      "          9.3858e-20, 1.0635e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.2475e-16, 8.0693e-10, 2.0637e-12,  ..., 1.4700e-21,\n",
      "          1.3384e-21, 1.5167e-21]],\n",
      "\n",
      "        [[2.6761e-14, 6.0217e-11, 4.6434e-12,  ..., 1.6443e-19,\n",
      "          1.6965e-19, 1.9223e-19]],\n",
      "\n",
      "        [[2.5767e-18, 8.2579e-14, 2.4899e-12,  ..., 1.2070e-22,\n",
      "          1.0989e-22, 1.2848e-22]]], device='cuda:0')\n",
      "header(self) -> Got scores scores stopping:  torch.Size([1, 32256]) 15\n",
      "tensor([[[7.5068e-14, 6.4113e-11, 6.8145e-08,  ..., 3.4816e-19,\n",
      "          3.2706e-19, 3.4816e-19]],\n",
      "\n",
      "        [[2.1321e-15, 4.2759e-11, 1.4444e-07,  ..., 1.0202e-20,\n",
      "          9.8883e-21, 1.0526e-20]],\n",
      "\n",
      "        [[3.6969e-14, 3.6858e-08, 2.9911e-07,  ..., 5.5347e-19,\n",
      "          5.2813e-19, 5.8917e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.7536e-15, 3.2685e-09, 1.1167e-07,  ..., 2.8689e-19,\n",
      "          2.6121e-19, 2.7806e-19]],\n",
      "\n",
      "        [[8.0936e-16, 9.5423e-12, 3.6524e-08,  ..., 3.0162e-21,\n",
      "          2.6618e-21, 2.9234e-21]],\n",
      "\n",
      "        [[4.0843e-15, 3.6710e-10, 3.7076e-09,  ..., 1.0081e-19,\n",
      "          9.4706e-20, 1.0081e-19]]], device='cuda:0')\n",
      "list[str]:\n",
      "        lines = self.csv.split(\"\\n\")\n",
      "        return Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3792e-18, 1.8610e-13, 5.7322e-13,  ..., 1.1541e-21,\n",
      "          1.2286e-21, 1.1908e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5223e-17, 3.2710e-16, 3.4424e-14,  ..., 4.3897e-21,\n",
      "          3.8739e-21, 4.1887e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.9526e-18, 8.0837e-13, 7.2310e-14,  ..., 4.3393e-20,\n",
      "          3.8632e-20, 4.4858e-20]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.6641e-17, 2.8172e-09, 4.3023e-12,  ..., 3.1259e-19,\n",
      "          2.7803e-19, 3.1752e-19]]], device='cuda:0')\n",
      "lines[0].split(\",\")\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.1633e-09, 1.1766e-08, 3.6968e-06,  ..., 4.2499e-14,\n",
      "          4.2499e-14, 4.5239e-14]]], device='cuda:0')\n",
      "```\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5111e-03, 1.1998e-05, 1.1033e-04,  ..., 9.4513e-08,\n",
      "          9.7513e-08, 1.0061e-07]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5224e-10, 2.1225e-08, 2.4328e-10,  ..., 4.2825e-16,\n",
      "          4.4185e-16, 4.5587e-16]]], device='cuda:0')\n",
      "\n",
      "In this Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[7.8681e-13, 2.2959e-08, 2.3223e-10,  ..., 1.2223e-18,\n",
      "          1.2611e-18, 1.3011e-18]],\n",
      "\n",
      "        [[5.8030e-11, 2.2212e-07, 8.7982e-10,  ..., 7.0209e-17,\n",
      "          7.0209e-17, 7.2438e-17]]], device='cuda:0')\n",
      "updated code, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.2254e-13, 8.9651e-07, 8.8901e-11,  ..., 3.4574e-18,\n",
      "          4.1705e-18, 4.3029e-18]]], device='cuda:0')\n",
      "I Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4384e-13, 1.0510e-07, 5.6343e-11,  ..., 8.3170e-19,\n",
      "          8.8534e-19, 8.8534e-19]]], device='cuda:0')\n",
      "added a Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0081e-14, 3.8527e-08, 8.3445e-12,  ..., 3.2133e-20,\n",
      "          3.5291e-20, 3.4205e-20]]], device='cuda:0')\n",
      "new method Got scores scores stopping:  torch.Size([1, 32256]) 18\n",
      "tensor([[[9.8614e-15, 2.5609e-06, 1.2624e-08,  ..., 2.2290e-20,\n",
      "          2.1604e-20, 2.1604e-20]],\n",
      "\n",
      "        [[1.4708e-12, 1.2419e-07, 1.9876e-10,  ..., 1.2230e-18,\n",
      "          1.1489e-18, 1.3433e-18]],\n",
      "\n",
      "        [[5.9940e-11, 1.7318e-07, 2.0480e-09,  ..., 5.4741e-17,\n",
      "          5.6479e-17, 5.8271e-17]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.4059e-12, 3.8388e-09, 1.3983e-10,  ..., 3.0032e-18,\n",
      "          3.1969e-18, 3.2984e-18]],\n",
      "\n",
      "        [[6.3303e-15, 3.3448e-10, 3.4907e-12,  ..., 3.6538e-20,\n",
      "          3.6538e-20, 3.8895e-20]],\n",
      "\n",
      "        [[1.9834e-10, 6.4296e-08, 2.0668e-09,  ..., 2.2543e-16,\n",
      "          2.2543e-16, 2.3997e-16]]], device='cuda:0')\n",
      "`header` which Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4898e-14, 6.2956e-13, 4.0647e-13,  ..., 2.3695e-17,\n",
      "          2.2260e-17, 2.1915e-17]]], device='cuda:0')\n",
      "splits Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.3203e-14, 1.9880e-09, 1.0212e-10,  ..., 2.6195e-19,\n",
      "          2.3851e-19, 2.6195e-19]]], device='cuda:0')\n",
      "the first Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.2701e-14, 6.6896e-08, 1.7651e-10,  ..., 2.2067e-19,\n",
      "          2.2067e-19, 2.5799e-19]]], device='cuda:0')\n",
      "line of Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.7915e-14, 1.1615e-09, 1.1387e-11,  ..., 5.5114e-19,\n",
      "          4.8638e-19, 5.6863e-19]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.3746e-13, 1.9789e-07, 1.2140e-09,  ..., 3.2130e-18,\n",
      "          3.1142e-18, 3.4203e-18]]], device='cuda:0')\n",
      "CSV file Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.8606e-11, 7.3666e-07, 4.5644e-08,  ..., 2.5573e-16,\n",
      "          2.3285e-16, 2.7223e-16]]], device='cuda:0')\n",
      "(which Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.2110e-13, 8.7461e-09, 2.0569e-10,  ..., 2.0868e-18,\n",
      "          1.8706e-18, 2.1869e-18]]], device='cuda:0')\n",
      "is assumed Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.9336e-15, 2.8026e-09, 8.2028e-11,  ..., 5.8430e-20,\n",
      "          5.6632e-20, 6.1234e-20]]], device='cuda:0')\n",
      "to Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.7718e-14, 5.3525e-09, 2.8367e-10,  ..., 5.8469e-19,\n",
      "          5.8469e-19, 6.3220e-19]]], device='cuda:0')\n",
      "be the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3300e-12, 7.9630e-08, 6.6774e-10,  ..., 5.7945e-18,\n",
      "          5.2759e-18, 5.4434e-18]]], device='cuda:0')\n",
      "header) Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1119e-14, 1.7170e-08, 8.2036e-11,  ..., 9.3379e-20,\n",
      "          8.5023e-20, 9.1932e-20]]], device='cuda:0')\n",
      "and returns Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4350e-13, 7.1469e-09, 1.6130e-11,  ..., 1.0025e-18,\n",
      "          1.0025e-18, 1.1359e-18]]], device='cuda:0')\n",
      "it as Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[6.9834e-15, 1.6374e-10, 2.7306e-12,  ..., 4.1587e-20,\n",
      "          4.1587e-20, 4.4269e-20]],\n",
      "\n",
      "        [[1.9837e-11, 5.5002e-09, 1.0074e-10,  ..., 2.4000e-17,\n",
      "          2.4762e-17, 2.7196e-17]],\n",
      "\n",
      "        [[7.6989e-15, 8.0902e-10, 3.7465e-12,  ..., 7.1011e-20,\n",
      "          6.8826e-20, 8.3020e-20]],\n",
      "\n",
      "        [[1.4964e-10, 4.0215e-08, 5.0623e-10,  ..., 2.4746e-16,\n",
      "          2.4746e-16, 2.6342e-16]]], device='cuda:0')\n",
      "a list of strings.\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.5731e-04, 4.1837e-07, 1.3428e-05,  ..., 1.5391e-07,\n",
      "          1.5391e-07, 1.4917e-07]]], device='cuda:0')\n",
      "<|EOT|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▉                                                                                                                                                                                                     | 1/105 [00:03<06:15,  3.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  3.586542649194598\n",
      "<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\n",
      "### Instruction:\n",
      "## Code Before:\n",
      "class Fib:\n",
      "    def __iter__(self):\n",
      "        self.prev_prev = 0\n",
      "        self.prev = 1\n",
      "        return self\n",
      "    def __next__(self):\n",
      "        output = self.prev + self.prev_prev\n",
      "        self.prev_prev = self.prev\n",
      "        self.prev = output\n",
      "        return output\n",
      "## Change requested: add a method `next_n_fibs(n: int)` which takes in an integer, and produces a list containing the next `n` integers in the fibonacci sequence\n",
      "starting from what the object would return if its `__next__` method was called. The method should not mutate the state of the object. When asked \n",
      "for the next fibonacci number after this method is called, it should return the same number it would have return if the method was never called.\n",
      "## Rewrite the code to incorporate the change.\n",
      "\n",
      "### Response:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.2758e-12, 6.0137e-06, 3.9605e-04,  ..., 1.3214e-17,\n",
      "          1.4513e-17, 1.3634e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[7.2758e-12, 6.0137e-06, 3.9605e-04,  ..., 1.3214e-17,\n",
      "          1.4513e-17, 1.3634e-17]],\n",
      "\n",
      "        [[2.3526e-10, 5.8140e-07, 2.5043e-10,  ..., 1.2630e-16,\n",
      "          1.3872e-16, 1.3445e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.9861e-02, 1.3692e-08, 1.1351e-08,  ..., 2.3793e-09,\n",
      "          2.3793e-09, 2.3061e-09]]], device='cuda:0')\n",
      "Sure, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.4675e-10, 2.7059e-07, 2.7100e-10,  ..., 1.4549e-16,\n",
      "          1.5488e-16, 1.5011e-16]]], device='cuda:0')\n",
      "here is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3587e-12, 3.3577e-09, 8.6727e-11,  ..., 5.9196e-18,\n",
      "          6.1075e-18, 6.3014e-18]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.4339e-12, 6.2812e-08, 7.1993e-10,  ..., 2.6043e-18,\n",
      "          2.7723e-18, 2.7723e-18]]], device='cuda:0')\n",
      "modified Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[6.9614e-12, 9.3142e-11, 5.5301e-10,  ..., 1.1512e-17,\n",
      "          1.1877e-17, 1.1877e-17]],\n",
      "\n",
      "        [[2.7940e-09, 1.5104e-08, 3.0338e-07,  ..., 6.1211e-15,\n",
      "          6.3154e-15, 6.1211e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.7791e-11, 2.4756e-08, 1.8293e-07,  ..., 6.1550e-17,\n",
      "          6.3504e-17, 5.9656e-17]]], device='cuda:0')\n",
      "code:\n",
      "\n",
      "```python\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1950e-12, 2.3563e-08, 5.1388e-05,  ..., 7.4479e-18,\n",
      "          7.6843e-18, 7.4479e-18]]], device='cuda:0')\n",
      "class Got scores scores stopping:  torch.Size([1, 32256]) 7\n",
      "tensor([[[4.0078e-16, 1.5428e-13, 1.2135e-12,  ..., 1.6732e-19,\n",
      "          1.7535e-19, 1.6996e-19]],\n",
      "\n",
      "        [[1.9354e-12, 9.8288e-12, 2.5349e-10,  ..., 2.0870e-17,\n",
      "          2.2216e-17, 2.1533e-17]],\n",
      "\n",
      "        [[8.9751e-15, 2.2659e-12, 2.7879e-10,  ..., 1.0302e-19,\n",
      "          9.6783e-20, 9.3805e-20]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.8528e-14, 4.8455e-11, 1.5399e-10,  ..., 3.3787e-19,\n",
      "          3.7108e-19, 3.7108e-19]],\n",
      "\n",
      "        [[2.1118e-16, 2.6504e-12, 1.0277e-13,  ..., 3.3134e-21,\n",
      "          3.5271e-21, 3.2115e-21]],\n",
      "\n",
      "        [[3.4859e-19, 1.6070e-12, 1.1942e-12,  ..., 5.8924e-22,\n",
      "          6.4715e-22, 6.1752e-22]]], device='cuda:0')\n",
      "Fib:\n",
      "    def Got scores scores stopping:  torch.Size([1, 32256]) 21\n",
      "tensor([[[3.0729e-16, 4.7450e-10, 4.9519e-12,  ..., 1.1210e-20,\n",
      "          1.2702e-20, 1.1933e-20]],\n",
      "\n",
      "        [[3.0046e-14, 2.1032e-09, 8.9565e-11,  ..., 2.9500e-19,\n",
      "          3.0437e-19, 3.2400e-19]],\n",
      "\n",
      "        [[1.5403e-16, 1.0450e-11, 4.1680e-07,  ..., 3.9843e-21,\n",
      "          3.9843e-21, 3.8618e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.5064e-12, 4.0969e-09, 3.4303e-08,  ..., 8.9890e-18,\n",
      "          8.9890e-18, 9.8725e-18]],\n",
      "\n",
      "        [[4.0627e-12, 1.1873e-10, 2.0166e-07,  ..., 9.7752e-18,\n",
      "          1.0406e-17, 1.0736e-17]],\n",
      "\n",
      "        [[3.0061e-15, 5.4351e-12, 1.0255e-10,  ..., 1.7351e-20,\n",
      "          1.7902e-20, 1.9056e-20]]], device='cuda:0')\n",
      "__init__(self):\n",
      "        self.prev_prev = 0\n",
      "        self.prev = 1\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1614e-12, 5.4566e-10, 1.5947e-08,  ..., 1.3702e-17,\n",
      "          1.3280e-17, 1.3702e-17]]], device='cuda:0')\n",
      "self.current = Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[7.3402e-16, 7.4760e-11, 1.6681e-11,  ..., 1.1517e-20,\n",
      "          9.8507e-21, 1.0819e-20]],\n",
      "\n",
      "        [[2.5403e-12, 1.2754e-09, 3.0248e-07,  ..., 1.6103e-17,\n",
      "          1.6103e-17, 1.7142e-17]],\n",
      "\n",
      "        [[1.1584e-11, 1.4560e-10, 1.2435e-07,  ..., 4.1842e-17,\n",
      "          4.4540e-17, 4.4540e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[1.7002e-11, 6.8590e-09, 9.5629e-07,  ..., 7.8852e-17,\n",
      "          7.8852e-17, 8.9351e-17]],\n",
      "\n",
      "        [[5.1171e-12, 1.9811e-10, 1.3177e-07,  ..., 2.3733e-17,\n",
      "          2.5263e-17, 2.6065e-17]]], device='cuda:0')\n",
      "1\n",
      "\n",
      "   Got scores scores stopping:  torch.Size([1, 32256]) 9\n",
      "tensor([[[3.2758e-19, 1.8036e-13, 2.1297e-12,  ..., 3.4578e-23,\n",
      "          3.9183e-23, 4.0426e-23]],\n",
      "\n",
      "        [[1.7594e-15, 8.6472e-12, 1.5996e-12,  ..., 2.3612e-20,\n",
      "          2.5135e-20, 2.3612e-20]],\n",
      "\n",
      "        [[8.6720e-17, 1.5501e-11, 1.0884e-12,  ..., 3.9991e-21,\n",
      "          3.8760e-21, 4.1260e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.2981e-17, 5.7888e-12, 3.3980e-09,  ..., 1.5651e-21,\n",
      "          1.5169e-21, 1.6148e-21]],\n",
      "\n",
      "        [[4.6650e-18, 6.1008e-13, 3.8884e-08,  ..., 3.2803e-22,\n",
      "          3.3320e-22, 3.4919e-22]],\n",
      "\n",
      "        [[1.2811e-15, 8.5080e-10, 5.9057e-09,  ..., 6.5253e-21,\n",
      "          6.9462e-21, 7.3942e-21]]], device='cuda:0')\n",
      " def __iter__(self):\n",
      "        return Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[2.1082e-13, 3.8497e-09, 6.7565e-09,  ..., 1.3789e-18,\n",
      "          1.4227e-18, 1.4227e-18]],\n",
      "\n",
      "        [[7.0978e-12, 1.4256e-10, 2.1158e-08,  ..., 3.7302e-17,\n",
      "          3.8486e-17, 3.8486e-17]]], device='cuda:0')\n",
      "self\n",
      "\n",
      "   Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[3.8680e-18, 1.1399e-12, 1.1513e-11,  ..., 7.0951e-23,\n",
      "          7.7925e-23, 8.0398e-23]],\n",
      "\n",
      "        [[3.4286e-14, 2.5842e-11, 1.8720e-12,  ..., 3.5835e-19,\n",
      "          3.4732e-19, 3.4732e-19]],\n",
      "\n",
      "        [[1.9870e-19, 9.7507e-13, 3.4424e-14,  ..., 1.0066e-21,\n",
      "          9.7949e-22, 9.7567e-22]]], device='cuda:0')\n",
      " def Got scores scores stopping:  torch.Size([1, 32256]) 9\n",
      "tensor([[[2.3227e-20, 2.1177e-11, 1.4047e-13,  ..., 2.5307e-21,\n",
      "          2.9703e-21, 2.5605e-21]],\n",
      "\n",
      "        [[2.9148e-15, 2.0202e-11, 1.1643e-13,  ..., 4.0129e-19,\n",
      "          4.4073e-19, 4.5472e-19]],\n",
      "\n",
      "        [[1.5440e-16, 5.5433e-10, 1.7245e-08,  ..., 3.0148e-21,\n",
      "          2.8321e-21, 2.9220e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[9.6685e-17, 2.1054e-10, 6.4950e-13,  ..., 2.3495e-21,\n",
      "          2.5404e-21, 2.5404e-21]],\n",
      "\n",
      "        [[4.2064e-19, 1.8184e-11, 1.4899e-11,  ..., 1.5875e-18,\n",
      "          1.6125e-18, 1.5875e-18]],\n",
      "\n",
      "        [[1.4198e-16, 1.2368e-11, 7.5766e-11,  ..., 1.7348e-21,\n",
      "          1.5310e-21, 1.6815e-21]]], device='cuda:0')\n",
      "__next__(self):\n",
      "        output = self.current\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0067e-15, 3.0009e-12, 3.6868e-07,  ..., 2.6041e-20,\n",
      "          2.6041e-20, 2.6041e-20]]], device='cuda:0')\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[6.5718e-18, 2.1271e-12, 8.7665e-11,  ..., 4.6211e-22,\n",
      "          4.4789e-22, 4.6211e-22]],\n",
      "\n",
      "        [[2.7931e-15, 1.6724e-10, 4.0518e-09,  ..., 2.1358e-20,\n",
      "          2.1358e-20, 2.1358e-20]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[4.9533e-15, 1.5718e-11, 8.1544e-12,  ..., 5.5109e-20,\n",
      "          5.0178e-20, 5.5109e-20]],\n",
      "\n",
      "        [[1.5079e-22, 2.6850e-17, 3.0315e-15,  ..., 1.1765e-23,\n",
      "          1.2721e-23, 1.2524e-23]],\n",
      "\n",
      "        [[4.1838e-15, 2.2361e-12, 1.3993e-12,  ..., 1.3681e-19,\n",
      "          1.3055e-19, 1.5026e-19]]], device='cuda:0')\n",
      "self.prev_prev, Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.4998e-19, 2.3895e-13, 1.2135e-12,  ..., 7.1446e-16,\n",
      "          7.1446e-16, 6.9248e-16]],\n",
      "\n",
      "        [[3.6805e-24, 4.4710e-16, 4.7053e-14,  ..., 2.6321e-26,\n",
      "          2.5288e-26, 2.6117e-26]],\n",
      "\n",
      "        [[7.7041e-13, 2.9827e-11, 8.3652e-11,  ..., 8.8435e-18,\n",
      "          8.0521e-18, 9.1242e-18]]], device='cuda:0')\n",
      "self.prev Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.1885e-17, 3.1656e-13, 1.8426e-14,  ..., 2.1607e-20,\n",
      "          2.2644e-20, 2.3731e-20]]], device='cuda:0')\n",
      "= Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[8.7432e-24, 3.0728e-16, 2.6244e-13,  ..., 3.0389e-25,\n",
      "          2.6197e-25, 2.8325e-25]],\n",
      "\n",
      "        [[2.3423e-15, 3.8180e-13, 4.2351e-12,  ..., 1.8089e-19,\n",
      "          1.6993e-19, 1.7809e-19]]], device='cuda:0')\n",
      "self.prev, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.7815e-12, 5.3933e-08, 1.2016e-05,  ..., 3.7235e-17,\n",
      "          4.0895e-17, 3.7235e-17]]], device='cuda:0')\n",
      "output\n",
      "       Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.3567e-13, 1.1832e-10, 1.3971e-09,  ..., 9.3489e-19,\n",
      "          9.6457e-19, 9.3489e-19]]], device='cuda:0')\n",
      " Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.6585e-19, 3.9384e-13, 6.4835e-10,  ..., 7.6695e-23,\n",
      "          6.9831e-23, 7.4335e-23]]], device='cuda:0')\n",
      "self.current Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[4.8892e-15, 6.3940e-10, 8.0489e-12,  ..., 3.7386e-20,\n",
      "          3.7386e-20, 3.9797e-20]],\n",
      "\n",
      "        [[7.4561e-18, 1.2397e-13, 2.8823e-13,  ..., 1.0106e-21,\n",
      "          1.0265e-21, 1.0758e-21]],\n",
      "\n",
      "        [[3.1020e-18, 3.8931e-14, 2.3345e-12,  ..., 4.0349e-23,\n",
      "          3.6738e-23, 4.0349e-23]],\n",
      "\n",
      "        [[7.1169e-14, 1.4132e-10, 7.5645e-11,  ..., 2.8963e-18,\n",
      "          2.5962e-18, 3.0353e-18]]], device='cuda:0')\n",
      "= self.prev Got scores scores stopping:  torch.Size([1, 32256]) 8\n",
      "tensor([[[4.8409e-16, 5.0367e-12, 1.4288e-13,  ..., 3.9403e-21,\n",
      "          4.0654e-21, 4.1945e-21]],\n",
      "\n",
      "        [[5.0663e-16, 9.2513e-12, 7.2050e-12,  ..., 4.1238e-21,\n",
      "          4.1238e-21, 4.1238e-21]],\n",
      "\n",
      "        [[4.0129e-20, 7.0217e-14, 3.7158e-12,  ..., 2.4902e-24,\n",
      "          2.3030e-24, 2.5294e-24]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.9364e-12, 2.1038e-09, 1.1133e-07,  ..., 1.3357e-17,\n",
      "          1.2547e-17, 1.3781e-17]],\n",
      "\n",
      "        [[1.7755e-14, 3.1114e-11, 2.2249e-07,  ..., 1.3159e-19,\n",
      "          1.3159e-19, 1.4452e-19]],\n",
      "\n",
      "        [[1.0561e-13, 1.4414e-10, 1.2452e-09,  ..., 4.1897e-19,\n",
      "          4.0608e-19, 4.4599e-19]]], device='cuda:0')\n",
      "+ self.prev_prev\n",
      "        return Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[9.6129e-11, 4.0875e-09, 1.4267e-08,  ..., 5.5485e-16,\n",
      "          5.5485e-16, 5.3778e-16]],\n",
      "\n",
      "        [[1.3579e-12, 1.6193e-10, 4.4900e-08,  ..., 8.6080e-18,\n",
      "          8.3432e-18, 8.8813e-18]]], device='cuda:0')\n",
      "output\n",
      "\n",
      "   Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[4.1080e-18, 2.8149e-12, 4.8360e-11,  ..., 1.1312e-22,\n",
      "          1.1312e-22, 1.2424e-22]],\n",
      "\n",
      "        [[3.7487e-18, 1.3045e-11, 8.6898e-12,  ..., 3.8434e-21,\n",
      "          3.7838e-21, 3.5824e-21]]], device='cuda:0')\n",
      " def Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[8.6180e-16, 1.1762e-12, 2.6769e-11,  ..., 4.2305e-20,\n",
      "          4.2971e-20, 4.7938e-20]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 5\n",
      "tensor([[[7.6905e-20, 1.0703e-16, 3.0554e-15,  ..., 1.2577e-21,\n",
      "          1.2676e-21, 1.3129e-21]],\n",
      "\n",
      "        [[5.1430e-20, 1.3989e-15, 1.1304e-16,  ..., 1.7876e-21,\n",
      "          2.0899e-21, 1.9442e-21]],\n",
      "\n",
      "        [[1.9613e-14, 3.0033e-12, 8.6902e-12,  ..., 4.7662e-19,\n",
      "          4.7662e-19, 4.7662e-19]],\n",
      "\n",
      "        [[3.1343e-14, 2.6505e-12, 1.0160e-11,  ..., 1.2829e-19,\n",
      "          1.2434e-19, 1.2829e-19]],\n",
      "\n",
      "        [[1.6310e-20, 4.1349e-16, 2.7077e-13,  ..., 3.7099e-23,\n",
      "          4.0113e-23, 4.0113e-23]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3016e-14, 8.0529e-13, 2.0564e-12,  ..., 2.5416e-19,\n",
      "          2.6223e-19, 2.4634e-19]]], device='cuda:0')\n",
      "next_n_fibs(self, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.9490e-18, 4.7351e-13, 2.8720e-13,  ..., 4.7565e-22,\n",
      "          4.9075e-22, 5.5609e-22]]], device='cuda:0')\n",
      "n: Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.1510e-14, 3.3585e-10, 1.2728e-07,  ..., 7.2962e-20,\n",
      "          7.0717e-20, 7.0717e-20]],\n",
      "\n",
      "        [[5.1628e-14, 8.7691e-11, 1.5520e-06,  ..., 2.7133e-19,\n",
      "          2.5489e-19, 2.8883e-19]],\n",
      "\n",
      "        [[6.6795e-12, 2.4018e-08, 3.2135e-07,  ..., 5.1075e-17,\n",
      "          4.9504e-17, 5.2697e-17]]], device='cuda:0')\n",
      "int):\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.6546e-13, 1.1762e-10, 2.4374e-09,  ..., 3.2437e-18,\n",
      "          3.0471e-18, 3.2437e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.5109e-14, 5.8989e-10, 1.6901e-10,  ..., 2.5486e-19,\n",
      "          2.3205e-19, 2.5486e-19]]], device='cuda:0')\n",
      "fib_sequence = Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.1454e-14, 9.0409e-11, 3.8826e-08,  ..., 5.7399e-19,\n",
      "          5.2262e-19, 5.0654e-19]]], device='cuda:0')\n",
      "[]\n",
      "       Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.6133e-14, 1.0941e-11, 1.9393e-10,  ..., 3.5276e-19,\n",
      "          3.5276e-19, 3.5276e-19]]], device='cuda:0')\n",
      " Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[2.1591e-10, 2.2024e-08, 1.4671e-08,  ..., 5.5302e-16,\n",
      "          5.3600e-16, 5.5302e-16]],\n",
      "\n",
      "        [[4.5108e-11, 4.8979e-09, 6.1563e-08,  ..., 1.6810e-16,\n",
      "          1.6810e-16, 1.7894e-16]],\n",
      "\n",
      "        [[4.4185e-12, 1.2251e-09, 1.2251e-09,  ..., 2.8899e-17,\n",
      "          2.9816e-17, 3.0763e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.8798e-14, 6.6369e-10, 2.2937e-10,  ..., 3.9193e-19,\n",
      "          4.1721e-19, 4.1721e-19]]], device='cuda:0')\n",
      "fib_generator = Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.8612e-15, 2.7615e-11, 6.2946e-13,  ..., 1.3366e-18,\n",
      "          1.3790e-18, 1.3159e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.0269e-14, 6.0797e-13, 4.3975e-11,  ..., 5.2159e-19,\n",
      "          5.0554e-19, 5.0554e-19]]], device='cuda:0')\n",
      "iter(self)\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.7847e-12, 1.7718e-10, 8.5369e-09,  ..., 1.8154e-17,\n",
      "          1.8154e-17, 1.8731e-17]]], device='cuda:0')\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.4759e-14, 9.3832e-12, 8.6416e-14,  ..., 1.9533e-19,\n",
      "          2.0793e-19, 2.0793e-19]]], device='cuda:0')\n",
      "for _ Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0148e-19, 1.8610e-13, 6.3051e-16,  ..., 6.2617e-23,\n",
      "          6.4605e-23, 5.9750e-23]]], device='cuda:0')\n",
      "in Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[5.4545e-18, 8.7032e-15, 2.2895e-11,  ..., 4.7733e-22,\n",
      "          4.4146e-22, 5.0024e-22]],\n",
      "\n",
      "        [[4.0634e-13, 1.4467e-10, 6.1606e-12,  ..., 7.9343e-18,\n",
      "          7.9343e-18, 8.4460e-18]]], device='cuda:0')\n",
      "range(n):\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.9821e-15, 1.7644e-12, 6.0192e-08,  ..., 2.0928e-20,\n",
      "          1.9055e-20, 2.0284e-20]]], device='cuda:0')\n",
      "            Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1225e-12, 2.4533e-10, 4.0448e-10,  ..., 7.2021e-18,\n",
      "          6.7657e-18, 7.2021e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.7117e-16, 8.6051e-13, 3.6645e-14,  ..., 1.5718e-19,\n",
      "          1.4312e-19, 1.6217e-19]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.2702e-20, 1.4975e-16, 3.3606e-18,  ..., 1.2721e-23,\n",
      "          1.1403e-23, 1.3331e-23]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5039e-14, 4.2178e-14, 3.1656e-13,  ..., 2.9954e-17,\n",
      "          2.6434e-17, 2.9032e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[2.5567e-18, 8.9157e-11, 1.1623e-13,  ..., 6.7219e-19,\n",
      "          7.2115e-19, 7.0997e-19]],\n",
      "\n",
      "        [[1.1082e-18, 5.9731e-12, 2.9401e-11,  ..., 5.9821e-15,\n",
      "          5.9821e-15, 5.6197e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.9227e-16, 3.7008e-13, 3.4032e-12,  ..., 6.7599e-20,\n",
      "          6.5520e-20, 7.3092e-20]]], device='cuda:0')\n",
      "fib_sequence.append(next(fib_generator))\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0462e-14, 1.8419e-12, 1.8182e-07,  ..., 1.1810e-19,\n",
      "          1.0753e-19, 1.1810e-19]]], device='cuda:0')\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.7198e-21, 2.4271e-13, 2.1330e-15,  ..., 5.1860e-23,\n",
      "          4.2910e-23, 4.7288e-23]]], device='cuda:0')\n",
      "return Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[1.6995e-19, 3.8622e-15, 1.2917e-12,  ..., 1.0989e-22,\n",
      "          9.8508e-23, 9.6981e-23]],\n",
      "\n",
      "        [[2.5625e-11, 9.1233e-09, 1.5192e-07,  ..., 1.0488e-16,\n",
      "          9.5497e-17, 1.0166e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5931e-10, 2.0600e-08, 1.8360e-07,  ..., 5.5062e-16,\n",
      "          5.3368e-16, 5.5062e-16]]], device='cuda:0')\n",
      "fib_sequence\n",
      "```\n",
      "\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7987e-12, 4.8745e-06, 1.8111e-05,  ..., 5.0597e-18,\n",
      "          5.0597e-18, 5.3860e-18]]], device='cuda:0')\n",
      "In Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.6134e-13, 1.8112e-08, 2.2098e-10,  ..., 2.2419e-18,\n",
      "          2.3865e-18, 2.3865e-18]]], device='cuda:0')\n",
      "this Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.9187e-12, 4.4987e-08, 3.6928e-09,  ..., 5.0703e-18,\n",
      "          5.0703e-18, 5.2312e-18]]], device='cuda:0')\n",
      "code, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5661e-12, 3.3055e-06, 8.1128e-10,  ..., 8.7615e-18,\n",
      "          1.0243e-17, 1.0904e-17]]], device='cuda:0')\n",
      "I Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1365e-12, 8.3416e-07, 1.1781e-09,  ..., 1.3544e-17,\n",
      "          1.4417e-17, 1.6856e-17]]], device='cuda:0')\n",
      "have added Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4806e-13, 4.8577e-08, 2.1133e-10,  ..., 3.8823e-18,\n",
      "          4.5389e-18, 4.2639e-18]]], device='cuda:0')\n",
      "a Got scores scores stopping:  torch.Size([1, 32256]) 13\n",
      "tensor([[[4.7518e-13, 5.9048e-10, 1.9583e-11,  ..., 2.0703e-18,\n",
      "          1.8850e-18, 2.0703e-18]],\n",
      "\n",
      "        [[6.1720e-15, 6.7017e-13, 1.9780e-10,  ..., 4.2971e-20,\n",
      "          4.0368e-20, 4.5743e-20]],\n",
      "\n",
      "        [[7.4561e-18, 3.0988e-12, 6.8462e-14,  ..., 9.1492e-21,\n",
      "          8.3957e-21, 8.0741e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.0835e-13, 4.4134e-11, 1.9391e-12,  ..., 2.8299e-18,\n",
      "          2.8299e-18, 2.9197e-18]],\n",
      "\n",
      "        [[1.9607e-14, 4.2338e-12, 4.1445e-11,  ..., 6.8640e-20,\n",
      "          6.4481e-20, 7.5386e-20]],\n",
      "\n",
      "        [[1.6373e-13, 2.1412e-08, 1.0555e-10,  ..., 2.2446e-19,\n",
      "          2.3894e-19, 2.3159e-19]]], device='cuda:0')\n",
      "`next_n_fibs(n: int)` method Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.9301e-14, 2.7912e-09, 3.5487e-10,  ..., 6.0638e-19,\n",
      "          5.8772e-19, 6.2563e-19]]], device='cuda:0')\n",
      "to the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0603e-13, 7.6578e-09, 3.6173e-09,  ..., 2.9827e-19,\n",
      "          3.0774e-19, 3.1751e-19]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.9399e-11, 1.0799e-08, 4.9441e-09,  ..., 7.5299e-17,\n",
      "          7.0736e-17, 7.5299e-17]]], device='cuda:0')\n",
      "`Fib` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.4416e-11, 3.6597e-08, 1.2523e-09,  ..., 2.4489e-17,\n",
      "          2.5267e-17, 2.6069e-17]]], device='cuda:0')\n",
      "class. Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1699e-14, 1.0192e-09, 1.1681e-11,  ..., 4.6410e-20,\n",
      "          4.4982e-20, 4.3598e-20]]], device='cuda:0')\n",
      "This method Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.8534e-13, 4.7438e-09, 4.1042e-11,  ..., 1.0633e-18,\n",
      "          1.0970e-18, 1.0633e-18]]], device='cuda:0')\n",
      "creates Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.5075e-13, 6.8237e-09, 5.9037e-11,  ..., 5.3384e-18,\n",
      "          6.0492e-18, 5.5078e-18]]], device='cuda:0')\n",
      "a Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.6832e-12, 3.7948e-08, 7.3987e-10,  ..., 1.3592e-17,\n",
      "          1.4928e-17, 1.4024e-17]]], device='cuda:0')\n",
      "new Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.2809e-12, 2.5885e-10, 4.4538e-12,  ..., 2.7365e-17,\n",
      "          2.7365e-17, 2.9130e-17]]], device='cuda:0')\n",
      "iterator Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7747e-12, 9.5795e-09, 9.4850e-10,  ..., 3.3256e-18,\n",
      "          3.5400e-18, 3.5400e-18]]], device='cuda:0')\n",
      "from the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4340e-12, 9.1239e-08, 3.7287e-10,  ..., 6.4350e-18,\n",
      "          6.8500e-18, 6.8500e-18]]], device='cuda:0')\n",
      "current state Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.2899e-12, 3.5011e-09, 2.1026e-10,  ..., 1.8246e-18,\n",
      "          1.9422e-18, 2.0039e-18]],\n",
      "\n",
      "        [[1.5483e-12, 1.9851e-09, 2.3709e-10,  ..., 3.9657e-18,\n",
      "          3.9657e-18, 4.2215e-18]],\n",
      "\n",
      "        [[1.0987e-10, 3.0767e-07, 4.9730e-09,  ..., 1.0034e-16,\n",
      "          9.7251e-17, 1.0352e-16]]], device='cuda:0')\n",
      "of the Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[5.5377e-13, 9.2990e-08, 6.8033e-08,  ..., 1.0377e-18,\n",
      "          1.0058e-18, 1.0706e-18]],\n",
      "\n",
      "        [[2.3426e-15, 2.4900e-12, 4.6060e-13,  ..., 5.8735e-20,\n",
      "          5.6928e-20, 6.2523e-20]],\n",
      "\n",
      "        [[6.6254e-11, 8.1518e-09, 4.1398e-08,  ..., 1.1663e-16,\n",
      "          1.0956e-16, 1.1663e-16]],\n",
      "\n",
      "        [[6.6364e-12, 1.9174e-08, 2.5950e-09,  ..., 9.0983e-18,\n",
      "          8.8183e-18, 9.3871e-18]]], device='cuda:0')\n",
      "`Fib` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.6817e-13, 1.1410e-08, 5.1722e-10,  ..., 1.7036e-18,\n",
      "          1.6256e-18, 1.7304e-18]]], device='cuda:0')\n",
      "object, and Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.2118e-14, 2.2850e-07, 1.5728e-10,  ..., 9.9856e-19,\n",
      "          9.5283e-19, 1.0143e-18]]], device='cuda:0')\n",
      "then uses Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.4388e-14, 5.7753e-09, 2.7322e-12,  ..., 6.1147e-19,\n",
      "          6.2110e-19, 5.7442e-19]]], device='cuda:0')\n",
      "a loop Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.5383e-14, 6.6563e-07, 9.0218e-11,  ..., 4.2565e-19,\n",
      "          4.3236e-19, 4.6024e-19]]], device='cuda:0')\n",
      "to generate Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1324e-14, 1.5890e-09, 2.8816e-12,  ..., 1.2699e-19,\n",
      "          1.3518e-19, 1.3518e-19]]], device='cuda:0')\n",
      "the next Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[5.9821e-15, 1.9750e-07, 4.9444e-09,  ..., 2.8625e-20,\n",
      "          2.8625e-20, 2.9534e-20]],\n",
      "\n",
      "        [[5.9138e-13, 1.6726e-08, 5.6668e-11,  ..., 4.3829e-18,\n",
      "          4.2481e-18, 4.3829e-18]],\n",
      "\n",
      "        [[2.2299e-12, 2.3938e-08, 8.1912e-10,  ..., 8.3103e-18,\n",
      "          7.8068e-18, 8.0546e-18]]], device='cuda:0')\n",
      "`n` Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[6.2335e-14, 4.2356e-12, 6.6255e-11,  ..., 1.6542e-17,\n",
      "          1.7886e-17, 1.6033e-17]],\n",
      "\n",
      "        [[1.5565e-12, 3.9297e-10, 6.6846e-10,  ..., 1.7867e-17,\n",
      "          1.7318e-17, 1.9020e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.5009e-19, 3.9232e-15, 1.8971e-15,  ..., 2.4580e-20,\n",
      "          2.2293e-20, 2.2889e-20]],\n",
      "\n",
      "        [[1.7983e-13, 9.5022e-09, 2.9900e-09,  ..., 5.7324e-19,\n",
      "          5.3850e-19, 5.7324e-19]]], device='cuda:0')\n",
      "Fibonacci Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.4910e-13, 6.8060e-08, 3.4223e-08,  ..., 4.7528e-19,\n",
      "          4.4648e-19, 4.9037e-19]]], device='cuda:0')\n",
      "numbers. Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7276e-13, 3.6103e-08, 6.1506e-11,  ..., 1.1658e-18,\n",
      "          1.2028e-18, 1.2028e-18]]], device='cuda:0')\n",
      "These numbers Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.7406e-12, 5.1634e-08, 3.1365e-11,  ..., 1.4403e-17,\n",
      "          1.3530e-17, 1.4860e-17]]], device='cuda:0')\n",
      "are Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4033e-12, 2.0848e-11, 7.3602e-13,  ..., 1.2683e-17,\n",
      "          1.2293e-17, 1.2683e-17]]], device='cuda:0')\n",
      "appended Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.3641e-12, 6.0278e-09, 6.6963e-11,  ..., 5.8688e-18,\n",
      "          5.8688e-18, 5.6883e-18]]], device='cuda:0')\n",
      "to the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.5050e-16, 1.0799e-08, 9.1459e-10,  ..., 5.2949e-21,\n",
      "          4.6727e-21, 4.9741e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7113e-12, 1.5894e-10, 9.5450e-12,  ..., 1.2683e-17,\n",
      "          1.2683e-17, 1.1915e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3193e-13, 4.6900e-08, 1.7452e-10,  ..., 3.0767e-19,\n",
      "          2.8014e-19, 3.0767e-19]]], device='cuda:0')\n",
      "`fib_sequence` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.9724e-11, 7.8103e-09, 2.8449e-10,  ..., 5.1160e-17,\n",
      "          5.4459e-17, 5.4459e-17]]], device='cuda:0')\n",
      "list, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1548e-13, 1.1287e-09, 1.8823e-11,  ..., 1.0651e-18,\n",
      "          1.0323e-18, 1.0651e-18]]], device='cuda:0')\n",
      "which is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.3866e-13, 1.4766e-08, 8.4261e-12,  ..., 1.8858e-18,\n",
      "          1.8278e-18, 2.0074e-18]]], device='cuda:0')\n",
      "returned at Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.3191e-16, 6.9820e-12, 3.3360e-14,  ..., 4.8204e-21,\n",
      "          4.3890e-21, 5.2942e-21]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1689e-12, 2.4955e-08, 4.1144e-08,  ..., 4.0923e-18,\n",
      "          3.8443e-18, 4.0923e-18]]], device='cuda:0')\n",
      "end.\n",
      "\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0315e-13, 2.5706e-06, 2.1311e-06,  ..., 3.5000e-19,\n",
      "          3.3923e-19, 3.5000e-19]]], device='cuda:0')\n",
      "The Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.1003e-10, 2.3102e-05, 4.0545e-05,  ..., 3.8700e-16,\n",
      "          3.7509e-16, 3.8700e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[4.6659e-18, 8.6909e-12, 1.1400e-12,  ..., 4.2881e-21,\n",
      "          4.3218e-21, 4.6366e-21]],\n",
      "\n",
      "        [[5.7148e-10, 4.3072e-07, 6.2670e-07,  ..., 1.8795e-15,\n",
      "          1.8216e-15, 1.8795e-15]],\n",
      "\n",
      "        [[1.4105e-12, 3.9891e-08, 3.5204e-08,  ..., 3.1881e-18,\n",
      "          3.0900e-18, 3.0900e-18]],\n",
      "\n",
      "        [[2.3587e-13, 4.2582e-07, 1.1461e-07,  ..., 2.8375e-18,\n",
      "          2.7935e-18, 2.7502e-18]]], device='cuda:0')\n",
      "`Fib` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3023e-12, 7.8752e-07, 2.4018e-07,  ..., 8.2557e-18,\n",
      "          8.0017e-18, 7.6353e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.5862e-13, 7.9443e-09, 4.2103e-10,  ..., 2.9358e-18,\n",
      "          2.9358e-18, 2.8454e-18]]], device='cuda:0')\n",
      "object's state Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.4099e-13, 2.0747e-07, 1.5684e-10,  ..., 1.6324e-17,\n",
      "          1.6324e-17, 1.9085e-17]]], device='cuda:0')\n",
      "is not Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[8.8695e-13, 9.9363e-11, 1.1148e-11,  ..., 1.3411e-16,\n",
      "          1.4055e-16, 1.3837e-16]]], device='cuda:0')\n",
      "mutated Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.8302e-13, 4.6592e-10, 4.2423e-10,  ..., 2.0330e-18,\n",
      "          1.8511e-18, 2.1641e-18]]], device='cuda:0')\n",
      "by this Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0955e-07, 1.4402e-07, 5.2460e-09,  ..., 1.0904e-13,\n",
      "          1.0904e-13, 1.0904e-13]]], device='cuda:0')\n",
      "method, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1621e-13, 7.2505e-08, 1.9935e-09,  ..., 5.9195e-19,\n",
      "          5.5609e-19, 5.9195e-19]]], device='cuda:0')\n",
      "so Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0963e-12, 2.9813e-08, 1.6302e-09,  ..., 5.8971e-18,\n",
      "          5.3693e-18, 5.7156e-18]]], device='cuda:0')\n",
      "if Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0981e-14, 4.6552e-07, 9.1805e-11,  ..., 1.0450e-19,\n",
      "          9.6647e-20, 1.1124e-19]]], device='cuda:0')\n",
      "you call Got scores scores stopping:  torch.Size([1, 32256]) 10\n",
      "tensor([[[2.2473e-12, 6.3559e-08, 3.2278e-07,  ..., 2.8052e-18,\n",
      "          2.7189e-18, 2.7189e-18]],\n",
      "\n",
      "        [[1.9580e-11, 2.2409e-10, 1.0259e-10,  ..., 3.4468e-17,\n",
      "          3.0418e-17, 3.4468e-17]],\n",
      "\n",
      "        [[2.1542e-14, 5.7322e-13, 5.9053e-10,  ..., 8.2829e-20,\n",
      "          8.0281e-20, 8.8171e-20]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.1864e-12, 3.2201e-09, 5.9565e-10,  ..., 1.5279e-18,\n",
      "          1.3484e-18, 1.5279e-18]],\n",
      "\n",
      "        [[3.2200e-13, 1.7959e-12, 1.8111e-08,  ..., 9.6420e-19,\n",
      "          8.7791e-19, 9.3454e-19]],\n",
      "\n",
      "        [[1.2941e-09, 6.5072e-10, 8.8942e-10,  ..., 2.0742e-15,\n",
      "          2.0742e-15, 2.1401e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.2925e-12, 4.1421e-08, 9.4417e-10,  ..., 5.2900e-18,\n",
      "          4.9695e-18, 5.8099e-18]]], device='cuda:0')\n",
      "`next_n_fibs(n)` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.8135e-13, 9.5822e-09, 2.7183e-10,  ..., 2.0817e-18,\n",
      "          1.9252e-18, 2.0817e-18]]], device='cuda:0')\n",
      "and then Got scores scores stopping:  torch.Size([1, 32256]) 13\n",
      "tensor([[[2.9230e-11, 3.5965e-09, 3.9110e-10,  ..., 3.0249e-17,\n",
      "          2.9318e-17, 3.3222e-17]],\n",
      "\n",
      "        [[7.0004e-12, 1.2911e-06, 6.4918e-07,  ..., 9.0158e-18,\n",
      "          8.7384e-18, 9.0158e-18]],\n",
      "\n",
      "        [[8.0485e-09, 7.8009e-09, 8.0485e-09,  ..., 8.5934e-15,\n",
      "          7.3503e-15, 8.5934e-15]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.4498e-11, 1.3843e-09, 6.9606e-10,  ..., 1.3748e-16,\n",
      "          1.3748e-16, 1.3748e-16]],\n",
      "\n",
      "        [[2.2448e-13, 4.1052e-12, 1.8010e-10,  ..., 7.1553e-19,\n",
      "          6.3146e-19, 7.3825e-19]],\n",
      "\n",
      "        [[7.3131e-12, 1.6108e-07, 6.2458e-09,  ..., 2.6415e-17,\n",
      "          2.4814e-17, 2.8118e-17]]], device='cuda:0')\n",
      "call Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3887e-11, 2.1940e-09, 4.9442e-09,  ..., 2.4446e-17,\n",
      "          2.1574e-17, 2.6023e-17]]], device='cuda:0')\n",
      "`next()` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.3169e-11, 3.1784e-09, 3.9165e-10,  ..., 3.8896e-17,\n",
      "          3.8896e-17, 4.5474e-17]]], device='cuda:0')\n",
      "on the Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[8.8121e-13, 3.4065e-08, 2.3413e-08,  ..., 1.3690e-18,\n",
      "          1.3690e-18, 1.4124e-18]],\n",
      "\n",
      "        [[9.9761e-17, 7.2050e-12, 1.3751e-12,  ..., 2.9999e-20,\n",
      "          2.9999e-20, 3.2437e-20]],\n",
      "\n",
      "        [[2.0845e-11, 1.2896e-09, 8.1508e-09,  ..., 5.0156e-17,\n",
      "          4.7117e-17, 5.3390e-17]],\n",
      "\n",
      "        [[3.5596e-13, 2.4672e-09, 5.8600e-10,  ..., 6.0734e-19,\n",
      "          6.0734e-19, 6.6703e-19]]], device='cuda:0')\n",
      "`Fib` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1892e-13, 1.2640e-10, 6.2215e-10,  ..., 6.2497e-19,\n",
      "          5.8710e-19, 6.4480e-19]]], device='cuda:0')\n",
      "object, it Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5354e-15, 7.1601e-08, 4.9285e-11,  ..., 4.4378e-20,\n",
      "          4.1043e-20, 4.5077e-20]]], device='cuda:0')\n",
      "will return Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[5.0222e-13, 9.7624e-09, 3.0416e-10,  ..., 2.1208e-18,\n",
      "          1.9310e-18, 2.1208e-18]],\n",
      "\n",
      "        [[8.7745e-13, 7.6441e-08, 2.8727e-09,  ..., 3.0719e-18,\n",
      "          2.7109e-18, 3.0719e-18]]], device='cuda:0')\n",
      "the same Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0379e-12, 1.3175e-10, 2.1722e-10,  ..., 1.0847e-17,\n",
      "          1.0514e-17, 1.1192e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.2974e-20, 1.4433e-15, 7.4875e-16,  ..., 5.1322e-21,\n",
      "          4.5027e-21, 4.6729e-21]],\n",
      "\n",
      "        [[1.9764e-13, 3.8419e-09, 4.3534e-09,  ..., 5.5598e-19,\n",
      "          5.2229e-19, 5.7363e-19]]], device='cuda:0')\n",
      "Fibonacci number Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.8754e-13, 4.3973e-09, 2.3075e-11,  ..., 2.5968e-18,\n",
      "          2.5169e-18, 2.6792e-18]],\n",
      "\n",
      "        [[2.4341e-14, 1.6166e-08, 5.8304e-11,  ..., 2.8828e-19,\n",
      "          2.8381e-19, 3.0212e-19]],\n",
      "\n",
      "        [[1.2168e-12, 1.5423e-07, 2.8573e-11,  ..., 2.8660e-17,\n",
      "          2.7778e-17, 2.8660e-17]]], device='cuda:0')\n",
      "it would have returned Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.6097e-12, 8.1223e-09, 5.3573e-10,  ..., 1.2637e-17,\n",
      "          1.1871e-17, 1.3038e-17]]], device='cuda:0')\n",
      "if Got scores scores stopping:  torch.Size([1, 32256]) 9\n",
      "tensor([[[3.7221e-10, 1.3404e-09, 7.8797e-10,  ..., 4.9459e-16,\n",
      "          4.3647e-16, 4.9459e-16]],\n",
      "\n",
      "        [[3.9387e-13, 1.8790e-12, 3.8497e-09,  ..., 2.3456e-18,\n",
      "          2.2034e-18, 2.4200e-18]],\n",
      "\n",
      "        [[2.3660e-14, 3.4373e-11, 1.2520e-12,  ..., 1.7535e-19,\n",
      "          1.6473e-19, 1.6996e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.7103e-12, 4.8521e-10, 1.3059e-10,  ..., 4.9226e-18,\n",
      "          4.4821e-18, 5.0789e-18]],\n",
      "\n",
      "        [[1.6421e-13, 1.8035e-13, 1.0798e-08,  ..., 4.0764e-19,\n",
      "          3.9510e-19, 4.2058e-19]],\n",
      "\n",
      "        [[4.3169e-11, 1.1024e-10, 1.5067e-10,  ..., 1.0387e-16,\n",
      "          1.0387e-16, 1.0387e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1424e-11, 6.4992e-09, 4.7080e-10,  ..., 3.9993e-17,\n",
      "          3.7570e-17, 4.1262e-17]]], device='cuda:0')\n",
      "`next_n_fibs(n)` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.7170e-14, 9.0733e-09, 1.9237e-11,  ..., 6.5001e-19,\n",
      "          6.2024e-19, 6.6024e-19]]], device='cuda:0')\n",
      "had Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4807e-16, 6.4192e-11, 2.2439e-13,  ..., 1.2116e-20,\n",
      "          1.2897e-20, 1.3101e-20]]], device='cuda:0')\n",
      "never been Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[4.1250e-07, 1.5025e-08, 4.5825e-09,  ..., 1.7795e-13,\n",
      "          1.6717e-13, 1.7247e-13]],\n",
      "\n",
      "        [[1.5841e-11, 7.5457e-08, 4.9204e-07,  ..., 4.3189e-17,\n",
      "          4.0572e-17, 4.3189e-17]]], device='cuda:0')\n",
      "called.\n",
      "<|EOT|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▊                                                                                                                                                                                                   | 2/105 [00:15<14:12,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  11.53588342294097\n",
      "<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\n",
      "### Instruction:\n",
      "## Code Before:\n",
      "from typing import List, Literal, Tuple\n",
      "from queue import PriorityQueue\n",
      "\n",
      "Move = Literal[\"up\", \"down\", \"left\", \"right\"]\n",
      "# 0 = up, 1 = down, 2 = left, 3 = right\n",
      "MoveIndex = Literal[0, 1, 2, 3]\n",
      "# 0 = empty, 1 = wall, 2 = start, 3 = end\n",
      "Cell = Literal[0, 1, 2, 3]\n",
      "\n",
      "\n",
      "class Maze:\n",
      "    def __init__(self, maze: List[List[Cell]]):\n",
      "        self.maze = maze\n",
      "        self.rows = len(maze)\n",
      "        self.cols = len(maze[0])\n",
      "        self.start = self.find_start()\n",
      "        self.end = self.find_end()\n",
      "\n",
      "    def find_start(self) -> Tuple[int, int]:\n",
      "        for row in range(self.rows):\n",
      "            for col in range(self.cols):\n",
      "                if self.maze[row][col] == 2:\n",
      "                    return row, col\n",
      "        raise ValueError(\"No start found\")\n",
      "\n",
      "    def find_end(self) -> Tuple[int, int]:\n",
      "        for row in range(self.rows):\n",
      "            for col in range(self.cols):\n",
      "                if self.maze[row][col] == 3:\n",
      "                    return row, col\n",
      "        raise ValueError(\"No end found\")\n",
      "\n",
      "    def get_neighbors(self, row: int, col: int) -> List[Tuple[int, int]]:\n",
      "        neighbors = []\n",
      "        if row > 0 and self.maze[row - 1][col] != 1:\n",
      "            neighbors.append((row - 1, col))\n",
      "        if row < self.rows - 1 and self.maze[row + 1][col] != 1:\n",
      "            neighbors.append((row + 1, col))\n",
      "        if col > 0 and self.maze[row][col - 1] != 1:\n",
      "            neighbors.append((row, col - 1))\n",
      "        if col < self.cols - 1 and self.maze[row][col + 1] != 1:\n",
      "            neighbors.append((row, col + 1))\n",
      "        return neighbors\n",
      "\n",
      "    def solve(self) -> Tuple[int, List[Tuple[int, int]]]:\n",
      "        \"\"\"\n",
      "        Uses UCS to find a path from start to end, returning the number of nodes\n",
      "        expanded and the path if one exists. The cost of each move is 1.\n",
      "        \"\"\"\n",
      "        visited = set()\n",
      "        frontier = PriorityQueue()\n",
      "        frontier.put((0, self.start, []))\n",
      "        expanded = 0\n",
      "\n",
      "        while not frontier.empty():\n",
      "            cost, current, path = frontier.get()\n",
      "\n",
      "            if current in visited:\n",
      "                continue\n",
      "\n",
      "            visited.add(current)\n",
      "            new_path = path + [current]\n",
      "\n",
      "            if current == self.end:\n",
      "                return expanded, new_path\n",
      "\n",
      "            for neighbor in self.get_neighbors(*current):\n",
      "                if neighbor not in visited:\n",
      "                    new_cost = cost + 1\n",
      "                    frontier.put((new_cost, neighbor, new_path))\n",
      "\n",
      "            expanded += 1\n",
      "\n",
      "        return expanded, []\n",
      "## Change requested: Change the `solve` function in the `Maze` class to use A* with manhattan distance as the heuristic instead\n",
      "of using Uniform Cost Search (UCS). The manhattan distance heuristic is \n",
      "mathematically defined as follows: `h(n) = |n.x - goal.x| + |n.y - goal.y|`;\n",
      "Where `n` is the current node and `goal` is the goal node.\n",
      "## Rewrite the code to incorporate the change.\n",
      "\n",
      "### Response:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.4771e-11, 2.2108e-05, 1.1339e-03,  ..., 2.9465e-17,\n",
      "          3.3388e-17, 3.2361e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[1.4771e-11, 2.2108e-05, 1.1339e-03,  ..., 2.9465e-17,\n",
      "          3.3388e-17, 3.2361e-17]],\n",
      "\n",
      "        [[1.2435e-10, 2.2968e-08, 6.3150e-10,  ..., 3.1177e-15,\n",
      "          2.9288e-15, 3.1177e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.0409e-03, 3.7802e-09, 2.0234e-09,  ..., 1.2272e-09,\n",
      "          1.3479e-09, 1.2662e-09]]], device='cuda:0')\n",
      "Sure, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.4898e-11, 6.3968e-08, 4.5428e-11,  ..., 5.3271e-17,\n",
      "          5.8507e-17, 5.6707e-17]]], device='cuda:0')\n",
      "here is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.8012e-13, 1.8107e-09, 4.8254e-11,  ..., 2.8172e-18,\n",
      "          2.9066e-18, 3.0941e-18]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5313e-12, 7.1402e-08, 3.0407e-09,  ..., 3.2514e-18,\n",
      "          3.4611e-18, 3.4611e-18]]], device='cuda:0')\n",
      "updated Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.6017e-12, 2.6878e-10, 1.9860e-09,  ..., 8.3993e-18,\n",
      "          8.6660e-18, 8.9411e-18]],\n",
      "\n",
      "        [[8.8192e-10, 1.6129e-08, 3.9076e-07,  ..., 2.4809e-15,\n",
      "          2.7247e-15, 2.6409e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0406e-13, 9.1317e-10, 1.1125e-08,  ..., 5.0658e-19,\n",
      "          5.3925e-19, 5.0658e-19]]], device='cuda:0')\n",
      "code:\n",
      "\n",
      "```python\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0909e-10, 8.2224e-08, 5.1889e-04,  ..., 2.7082e-16,\n",
      "          2.8829e-16, 2.7082e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 18\n",
      "tensor([[[2.2171e-15, 1.8642e-12, 7.7710e-13,  ..., 3.3523e-19,\n",
      "          3.1988e-19, 3.4587e-19]],\n",
      "\n",
      "        [[1.2902e-20, 2.6665e-11, 7.1702e-15,  ..., 3.9350e-21,\n",
      "          4.2216e-21, 3.8139e-21]],\n",
      "\n",
      "        [[1.0080e-18, 1.0368e-12, 7.8265e-13,  ..., 5.4458e-22,\n",
      "          5.3614e-22, 5.3614e-22]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.7355e-23, 4.9049e-17, 3.4956e-16,  ..., 1.0142e-23,\n",
      "          1.1315e-23, 9.9852e-24]],\n",
      "\n",
      "        [[2.9086e-12, 2.3604e-11, 2.5089e-08,  ..., 3.6669e-17,\n",
      "          3.9034e-17, 3.7833e-17]],\n",
      "\n",
      "        [[9.7650e-13, 1.2520e-09, 7.1937e-06,  ..., 1.4850e-17,\n",
      "          1.6827e-17, 1.5807e-17]]], device='cuda:0')\n",
      "from typing import List, Literal, Tuple\n",
      "from queue import PriorityQueue\n",
      "\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 96\n",
      "tensor([[[8.4135e-15, 6.3318e-09, 5.8718e-04,  ..., 1.6174e-19,\n",
      "          1.7217e-19, 1.6950e-19]],\n",
      "\n",
      "        [[3.0722e-16, 1.5402e-10, 3.4365e-11,  ..., 8.7283e-21,\n",
      "          9.7371e-21, 9.0053e-21]],\n",
      "\n",
      "        [[8.0112e-21, 1.0445e-09, 4.6869e-14,  ..., 1.4141e-21,\n",
      "          1.4589e-21, 1.5053e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.9515e-12, 4.5533e-11, 5.9637e-09,  ..., 1.4827e-17,\n",
      "          1.4827e-17, 1.5298e-17]],\n",
      "\n",
      "        [[8.8485e-13, 6.5284e-09, 2.3474e-05,  ..., 1.6231e-17,\n",
      "          1.7278e-17, 1.6746e-17]],\n",
      "\n",
      "        [[1.2155e-12, 1.7835e-08, 9.1340e-04,  ..., 1.0208e-17,\n",
      "          1.0208e-17, 1.0532e-17]]], device='cuda:0')\n",
      "Move = Literal[\"up\", \"down\", \"left\", \"right\"]\n",
      "# 0 = up, 1 = down, 2 = left, 3 = right\n",
      "MoveIndex = Literal[0, 1, 2, 3]\n",
      "# 0 = empty, 1 = wall, 2 = start, 3 = end\n",
      "Cell = Literal[0, 1, 2, 3]\n",
      "\n",
      "\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 451\n",
      "tensor([[[1.5258e-14, 6.6839e-10, 5.4700e-05,  ..., 1.3221e-19,\n",
      "          1.3221e-19, 1.3221e-19]],\n",
      "\n",
      "        [[2.8511e-18, 1.1575e-12, 8.7373e-13,  ..., 2.3263e-20,\n",
      "          2.2903e-20, 2.5750e-20]],\n",
      "\n",
      "        [[2.1823e-19, 1.0748e-14, 1.4524e-12,  ..., 1.1434e-18,\n",
      "          1.1082e-18, 9.9343e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.3738e-16, 1.3457e-11, 4.6046e-13,  ..., 5.2935e-21,\n",
      "          5.1306e-21, 5.6349e-21]],\n",
      "\n",
      "        [[2.8886e-18, 2.9972e-13, 2.9560e-14,  ..., 4.2978e-19,\n",
      "          4.2147e-19, 3.7706e-19]],\n",
      "\n",
      "        [[8.8998e-13, 8.0911e-10, 4.0283e-11,  ..., 7.7114e-18,\n",
      "          7.7114e-18, 7.7114e-18]]], device='cuda:0')\n",
      "class Maze:\n",
      "    def __init__(self, maze: List[List[Cell]]):\n",
      "        self.maze = maze\n",
      "        self.rows = len(maze)\n",
      "        self.cols = len(maze[0])\n",
      "        self.start = self.find_start()\n",
      "        self.end = self.find_end()\n",
      "\n",
      "    def find_start(self) -> Tuple[int, int]:\n",
      "        for row in range(self.rows):\n",
      "            for col in range(self.cols):\n",
      "                if self.maze[row][col] == 2:\n",
      "                    return row, col\n",
      "        raise ValueError(\"No start found\")\n",
      "\n",
      "    def find_end(self) -> Tuple[int, int]:\n",
      "        for row in range(self.rows):\n",
      "            for col in range(self.cols):\n",
      "                if self.maze[row][col] == 3:\n",
      "                    return row, col\n",
      "        raise ValueError(\"No end found\")\n",
      "\n",
      "    def get_neighbors(self, row: int, col: int) -> List[Tuple[int, int]]:\n",
      "        neighbors = []\n",
      "        if row > 0 and self.maze[row - 1][col] != 1:\n",
      "            neighbors.append((row - 1, col))\n",
      "        if row < self.rows - 1 and self.maze[row + 1][col] != 1:\n",
      "            neighbors.append((row + 1, col))\n",
      "        if col > 0 and self.maze[row][col - 1] != 1:\n",
      "            neighbors.append((row, col - 1))\n",
      "        if col < self.cols - 1 and self.maze[row][col + 1] != 1:\n",
      "            neighbors.append((row, col + 1))\n",
      "        return neighbors\n",
      "\n",
      "    def Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.6942e-13, 1.7381e-12, 2.8656e-12,  ..., 9.6883e-16,\n",
      "          9.0305e-16, 9.2446e-16]],\n",
      "\n",
      "        [[3.8993e-14, 6.6330e-14, 3.5857e-13,  ..., 4.5206e-18,\n",
      "          4.3136e-18, 4.1809e-18]],\n",
      "\n",
      "        [[1.3136e-12, 1.7035e-11, 6.4658e-12,  ..., 8.3273e-18,\n",
      "          8.0711e-18, 7.5821e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1237e-17, 2.9507e-13, 2.2801e-13,  ..., 2.4297e-19,\n",
      "          2.7748e-19, 2.8021e-19]]], device='cuda:0')\n",
      "heuristic(self, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.8447e-12, 2.8129e-12, 2.7693e-12,  ..., 1.1206e-15,\n",
      "          1.0861e-15, 1.1928e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5856e-13, 1.4421e-12, 2.6113e-12,  ..., 9.4321e-18,\n",
      "          8.8606e-18, 1.0040e-17]]], device='cuda:0')\n",
      "a: Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.6582e-12, 5.4913e-11, 3.9779e-12,  ..., 2.5217e-17,\n",
      "          2.6843e-17, 2.6843e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.0064e-15, 2.7046e-13, 1.9592e-14,  ..., 2.2762e-17,\n",
      "          2.2234e-17, 2.0563e-17]],\n",
      "\n",
      "        [[6.6734e-18, 1.3252e-14, 2.7461e-13,  ..., 3.6644e-17,\n",
      "          3.9622e-17, 4.2177e-17]],\n",
      "\n",
      "        [[1.2790e-13, 3.6643e-14, 2.3658e-14,  ..., 1.7164e-18,\n",
      "          1.7709e-18, 1.8271e-18]]], device='cuda:0')\n",
      "Tuple[int, int], Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.3398e-17, 1.4695e-12, 2.0080e-14,  ..., 1.5695e-16,\n",
      "          1.4290e-16, 1.6193e-16]]], device='cuda:0')\n",
      "b: Got scores scores stopping:  torch.Size([1, 32256]) 6\n",
      "tensor([[[3.7345e-18, 7.7403e-16, 1.6742e-15,  ..., 1.0575e-18,\n",
      "          9.6852e-19, 9.2417e-19]],\n",
      "\n",
      "        [[1.8067e-15, 1.7937e-11, 1.5430e-12,  ..., 1.0834e-13,\n",
      "          1.1004e-13, 1.0834e-13]],\n",
      "\n",
      "        [[5.2350e-19, 1.6777e-14, 1.5737e-11,  ..., 1.8244e-15,\n",
      "          1.8244e-15, 1.8244e-15]],\n",
      "\n",
      "        [[2.7951e-16, 3.2258e-11, 1.8777e-12,  ..., 8.3321e-13,\n",
      "          7.8272e-13, 7.5864e-13]],\n",
      "\n",
      "        [[8.0571e-18, 3.8763e-13, 5.8190e-13,  ..., 2.2563e-14,\n",
      "          2.4018e-14, 2.6379e-14]],\n",
      "\n",
      "        [[4.6244e-14, 2.8567e-09, 1.2570e-13,  ..., 1.0557e-18,\n",
      "          1.0232e-18, 1.1238e-18]]], device='cuda:0')\n",
      "Tuple[int, int]) Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[5.2856e-23, 3.2067e-18, 6.8398e-20,  ..., 4.8948e-24,\n",
      "          5.1902e-24, 4.5714e-24]],\n",
      "\n",
      "        [[7.1201e-16, 1.2075e-09, 2.9300e-11,  ..., 3.8991e-20,\n",
      "          4.1506e-20, 4.4183e-20]]], device='cuda:0')\n",
      "-> Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[4.8944e-13, 8.9509e-12, 2.8403e-08,  ..., 3.7425e-18,\n",
      "          3.6274e-18, 3.7425e-18]],\n",
      "\n",
      "        [[2.7963e-16, 4.2753e-11, 1.2744e-07,  ..., 2.2761e-21,\n",
      "          2.3483e-21, 2.2761e-21]]], device='cuda:0')\n",
      "int:\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.9106e-18, 7.8174e-13, 1.2247e-14,  ..., 6.7169e-22,\n",
      "          7.2627e-22, 6.8227e-22]]], device='cuda:0')\n",
      "return Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.2406e-16, 4.2698e-14, 3.9655e-12,  ..., 3.0069e-21,\n",
      "          2.9144e-21, 3.1023e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.3416e-17, 3.4085e-15, 8.6050e-13,  ..., 8.4615e-21,\n",
      "          7.3515e-21, 7.1253e-21]],\n",
      "\n",
      "        [[1.4423e-19, 2.3014e-16, 1.4178e-16,  ..., 2.0414e-21,\n",
      "          2.0735e-21, 2.0255e-21]]], device='cuda:0')\n",
      "abs(a[0] Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5354e-19, 6.4447e-13, 5.2301e-12,  ..., 2.9551e-16,\n",
      "          2.9551e-16, 3.0489e-16]]], device='cuda:0')\n",
      "- Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.8082e-18, 1.9615e-14, 8.9157e-11,  ..., 3.9067e-17,\n",
      "          3.5020e-17, 3.4477e-17]],\n",
      "\n",
      "        [[3.7066e-16, 1.1628e-10, 5.3318e-14,  ..., 7.2550e-18,\n",
      "          7.5440e-18, 6.5543e-18]]], device='cuda:0')\n",
      "b[0]) Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.6237e-24, 8.9103e-15, 2.6339e-15,  ..., 1.4022e-25,\n",
      "          1.5889e-25, 1.6140e-25]]], device='cuda:0')\n",
      "+ Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[6.5715e-20, 4.6000e-15, 1.5538e-11,  ..., 1.0063e-17,\n",
      "          1.0063e-17, 1.0382e-17]],\n",
      "\n",
      "        [[3.2898e-17, 3.0508e-12, 2.1420e-13,  ..., 1.6873e-15,\n",
      "          1.6873e-15, 1.5605e-15]],\n",
      "\n",
      "        [[2.2040e-18, 8.6543e-14, 6.4720e-11,  ..., 2.0587e-17,\n",
      "          1.7886e-17, 1.8744e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0465e-16, 2.9473e-14, 3.4603e-12,  ..., 5.2024e-15,\n",
      "          5.6251e-15, 5.2843e-15]]], device='cuda:0')\n",
      "abs(a[1] - Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[6.7116e-16, 2.4616e-10, 2.9110e-12,  ..., 6.3582e-12,\n",
      "          5.6111e-12, 5.7892e-12]],\n",
      "\n",
      "        [[2.3237e-17, 4.1774e-13, 5.2728e-10,  ..., 3.1400e-15,\n",
      "          2.6858e-15, 2.9498e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[4.4309e-13, 1.3921e-10, 1.1169e-07,  ..., 2.1202e-18,\n",
      "          2.1875e-18, 2.2570e-18]],\n",
      "\n",
      "        [[3.5358e-10, 3.7267e-11, 5.6417e-07,  ..., 2.2414e-15,\n",
      "          2.1725e-15, 2.3860e-15]]], device='cuda:0')\n",
      "b[1])\n",
      "\n",
      "   Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[1.3767e-15, 5.2694e-12, 1.6913e-10,  ..., 1.5803e-20,\n",
      "          1.7907e-20, 1.6822e-20]],\n",
      "\n",
      "        [[8.9227e-14, 4.6949e-11, 7.0478e-11,  ..., 3.3918e-17,\n",
      "          2.9932e-17, 3.2365e-17]]], device='cuda:0')\n",
      " def Got scores scores stopping:  torch.Size([1, 32256]) 27\n",
      "tensor([[[2.4728e-19, 2.9445e-14, 1.0816e-11,  ..., 2.9783e-16,\n",
      "          3.2710e-16, 3.1704e-16]],\n",
      "\n",
      "        [[3.4542e-16, 9.2300e-13, 3.6505e-12,  ..., 7.2709e-15,\n",
      "          7.5017e-15, 7.6198e-15]],\n",
      "\n",
      "        [[3.5635e-18, 2.5231e-15, 2.0445e-11,  ..., 6.5819e-16,\n",
      "          6.7908e-16, 6.7908e-16]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.7972e-16, 1.6748e-11, 3.0675e-13,  ..., 4.6719e-21,\n",
      "          4.5281e-21, 4.9732e-21]],\n",
      "\n",
      "        [[3.3739e-18, 3.5454e-13, 2.8097e-14,  ..., 9.5165e-19,\n",
      "          9.2960e-19, 8.3982e-19]],\n",
      "\n",
      "        [[8.8629e-13, 9.1304e-10, 4.0116e-11,  ..., 1.1174e-17,\n",
      "          1.1174e-17, 1.1174e-17]]], device='cuda:0')\n",
      "solve(self) -> Tuple[int, List[Tuple[int, int]]]:\n",
      "        \"\"\"\n",
      "        Uses Got scores scores stopping:  torch.Size([1, 32256]) 10\n",
      "tensor([[[3.5541e-12, 2.0862e-09, 8.3458e-11,  ..., 2.1165e-17,\n",
      "          2.1165e-17, 2.1837e-17]],\n",
      "\n",
      "        [[5.1907e-13, 3.7119e-09, 1.3387e-11,  ..., 1.9344e-18,\n",
      "          2.1245e-18, 2.0592e-18]],\n",
      "\n",
      "        [[3.3223e-16, 1.2134e-12, 2.2800e-13,  ..., 2.8078e-18,\n",
      "          3.0838e-18, 2.8298e-18]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.7187e-16, 4.1288e-13, 4.1686e-14,  ..., 1.4974e-17,\n",
      "          1.4944e-17, 1.5404e-17]],\n",
      "\n",
      "        [[2.6697e-16, 5.5442e-14, 2.2053e-14,  ..., 7.2550e-18,\n",
      "          7.0043e-18, 6.6836e-18]],\n",
      "\n",
      "        [[1.2257e-10, 7.6588e-08, 7.0536e-10,  ..., 1.4830e-16,\n",
      "          1.5300e-16, 1.5300e-16]]], device='cuda:0')\n",
      "A* with manhattan distance as the heuristic to Got scores scores stopping:  torch.Size([1, 32256]) 51\n",
      "tensor([[[1.0271e-13, 1.2370e-10, 2.8477e-11,  ..., 3.9490e-19,\n",
      "          3.9490e-19, 3.9490e-19]],\n",
      "\n",
      "        [[4.6549e-15, 2.3839e-10, 3.0962e-12,  ..., 8.8097e-20,\n",
      "          8.8097e-20, 9.0893e-20]],\n",
      "\n",
      "        [[1.9610e-12, 3.0980e-10, 3.4759e-11,  ..., 5.6914e-18,\n",
      "          6.2507e-18, 6.4492e-18]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.4195e-18, 8.0208e-13, 1.3644e-12,  ..., 2.4014e-19,\n",
      "          2.3004e-19, 2.5513e-19]],\n",
      "\n",
      "        [[3.4341e-17, 2.3895e-13, 2.6465e-09,  ..., 1.0411e-18,\n",
      "          1.0616e-18, 1.0699e-18]],\n",
      "\n",
      "        [[6.2529e-19, 8.5865e-14, 7.0822e-09,  ..., 2.2238e-20,\n",
      "          2.2632e-20, 2.3000e-20]]], device='cuda:0')\n",
      "find a path from start to end, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1298e-12, 2.1757e-13, 1.3461e-11,  ..., 3.6700e-17,\n",
      "          3.6700e-17, 3.5571e-17]]], device='cuda:0')\n",
      "\n",
      "       Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.7023e-16, 9.5315e-12, 1.1271e-13,  ..., 4.4273e-20,\n",
      "          4.3587e-20, 4.4970e-20]]], device='cuda:0')\n",
      " returning Got scores scores stopping:  torch.Size([1, 32256]) 4\n",
      "tensor([[[8.2702e-17, 3.3314e-11, 3.4372e-11,  ..., 2.7313e-20,\n",
      "          2.9075e-20, 2.7743e-20]],\n",
      "\n",
      "        [[3.0416e-19, 5.5142e-11, 3.3445e-11,  ..., 1.0392e-17,\n",
      "          1.1414e-17, 1.1414e-17]],\n",
      "\n",
      "        [[5.1631e-18, 2.4750e-11, 3.0198e-13,  ..., 8.8145e-20,\n",
      "          9.4197e-20, 9.5494e-20]],\n",
      "\n",
      "        [[1.5270e-14, 3.2925e-09, 5.4908e-11,  ..., 1.9443e-18,\n",
      "          1.9142e-18, 2.1354e-18]]], device='cuda:0')\n",
      "the number of nodes expanded Got scores scores stopping:  torch.Size([1, 32256]) 7\n",
      "tensor([[[1.8035e-13, 8.5062e-11, 1.3045e-11,  ..., 6.7209e-19,\n",
      "          6.5142e-19, 6.5142e-19]],\n",
      "\n",
      "        [[4.9591e-15, 3.7750e-11, 2.1756e-13,  ..., 9.0967e-20,\n",
      "          9.0967e-20, 9.6834e-20]],\n",
      "\n",
      "        [[6.0279e-11, 5.0974e-09, 7.7400e-11,  ..., 1.6957e-16,\n",
      "          1.8623e-16, 1.9824e-16]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2538e-15, 3.5814e-10, 2.0640e-12,  ..., 2.9996e-20,\n",
      "          2.9073e-20, 3.1435e-20]],\n",
      "\n",
      "        [[3.8430e-09, 2.3541e-08, 6.2736e-10,  ..., 2.7333e-15,\n",
      "          2.7333e-15, 2.8201e-15]],\n",
      "\n",
      "        [[2.5532e-12, 3.0752e-09, 7.8527e-09,  ..., 6.3384e-18,\n",
      "          6.7472e-18, 6.5396e-18]]], device='cuda:0')\n",
      "and the path if one exists. Got scores scores stopping:  torch.Size([1, 32256]) 154\n",
      "tensor([[[4.9026e-16, 1.2482e-09, 1.7256e-11,  ..., 1.0514e-20,\n",
      "          1.1729e-20, 1.0848e-20]],\n",
      "\n",
      "        [[1.1197e-13, 8.6080e-09, 1.3485e-10,  ..., 9.4031e-19,\n",
      "          1.0327e-18, 1.0327e-18]],\n",
      "\n",
      "        [[6.8424e-12, 1.6389e-08, 3.8928e-09,  ..., 2.5499e-17,\n",
      "          2.5499e-17, 2.5499e-17]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.5333e-13, 4.5265e-10, 5.9876e-07,  ..., 3.5765e-18,\n",
      "          3.5765e-18, 3.9280e-18]],\n",
      "\n",
      "        [[7.3712e-16, 1.0160e-11, 6.8934e-07,  ..., 1.0148e-19,\n",
      "          1.0803e-19, 1.1321e-19]],\n",
      "\n",
      "        [[3.6340e-12, 9.4655e-10, 1.5919e-07,  ..., 1.3257e-16,\n",
      "          1.3257e-16, 1.4112e-16]]], device='cuda:0')\n",
      "The cost of each move is 1.\n",
      "        \"\"\"\n",
      "        visited = set()\n",
      "        frontier = PriorityQueue()\n",
      "        frontier.put((0, self.start, []))\n",
      "        expanded = 0\n",
      "\n",
      "        while not frontier.empty():\n",
      "            Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.2652e-16, 1.9119e-11, 1.2370e-10,  ..., 1.2094e-17,\n",
      "          1.2576e-17, 1.3180e-17]]], device='cuda:0')\n",
      "_, Got scores scores stopping:  torch.Size([1, 32256]) 51\n",
      "tensor([[[2.6903e-16, 6.3938e-13, 1.8685e-11,  ..., 1.8997e-18,\n",
      "          1.9146e-18, 1.9909e-18]],\n",
      "\n",
      "        [[4.6505e-12, 1.3591e-10, 1.3173e-10,  ..., 4.8605e-17,\n",
      "          5.0148e-17, 4.8605e-17]],\n",
      "\n",
      "        [[1.7709e-18, 4.7065e-12, 3.3244e-12,  ..., 3.8299e-19,\n",
      "          3.7705e-19, 4.1735e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.4872e-19, 2.0961e-14, 1.6128e-10,  ..., 1.2558e-18,\n",
      "          1.2172e-18, 1.2558e-18]],\n",
      "\n",
      "        [[5.7494e-19, 6.7672e-13, 3.3982e-09,  ..., 9.3321e-19,\n",
      "          8.4970e-19, 8.7667e-19]],\n",
      "\n",
      "        [[4.4964e-17, 2.2447e-13, 2.4373e-11,  ..., 1.5808e-20,\n",
      "          1.6057e-20, 1.7092e-20]]], device='cuda:0')\n",
      "current, path = frontier.get()\n",
      "\n",
      "            if current in visited:\n",
      "                continue\n",
      "\n",
      "            visited.add(current)\n",
      "            new_path = path + [current]\n",
      "\n",
      "            if current == self.end:\n",
      "                return Got scores scores stopping:  torch.Size([1, 32256]) 35\n",
      "tensor([[[2.3828e-17, 7.7732e-12, 1.3807e-09,  ..., 4.7660e-18,\n",
      "          4.7660e-18, 4.6556e-18]],\n",
      "\n",
      "        [[6.8391e-18, 4.4623e-13, 2.0430e-13,  ..., 1.9360e-20,\n",
      "          1.9819e-20, 2.2110e-20]],\n",
      "\n",
      "        [[1.6125e-18, 1.4931e-10, 5.5559e-13,  ..., 2.4937e-15,\n",
      "          2.4170e-15, 2.3426e-15]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.8464e-14, 3.7652e-11, 1.1241e-10,  ..., 4.6077e-19,\n",
      "          4.6077e-19, 4.7540e-19]],\n",
      "\n",
      "        [[2.7503e-13, 2.6354e-11, 9.6950e-12,  ..., 3.1570e-18,\n",
      "          2.9657e-18, 3.2572e-18]],\n",
      "\n",
      "        [[4.0627e-12, 1.2495e-08, 8.5030e-10,  ..., 2.8567e-16,\n",
      "          3.1375e-16, 3.1375e-16]]], device='cuda:0')\n",
      "expanded, new_path\n",
      "\n",
      "            for neighbor in self.get_neighbors(*current):\n",
      "                if neighbor not in visited:\n",
      "                    new_cost = Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[4.0766e-19, 4.9797e-13, 5.2187e-13,  ..., 2.0653e-21,\n",
      "          2.3772e-21, 2.1899e-21]],\n",
      "\n",
      "        [[5.3649e-12, 4.8293e-10, 4.3472e-08,  ..., 4.3669e-17,\n",
      "          4.1023e-17, 4.1023e-17]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[3.4270e-18, 1.5807e-14, 7.4181e-13,  ..., 2.4877e-18,\n",
      "          2.4780e-18, 2.3924e-18]],\n",
      "\n",
      "        [[7.4029e-13, 9.3976e-11, 3.7912e-08,  ..., 3.0300e-18,\n",
      "          2.7588e-18, 2.8464e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0383e-18, 8.1299e-14, 1.6777e-14,  ..., 1.6567e-20,\n",
      "          1.4908e-20, 1.6960e-20]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4407e-14, 3.2644e-13, 3.5096e-12,  ..., 6.9317e-19,\n",
      "          6.1172e-19, 6.7184e-19]]], device='cuda:0')\n",
      "self.heuristic(neighbor, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.4455e-17, 1.2910e-12, 1.8971e-11,  ..., 1.9166e-21,\n",
      "          1.5643e-21, 1.6651e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0369e-11, 2.9708e-12, 3.0212e-04,  ..., 7.2194e-17,\n",
      "          7.2194e-17, 6.9973e-17]]], device='cuda:0')\n",
      "self.end) + Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5683e-11, 2.2408e-09, 6.9603e-05,  ..., 1.0188e-16,\n",
      "          9.5711e-17, 1.0188e-16]]], device='cuda:0')\n",
      "1\n",
      "                   Got scores scores stopping:  torch.Size([1, 32256]) 30\n",
      "tensor([[[1.7898e-16, 1.4308e-11, 3.9057e-09,  ..., 6.2320e-19,\n",
      "          6.3302e-19, 6.8714e-19]],\n",
      "\n",
      "        [[3.0062e-19, 7.8186e-14, 3.9933e-14,  ..., 6.3279e-18,\n",
      "          7.8752e-18, 7.3981e-18]],\n",
      "\n",
      "        [[6.1110e-16, 1.3460e-11, 1.4026e-10,  ..., 5.2712e-12,\n",
      "          5.7892e-12, 5.7892e-12]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.0379e-14, 4.2419e-15, 4.8546e-14,  ..., 2.5767e-18,\n",
      "          2.3831e-18, 2.7429e-18]],\n",
      "\n",
      "        [[3.9316e-10, 6.0293e-11, 3.2224e-08,  ..., 3.0063e-15,\n",
      "          3.1018e-15, 3.3018e-15]],\n",
      "\n",
      "        [[1.5366e-07, 3.3949e-09, 2.7237e-06,  ..., 3.4000e-12,\n",
      "          3.5079e-12, 3.7341e-12]]], device='cuda:0')\n",
      " frontier.put((new_cost, neighbor, new_path))\n",
      "\n",
      "            expanded += 1\n",
      "\n",
      "        return expanded, []\n",
      "```\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5566e-03, 2.4911e-06, 1.6760e-05,  ..., 4.4223e-08,\n",
      "          4.5627e-08, 4.8569e-08]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.3646e-11, 2.4120e-09, 3.1326e-11,  ..., 8.2782e-17,\n",
      "          8.0235e-17, 9.0918e-17]]], device='cuda:0')\n",
      "\n",
      "In Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1757e-13, 3.0941e-09, 2.8496e-11,  ..., 7.3824e-19,\n",
      "          7.6168e-19, 7.6168e-19]]], device='cuda:0')\n",
      "this updated Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1449e-11, 2.6654e-08, 1.7959e-10,  ..., 2.8501e-17,\n",
      "          2.8501e-17, 2.9406e-17]]], device='cuda:0')\n",
      "code, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0028e-12, 3.6419e-08, 2.9599e-10,  ..., 5.1082e-18,\n",
      "          5.1082e-18, 5.1082e-18]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[5.1755e-17, 1.0648e-11, 5.0769e-15,  ..., 1.1345e-18,\n",
      "          1.1301e-18, 1.1797e-18]],\n",
      "\n",
      "        [[2.1777e-20, 1.1361e-15, 4.2704e-16,  ..., 1.2505e-20,\n",
      "          1.2312e-20, 1.2026e-20]],\n",
      "\n",
      "        [[1.8295e-14, 8.1746e-08, 2.2734e-11,  ..., 4.5417e-20,\n",
      "          4.0081e-20, 4.4020e-20]]], device='cuda:0')\n",
      "`heuristic` Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.0049e-13, 1.1039e-07, 6.2991e-11,  ..., 1.3113e-18,\n",
      "          1.3958e-18, 1.3529e-18]]], device='cuda:0')\n",
      "method Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5427e-13, 7.5936e-13, 8.2577e-14,  ..., 1.4681e-18,\n",
      "          1.3792e-18, 1.3367e-18]]], device='cuda:0')\n",
      "calculates Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5910e-13, 1.1490e-08, 2.2181e-11,  ..., 1.7156e-18,\n",
      "          1.8263e-18, 1.7701e-18]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[5.5631e-16, 7.8217e-10, 3.4027e-12,  ..., 1.4617e-20,\n",
      "          1.4617e-20, 1.5081e-20]],\n",
      "\n",
      "        [[1.0277e-12, 1.6726e-07, 7.7457e-10,  ..., 4.4775e-18,\n",
      "          4.3398e-18, 4.4775e-18]]], device='cuda:0')\n",
      "manhattan distance between Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1263e-14, 9.4070e-09, 5.9544e-11,  ..., 8.1290e-19,\n",
      "          7.5181e-19, 8.2570e-19]]], device='cuda:0')\n",
      "a Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.6096e-15, 3.0170e-09, 1.3542e-11,  ..., 1.0370e-19,\n",
      "          9.5910e-20, 1.0051e-19]]], device='cuda:0')\n",
      "given node Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.3608e-15, 6.2634e-10, 6.9581e-12,  ..., 2.5969e-20,\n",
      "          2.4396e-20, 2.5170e-20]]], device='cuda:0')\n",
      "and the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.0649e-12, 9.5203e-08, 1.0472e-10,  ..., 2.8269e-17,\n",
      "          2.9167e-17, 3.2033e-17]]], device='cuda:0')\n",
      "end Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.8337e-14, 1.1777e-08, 1.2031e-09,  ..., 9.9205e-20,\n",
      "          9.9205e-20, 1.0895e-19]]], device='cuda:0')\n",
      "node. Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.0182e-12, 1.0196e-08, 3.9534e-10,  ..., 5.5369e-17,\n",
      "          5.3665e-17, 5.7126e-17]]], device='cuda:0')\n",
      "The Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[5.7824e-20, 2.1208e-14, 5.0375e-15,  ..., 1.2748e-22,\n",
      "          1.1163e-22, 1.1163e-22]],\n",
      "\n",
      "        [[2.2446e-13, 1.5381e-07, 1.0587e-10,  ..., 4.6196e-19,\n",
      "          4.2062e-19, 4.7662e-19]],\n",
      "\n",
      "        [[4.8331e-15, 3.7527e-09, 6.0058e-12,  ..., 1.4932e-20,\n",
      "          1.4472e-20, 1.4932e-20]]], device='cuda:0')\n",
      "`solve` method Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1142e-14, 8.2544e-09, 1.6441e-11,  ..., 4.9796e-19,\n",
      "          4.8264e-19, 4.9796e-19]]], device='cuda:0')\n",
      "now uses Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.7737e-14, 3.7253e-09, 1.4756e-11,  ..., 2.1782e-19,\n",
      "          2.3923e-19, 2.3187e-19]]], device='cuda:0')\n",
      "this Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[6.5052e-16, 3.7435e-15, 5.0663e-16,  ..., 1.6995e-19,\n",
      "          1.5474e-19, 1.6217e-19]],\n",
      "\n",
      "        [[7.3306e-12, 2.4762e-08, 2.5841e-10,  ..., 1.5566e-17,\n",
      "          1.5566e-17, 1.6060e-17]]], device='cuda:0')\n",
      "heuristic Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.6738e-12, 1.9960e-10, 3.1581e-11,  ..., 2.2462e-17,\n",
      "          2.0452e-17, 2.1101e-17]]], device='cuda:0')\n",
      "in the Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[2.8693e-10, 1.2464e-09, 5.5307e-10,  ..., 3.7322e-15,\n",
      "          4.0990e-15, 4.0990e-15]],\n",
      "\n",
      "        [[4.6453e-15, 6.0749e-10, 1.9335e-12,  ..., 3.4771e-19,\n",
      "          3.0685e-19, 3.3701e-19]]], device='cuda:0')\n",
      "A* Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3240e-12, 8.3554e-09, 1.5130e-08,  ..., 6.3355e-18,\n",
      "          6.1406e-18, 6.9582e-18]]], device='cuda:0')\n",
      "algorithm. Got scores scores stopping:  torch.Size([1, 32256]) 6\n",
      "tensor([[[5.2946e-12, 1.8452e-08, 5.5720e-10,  ..., 7.4464e-17,\n",
      "          7.4464e-17, 7.6828e-17]],\n",
      "\n",
      "        [[6.1248e-13, 6.3726e-09, 7.5358e-11,  ..., 6.0136e-18,\n",
      "          5.8285e-18, 6.4014e-18]],\n",
      "\n",
      "        [[9.6895e-14, 4.4736e-10, 3.0444e-11,  ..., 1.7227e-18,\n",
      "          1.7227e-18, 1.8338e-18]],\n",
      "\n",
      "        [[1.3471e-14, 3.6149e-09, 5.4347e-12,  ..., 5.7454e-19,\n",
      "          5.8359e-19, 6.5104e-19]],\n",
      "\n",
      "        [[4.7669e-12, 7.4455e-08, 2.3197e-09,  ..., 2.8388e-17,\n",
      "          2.9289e-17, 3.3189e-17]],\n",
      "\n",
      "        [[4.7340e-12, 2.7201e-08, 2.2108e-10,  ..., 3.7348e-17,\n",
      "          3.7348e-17, 4.7956e-17]]], device='cuda:0')\n",
      "The Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.3215e-13, 1.7236e-08, 3.7704e-11,  ..., 1.0835e-17,\n",
      "          1.1355e-17, 1.2667e-17]]], device='cuda:0')\n",
      "priority queue Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7637e-11, 4.4021e-07, 3.1262e-10,  ..., 2.5196e-16,\n",
      "          2.2941e-16, 2.8551e-16]]], device='cuda:0')\n",
      "is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.0286e-12, 1.3553e-08, 5.5940e-10,  ..., 5.0084e-18,\n",
      "          5.0084e-18, 5.5007e-18]]], device='cuda:0')\n",
      "updated to Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3529e-11, 9.5789e-09, 2.1834e-10,  ..., 8.3124e-17,\n",
      "          9.1294e-17, 9.1294e-17]]], device='cuda:0')\n",
      "use the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.4169e-12, 2.7858e-10, 2.8459e-11,  ..., 5.7992e-18,\n",
      "          6.5714e-18, 6.5714e-18]]], device='cuda:0')\n",
      "sum of Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.6910e-12, 3.2410e-09, 4.0799e-11,  ..., 3.8442e-17,\n",
      "          4.0922e-17, 4.2221e-17]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3664e-12, 2.1342e-08, 6.2466e-10,  ..., 1.5685e-17,\n",
      "          1.5203e-17, 1.6697e-17]]], device='cuda:0')\n",
      "cost Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.2018e-15, 4.6979e-11, 1.2790e-13,  ..., 9.6832e-20,\n",
      "          9.3852e-20, 1.0148e-19]]], device='cuda:0')\n",
      "so far Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.6761e-13, 5.8475e-10, 8.6915e-11,  ..., 1.8667e-18,\n",
      "          1.9871e-18, 2.0502e-18]]], device='cuda:0')\n",
      "and the Got scores scores stopping:  torch.Size([1, 32256]) 3\n",
      "tensor([[[1.5039e-14, 5.3849e-13, 7.1747e-14,  ..., 6.1461e-17,\n",
      "          6.2429e-17, 6.5938e-17]],\n",
      "\n",
      "        [[2.6545e-15, 3.9007e-14, 3.4084e-15,  ..., 5.8399e-19,\n",
      "          5.8399e-19, 6.0252e-19]],\n",
      "\n",
      "        [[3.7567e-11, 5.1781e-07, 1.4544e-09,  ..., 1.3569e-16,\n",
      "          1.3152e-16, 1.4000e-16]]], device='cuda:0')\n",
      "heuristic as Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[7.1292e-14, 1.1603e-08, 1.4462e-11,  ..., 1.5530e-18,\n",
      "          1.4819e-18, 1.6275e-18]]], device='cuda:0')\n",
      "the Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.2917e-12, 7.7410e-09, 4.8925e-08,  ..., 1.8080e-17,\n",
      "          1.6462e-17, 1.9246e-17]]], device='cuda:0')\n",
      "priority.\n",
      "<|EOT|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▋                                                                                                                                                                                                 | 3/105 [00:24<14:31,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  8.86834499053657\n",
      "<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\n",
      "### Instruction:\n",
      "## Code Before:\n",
      "class Matrix:\n",
      "\n",
      "    def __init__(self, matrix: list[list[int]]):\n",
      "        self.matrix = matrix\n",
      "\n",
      "    def add(self, other):\n",
      "        result = []\n",
      "        for i in range(len(self.matrix)):\n",
      "            row = []\n",
      "            for j in range(len(self.matrix[0])):\n",
      "                row.append(self.matrix[i][j] + other.matrix[i][j])\n",
      "            result.append(row)\n",
      "        return Matrix(result)\n",
      "    \n",
      "    def subtract(self, other):\n",
      "        result = []\n",
      "        for i in range(len(self.matrix)):\n",
      "            row = []\n",
      "            for j in range(len(self.matrix[0])):\n",
      "                row.append(self.matrix[i][j] - other.matrix[i][j])\n",
      "            result.append(row)\n",
      "        return Matrix(result)\n",
      "\n",
      "    def transpose(self):\n",
      "        result = []\n",
      "        for i in range(len(self.matrix[0])):\n",
      "            row = []\n",
      "            for j in range(len(self.matrix)):\n",
      "                row.append(self.matrix[j][i])\n",
      "            result.append(row)\n",
      "        return Matrix(result)\n",
      "## Change requested: Modify the Matrix class to check that the matrices received are of the same size before subtracting or adding them. This should be done with a helper function 'same_size' that returns true if the matrices have the same dimension.\n",
      "## Rewrite the code to incorporate the change.\n",
      "\n",
      "### Response:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.9126e-12, 1.6711e-05, 6.6750e-04,  ..., 5.4579e-18,\n",
      "          6.1846e-18, 5.6311e-18]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[2.9126e-12, 1.6711e-05, 6.6750e-04,  ..., 5.4579e-18,\n",
      "          6.1846e-18, 5.6311e-18]],\n",
      "\n",
      "        [[1.9909e-10, 4.3419e-07, 1.5028e-10,  ..., 1.1378e-16,\n",
      "          1.2112e-16, 1.1739e-16]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7762e-02, 8.4154e-09, 5.4334e-09,  ..., 2.1277e-09,\n",
      "          2.2650e-09, 2.1277e-09]]], device='cuda:0')\n",
      "Sure, Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.3290e-10, 2.8941e-07, 2.0553e-10,  ..., 1.5082e-16,\n",
      "          1.6055e-16, 1.5561e-16]]], device='cuda:0')\n",
      "here is Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.5192e-13, 1.3899e-09, 2.2466e-11,  ..., 1.9690e-18,\n",
      "          2.0315e-18, 2.1625e-18]]], device='cuda:0')\n",
      "the modified Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.2772e-10, 6.2139e-07, 2.1938e-08,  ..., 4.7117e-16,\n",
      "          5.0156e-16, 5.1748e-16]]], device='cuda:0')\n",
      "code:\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4409e-10, 1.3390e-08, 1.8485e-07,  ..., 1.0357e-15,\n",
      "          1.1025e-15, 1.0685e-15]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1047e-11, 1.1031e-08, 8.1507e-08,  ..., 1.5626e-17,\n",
      "          1.5626e-17, 1.5146e-17]]], device='cuda:0')\n",
      "\n",
      "```python\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.3145e-13, 1.9479e-08, 2.7429e-05,  ..., 3.3668e-19,\n",
      "          3.3668e-19, 3.2632e-19]]], device='cuda:0')\n",
      "class Got scores scores stopping:  torch.Size([1, 32256]) 39\n",
      "tensor([[[2.9748e-16, 5.9071e-13, 1.5563e-12,  ..., 9.5768e-21,\n",
      "          9.7276e-21, 1.0194e-20]],\n",
      "\n",
      "        [[4.1517e-14, 6.1009e-13, 1.3174e-10,  ..., 2.8016e-19,\n",
      "          2.8016e-19, 2.7154e-19]],\n",
      "\n",
      "        [[2.4004e-12, 3.8740e-11, 1.0957e-06,  ..., 6.1481e-18,\n",
      "          6.5446e-18, 6.7524e-18]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.9034e-17, 4.1449e-11, 6.5482e-09,  ..., 1.4699e-21,\n",
      "          1.5647e-21, 1.5166e-21]],\n",
      "\n",
      "        [[7.7635e-17, 3.8156e-13, 5.9596e-09,  ..., 6.3193e-22,\n",
      "          6.5199e-22, 6.9404e-22]],\n",
      "\n",
      "        [[2.9182e-14, 7.9996e-10, 2.3148e-09,  ..., 1.4407e-19,\n",
      "          1.5823e-19, 1.4865e-19]]], device='cuda:0')\n",
      "Matrix:\n",
      "\n",
      "    def __init__(self, matrix: list[list[int]]):\n",
      "        self.matrix = matrix\n",
      "\n",
      "    def Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.7263e-19, 2.5330e-15, 9.5594e-15,  ..., 2.6988e-22,\n",
      "          2.5954e-22, 2.3265e-22]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.2274e-14, 5.3848e-13, 1.4783e-11,  ..., 1.8091e-19,\n",
      "          1.9258e-19, 1.6995e-19]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 6\n",
      "tensor([[[1.7683e-15, 5.0587e-13, 1.6587e-12,  ..., 9.5882e-21,\n",
      "          1.0531e-20, 1.0207e-20]],\n",
      "\n",
      "        [[1.9926e-13, 8.2121e-12, 1.0545e-11,  ..., 1.3873e-18,\n",
      "          1.4768e-18, 1.3873e-18]],\n",
      "\n",
      "        [[6.4272e-13, 7.5776e-09, 3.0314e-10,  ..., 2.8891e-18,\n",
      "          2.8891e-18, 2.8891e-18]],\n",
      "\n",
      "        [[4.0887e-15, 4.8206e-11, 1.0618e-06,  ..., 4.5490e-20,\n",
      "          4.2734e-20, 4.4090e-20]],\n",
      "\n",
      "        [[9.1603e-16, 2.3091e-10, 4.1750e-07,  ..., 4.8141e-21,\n",
      "          4.6660e-21, 5.1246e-21]],\n",
      "\n",
      "        [[9.4371e-14, 9.6116e-09, 1.8527e-08,  ..., 5.2795e-19,\n",
      "          5.6200e-19, 5.6200e-19]]], device='cuda:0')\n",
      "same_size(self, other):\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.6948e-16, 6.0848e-10, 9.7381e-13,  ..., 2.2971e-20,\n",
      "          2.0272e-20, 2.4073e-20]]], device='cuda:0')\n",
      "return Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[1.1548e-17, 3.1034e-15, 1.0709e-12,  ..., 1.2070e-22,\n",
      "          1.1698e-22, 1.2453e-22]],\n",
      "\n",
      "        [[5.1245e-18, 2.3896e-13, 3.1656e-13,  ..., 2.4004e-22,\n",
      "          2.4004e-22, 2.1517e-22]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.1696e-16, 1.8790e-12, 2.5430e-13,  ..., 1.0970e-19,\n",
      "          1.0633e-19, 1.1497e-19]]], device='cuda:0')\n",
      "len(self.matrix) Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.4827e-24, 1.5039e-14, 5.4125e-18,  ..., 2.6244e-26,\n",
      "          2.6606e-26, 2.5737e-26]]], device='cuda:0')\n",
      "== Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.4402e-23, 9.9761e-17, 1.3047e-11,  ..., 3.6755e-20,\n",
      "          3.6755e-20, 3.4529e-20]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.4714e-24, 3.4280e-16, 2.6450e-13,  ..., 8.2954e-23,\n",
      "          7.3207e-23, 7.5531e-23]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.8454e-17, 1.0191e-17, 1.2015e-13,  ..., 5.2950e-21,\n",
      "          5.8154e-21, 5.0525e-21]]], device='cuda:0')\n",
      "len(other.matrix) and Got scores scores stopping:  torch.Size([1, 32256]) 5\n",
      "tensor([[[1.6637e-18, 9.9611e-14, 9.2652e-15,  ..., 4.7096e-21,\n",
      "          4.3898e-21, 4.4939e-21]],\n",
      "\n",
      "        [[5.4012e-19, 1.4069e-16, 8.8782e-13,  ..., 5.2729e-23,\n",
      "          5.0314e-23, 5.7014e-23]],\n",
      "\n",
      "        [[3.2760e-19, 3.6229e-12, 9.4509e-13,  ..., 3.0729e-16,\n",
      "          3.1704e-16, 2.9783e-16]],\n",
      "\n",
      "        [[5.1912e-23, 1.0725e-15, 1.9585e-11,  ..., 1.0308e-19,\n",
      "          9.6838e-20, 9.9912e-20]],\n",
      "\n",
      "        [[1.3481e-14, 7.6696e-12, 2.3391e-12,  ..., 7.1554e-19,\n",
      "          7.6169e-19, 6.8277e-19]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.5363e-15, 2.2193e-11, 9.4509e-13,  ..., 4.0538e-18,\n",
      "          3.9599e-18, 4.4522e-18]]], device='cuda:0')\n",
      "len(self.matrix[0]) Got scores scores stopping:  torch.Size([1, 32256]) 6\n",
      "tensor([[[6.6654e-23, 8.0835e-13, 2.6545e-15,  ..., 2.0562e-25,\n",
      "          1.9620e-25, 2.1465e-25]],\n",
      "\n",
      "        [[1.2505e-20, 5.1677e-14, 6.1980e-13,  ..., 5.3174e-19,\n",
      "          4.8416e-19, 4.8416e-19]],\n",
      "\n",
      "        [[3.6691e-22, 3.1953e-16, 5.4386e-12,  ..., 1.0629e-23,\n",
      "          1.0505e-23, 1.0967e-23]],\n",
      "\n",
      "        [[1.5152e-16, 2.3490e-10, 1.4162e-11,  ..., 1.5662e-17,\n",
      "          1.6607e-17, 1.6096e-17]],\n",
      "\n",
      "        [[3.8659e-22, 4.0162e-15, 6.2111e-12,  ..., 1.4342e-18,\n",
      "          1.3473e-18, 1.3058e-18]],\n",
      "\n",
      "        [[5.0663e-16, 5.0298e-12, 7.0232e-13,  ..., 7.4987e-19,\n",
      "          7.7974e-19, 7.0997e-19]]], device='cuda:0')\n",
      "== Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[9.6361e-14, 9.3255e-11, 2.2628e-12,  ..., 8.4326e-18,\n",
      "          8.5654e-18, 9.2614e-18]]], device='cuda:0')\n",
      "len(other.matrix[0])\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[3.3414e-12, 2.5474e-11, 1.0277e-08,  ..., 3.1798e-17,\n",
      "          2.9871e-17, 3.3849e-17]]], device='cuda:0')\n",
      "\n",
      "   Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[5.0131e-17, 2.6489e-12, 2.0194e-11,  ..., 4.4816e-22,\n",
      "          4.9221e-22, 4.9221e-22]],\n",
      "\n",
      "        [[8.3386e-16, 4.4060e-11, 2.5393e-13,  ..., 2.6845e-20,\n",
      "          2.6845e-20, 2.9483e-20]]], device='cuda:0')\n",
      " def Got scores scores stopping:  torch.Size([1, 32256]) 7\n",
      "tensor([[[4.7266e-23, 1.6286e-17, 1.1712e-14,  ..., 3.7548e-21,\n",
      "          3.9970e-21, 3.8740e-21]],\n",
      "\n",
      "        [[4.9953e-19, 7.7577e-14, 4.9311e-14,  ..., 2.4975e-18,\n",
      "          2.9198e-18, 2.7429e-18]],\n",
      "\n",
      "        [[1.0927e-21, 1.4660e-15, 7.3029e-13,  ..., 1.9177e-21,\n",
      "          2.2421e-21, 2.1731e-21]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0394e-15, 1.2254e-11, 3.6169e-09,  ..., 1.7359e-20,\n",
      "          1.7359e-20, 1.7359e-20]],\n",
      "\n",
      "        [[2.3690e-17, 2.2443e-13, 8.6759e-09,  ..., 3.7170e-22,\n",
      "          3.7170e-22, 3.9567e-22]],\n",
      "\n",
      "        [[1.5649e-14, 3.6331e-11, 5.1745e-10,  ..., 1.2346e-19,\n",
      "          1.3560e-19, 1.2738e-19]]], device='cuda:0')\n",
      "add(self, other):\n",
      "        if Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.9489e-17, 2.5436e-13, 1.5125e-15,  ..., 4.0598e-21,\n",
      "          3.9969e-21, 3.8739e-21]]], device='cuda:0')\n",
      "not Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[8.0065e-25, 8.0959e-16, 2.5140e-13,  ..., 3.8197e-24,\n",
      "          3.5883e-24, 3.5883e-24]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 2\n",
      "tensor([[[2.2060e-25, 1.8415e-18, 6.7259e-15,  ..., 2.6308e-23,\n",
      "          2.6308e-23, 2.3216e-23]],\n",
      "\n",
      "        [[2.1303e-17, 3.5188e-11, 1.0402e-11,  ..., 5.8400e-19,\n",
      "          5.7159e-19, 5.8514e-19]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[5.1669e-14, 4.2771e-11, 4.4635e-13,  ..., 1.0089e-18,\n",
      "          1.0740e-18, 1.0740e-18]]], device='cuda:0')\n",
      "self.same_size(other):\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.4373e-17, 2.1075e-13, 1.2110e-09,  ..., 1.2183e-21,\n",
      "          1.2183e-21, 1.1445e-21]]], device='cuda:0')\n",
      "            Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[6.0829e-20, 6.4731e-09, 7.6663e-14,  ..., 5.1300e-23,\n",
      "          4.8192e-23, 5.7229e-23]]], device='cuda:0')\n",
      "raise Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.9204e-16, 1.5256e-09, 1.0178e-12,  ..., 1.9707e-21,\n",
      "          2.0978e-21, 1.9101e-21]]], device='cuda:0')\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.1417e-15, 6.0417e-14, 1.4953e-13,  ..., 3.5421e-19,\n",
      "          3.0775e-19, 3.1752e-19]]], device='cuda:0')\n",
      "ValueError(\"Matrices Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.1162e-16, 3.7030e-10, 5.0690e-13,  ..., 5.9781e-20,\n",
      "          5.4432e-20, 6.4639e-20]]], device='cuda:0')\n",
      "are not Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[2.5223e-17, 1.3888e-11, 4.1523e-14,  ..., 6.4235e-22,\n",
      "          5.7580e-22, 6.5247e-22]]], device='cuda:0')\n",
      "the same Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[1.0160e-02, 8.1758e-06, 1.2682e-08,  ..., 3.6334e-09,\n",
      "          3.6334e-09, 3.6334e-09]]], device='cuda:0')\n",
      "size\")\n",
      "Got scores scores stopping:  torch.Size([1, 32256]) 1\n",
      "tensor([[[4.2904e-14, 4.3763e-12, 1.1513e-08,  ..., 1.8693e-19,\n",
      "          1.8693e-19, 2.0530e-19]]], device='cuda:0')\n",
      "        Got scores scores stopping:  torch.Size([1, 32256]) 51\n",
      "tensor([[[3.7785e-18, 2.6244e-13, 8.3403e-13,  ..., 8.7301e-21,\n",
      "          1.0367e-20, 9.2931e-21]],\n",
      "\n",
      "        [[1.1433e-18, 1.1464e-13, 6.6447e-17,  ..., 6.8515e-21,\n",
      "          6.3863e-21, 6.6928e-21]],\n",
      "\n",
      "        [[1.4514e-16, 6.4951e-13, 4.2775e-11,  ..., 5.1027e-20,\n",
      "          5.2646e-20, 4.6460e-20]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.4999e-19, 1.9532e-16, 1.6286e-17,  ..., 1.2875e-21,\n",
      "          1.4252e-21, 1.4141e-21]],\n",
      "\n",
      "        [[3.1982e-23, 1.9840e-16, 2.5582e-14,  ..., 9.6431e-22,\n",
      "          1.0106e-21, 9.3465e-22]],\n",
      "\n",
      "        [[9.1877e-19, 1.2937e-15, 3.5167e-15,  ..., 6.3241e-22,\n",
      "          6.4237e-22, 6.1296e-22]]], device='cuda:0')\n",
      "result = []\n",
      "        for i in range(len(self.matrix)):\n",
      "            row = []\n",
      "            for j in range(len(self.matrix[0])):\n",
      "                row.append(self.matrix[i][j] Got scores scores stopping:  torch.Size([1, 32256]) 38\n",
      "tensor([[[3.5753e-22, 1.3169e-14, 9.2848e-14,  ..., 1.8920e-20,\n",
      "          2.0780e-20, 2.0780e-20]],\n",
      "\n",
      "        [[1.1019e-17, 1.9894e-11, 1.6848e-12,  ..., 5.2491e-14,\n",
      "          5.5877e-14, 5.2491e-14]],\n",
      "\n",
      "        [[5.1912e-23, 6.1111e-16, 7.5191e-14,  ..., 6.5151e-19,\n",
      "          6.5151e-19, 6.1203e-19]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.6099e-15, 5.6107e-12, 1.3729e-09,  ..., 9.9901e-20,\n",
      "          9.9901e-20, 9.9901e-20]],\n",
      "\n",
      "        [[2.2966e-17, 1.1761e-12, 1.2237e-08,  ..., 1.0367e-20,\n",
      "          1.0696e-20, 1.1209e-20]],\n",
      "\n",
      "        [[1.4660e-15, 1.5428e-13, 2.8215e-12,  ..., 1.9673e-20,\n",
      "          2.3001e-20, 2.2293e-20]]], device='cuda:0')\n",
      "+ other.matrix[i][j])\n",
      "            result.append(row)\n",
      "        return Matrix(result)\n",
      "    \n",
      "    def subtract(self, other):\n",
      "        if Got scores scores stopping:  torch.Size([1, 32256]) 51\n",
      "tensor([[[3.1128e-21, 2.3895e-13, 1.4806e-14,  ..., 1.2957e-18,\n",
      "          1.4230e-18, 1.3368e-18]],\n",
      "\n",
      "        [[5.6163e-19, 3.8484e-13, 8.8596e-14,  ..., 9.2458e-16,\n",
      "          8.9614e-16, 8.9614e-16]],\n",
      "\n",
      "        [[1.2352e-24, 3.7289e-15, 1.2278e-12,  ..., 1.3000e-22,\n",
      "          1.2600e-22, 1.2600e-22]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2052e-19, 2.2180e-15, 1.9120e-15,  ..., 2.4728e-19,\n",
      "          2.6738e-19, 2.7586e-19]],\n",
      "\n",
      "        [[5.2650e-20, 2.5239e-13, 7.0784e-13,  ..., 9.1877e-19,\n",
      "          1.0091e-18, 9.0453e-19]],\n",
      "\n",
      "        [[2.1530e-18, 3.2917e-13, 9.4310e-14,  ..., 1.3039e-15,\n",
      "          1.4775e-15, 1.5728e-15]]], device='cuda:0')\n",
      "not self.same_size(other):\n",
      "            raise ValueError(\"Matrices are not the same size\")\n",
      "        result = []\n",
      "        for i in range(len(self.matrix)):\n",
      "            row = []\n",
      "            for j in "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▋                                                                                                                                                                                                 | 3/105 [00:27<15:49,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got scores scores stopping:  torch.Size([1, 32256]) 127\n",
      "tensor([[[1.1730e-17, 3.7593e-13, 2.0761e-13,  ..., 1.8321e-13,\n",
      "          1.8321e-13, 1.7758e-13]],\n",
      "\n",
      "        [[6.9270e-27, 1.5942e-16, 4.6687e-14,  ..., 1.9017e-25,\n",
      "          1.6266e-25, 1.6783e-25]],\n",
      "\n",
      "        [[1.0742e-18, 2.0761e-13, 8.3054e-15,  ..., 4.1587e-17,\n",
      "          4.2242e-17, 4.1587e-17]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.8621e-22, 9.5221e-15, 1.0222e-10,  ..., 2.0421e-19,\n",
      "          1.9792e-19, 2.0421e-19]],\n",
      "\n",
      "        [[2.1088e-13, 3.7751e-11, 8.4234e-12,  ..., 1.2683e-17,\n",
      "          1.1915e-17, 1.3501e-17]],\n",
      "\n",
      "        [[1.2253e-11, 2.5684e-12, 2.3350e-09,  ..., 8.5309e-17,\n",
      "          8.2684e-17, 8.8017e-17]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Use this technique\u001b[39;00m\n\u001b[1;32m     32\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 33\u001b[0m test_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# attention_mask=inputs.attention_mask,\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_lookup_num_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mNewlineStoppingCriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTextStreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1919\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1911\u001b[0m             generation_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m     )\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# 13. run assisted generate\u001b[39;00m\n\u001b[0;32m-> 1919\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assisted_decoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mDOLA_GENERATION:\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stateful:\n\u001b[1;32m   1932\u001b[0m         \u001b[38;5;66;03m# DoLa decoding was not designed for stateful models, and would require some changes\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3992\u001b[0m, in \u001b[0;36mGenerationMixin._assisted_decoding\u001b[0;34m(self, input_ids, candidate_generator, logits_processor, logits_warper, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3989\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3990\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m-> 3992\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3994\u001b[0m \u001b[38;5;66;03m# 2.3. Process the new logits\u001b[39;00m\n\u001b[1;32m   3995\u001b[0m new_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39mcandidate_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :]  \u001b[38;5;66;03m# excludes the input prompt if present\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:944\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    932\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    933\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    934\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         position_embeddings,\n\u001b[1;32m    942\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:692\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    691\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    694\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import TextStreamer\n",
    "\n",
    "stats = {\"method\": [], \"assisted\": [], \"pld\": [], \"regular\": [], \"lev_dist\": [], \"generated_tokens\": []}\n",
    "\n",
    "for row in tqdm(ds):\n",
    "    input_text = \"## Code Before:\\n{code_text}\\n## Change requested: {question}\\n## Rewrite the code to incorporate the change.\\n\".format(code_text=row['before'], question=row['instruction_descriptive'])\n",
    "    # inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = tokenizer.apply_chat_template([\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_text\n",
    "        }\n",
    "    ], tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    code_tokens = tokenizer(row['before'], return_tensors=\"pt\")\n",
    "    \n",
    "    max_new_tokens = code_tokens.input_ids.shape[-1] + 500\n",
    "    \n",
    "    two_layer_candidate_generator = TwoLayerLookupCandidateGenerator(\n",
    "        tokenizer,\n",
    "        inputs.shape[-1],\n",
    "        draft_model,\n",
    "        inputs,\n",
    "        code_tokens.input_ids.tolist()[0],\n",
    "        ngram_size=5,\n",
    "        num_pred_tokens=50\n",
    "    )\n",
    "    model._get_candidate_generator = (_get_default_candidate_generator_generator(two_layer_candidate_generator)).__get__(model, type(model))\n",
    "    \n",
    "    # Use this technique\n",
    "    start_time = time.perf_counter()\n",
    "    test_out = model.generate(\n",
    "        inputs=inputs,\n",
    "        # attention_mask=inputs.attention_mask,\n",
    "        prompt_lookup_num_tokens=1,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        stopping_criteria=[NewlineStoppingCriteria(tokenizer, inputs.shape[-1])],\n",
    "        use_cache=True,\n",
    "        streamer=TextStreamer(tokenizer)\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(\"Time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9881114-6ac1-4d97-9a1d-a5693321de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "# stats = {\"method\": [], \"assisted\": [], \"pld\": [], \"regular\": [], \"lev_dist\": [], \"generated_tokens\": []}\n",
    "\n",
    "# for row in tqdm(ds):\n",
    "#     input_text = \"## Code Before:\\n{code_text}\\n## Change requested: {question}\\n## Rewrite the code to incorporate the change.\\n\".format(code_text=row['before'], question=row['instruction_descriptive'])\n",
    "#     # inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "#     inputs = tokenizer.apply_chat_template([\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": input_text\n",
    "#         }\n",
    "#     ], tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "#     code_tokens = tokenizer(row['before'], return_tensors=\"pt\")\n",
    "    \n",
    "#     max_new_tokens = code_tokens.input_ids.shape[-1] + 500\n",
    "\n",
    "#     # Use HuggingFace assisted decoding\n",
    "#     start_time = time.perf_counter()\n",
    "#     assisted_output = model.generate(\n",
    "#         input_ids=inputs,\n",
    "#         max_new_tokens=max_new_tokens,\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_score=True,\n",
    "#         assistant_model=draft_model\n",
    "#     )\n",
    "#     end_time = time.perf_counter()\n",
    "#     stats[\"assisted\"].append(end_time - start_time)\n",
    "\n",
    "#     # Use HuggingFace prompt lookup decoding\n",
    "#     start_time = time.perf_counter()\n",
    "#     pld_output = model.generate(\n",
    "#         input_ids=inputs,\n",
    "#         max_new_tokens=max_new_tokens,\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_score=True,\n",
    "#         prompt_lookup_num_tokens=50\n",
    "#     )\n",
    "#     end_time = time.perf_counter()\n",
    "#     stats[\"pld\"].append(end_time - start_time)\n",
    "\n",
    "#     # Use regular HuggingFace text generation\n",
    "#     start_time = time.perf_counter()\n",
    "#     regular_outputs = model.generate(\n",
    "#         input_ids=inputs,\n",
    "#         max_new_tokens=max_new_tokens,\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_scores=True\n",
    "#     )\n",
    "#     end_time = time.perf_counter()\n",
    "\n",
    "#     stats[\"regular\"].append(end_time - start_time)\n",
    "#     new_text = tokenizer.batch_decode(regular_outputs.sequences)[0]\n",
    "\n",
    "#     lev_dist = Levenshtein.distance(row['before'], new_text) \n",
    "#     stats[\"lev_dist\"].append(lev_dist)\n",
    "\n",
    "#     stats[\"generated_tokens\"].append(regular_outputs.sequences.shape[-1])\n",
    "\n",
    "# print(time_taken)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598b1e-8a2b-4aba-987c-898ee88ce477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
