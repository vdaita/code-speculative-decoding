{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e94e4e-8ca0-462a-9f41-95a2f41a944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers # requires transformers==4.35.2\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1668d6c1-d608-4f91-8741-b33693e83d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.2\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d5aa8-f265-4f79-a801-f5790e977cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c100275b-9db8-432f-bbec-b88c715ac61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "draft_model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "draft_model = AutoModelForCausalLM.from_pretrained(draft_model_name, trust_remote_code=True, device_map=\"cuda:0\", torch_dtype=torch.float16, use_flash_attention_2=True)\n",
    "print(draft_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e27a50-63e6-45c1-88c2-e43d2fa94bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a82d5e852945619001742f276f24f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"nuprl/EditCoder-6.7b-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"cuda:1\", torch_dtype=torch.float16, use_flash_attention_2=True) # , use_flash_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae23079f-d954-4feb-89af-0bd9503fb50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "speedup_txt = \"\"\"\n",
    "from typing import List\n",
    "\n",
    "class Node:\n",
    "    '''Simple node (No duplicate edges between nodes)'''\n",
    "    def __init__(self, id: int, out_edges: List[int]):\n",
    "        uniques = {}\n",
    "        for edge in out_edges:\n",
    "            if edge in uniques.keys():\n",
    "                raise RuntimeError\n",
    "            else:\n",
    "                uniques[edge] = True\n",
    "        self.id = id\n",
    "        self.in_edges = out_edges\n",
    "\n",
    "class Graph:\n",
    "    '''Simple directed graph (No duplicate edges between nodes, no duplicate nodes)'''\n",
    "    def __init__(self, nodes: List[Node]):\n",
    "        uniques = {}\n",
    "        for node in nodes:\n",
    "            if node in uniques:\n",
    "                raise RuntimeError\n",
    "            else:\n",
    "                uniques[node] = True\n",
    "        self.nodes = nodes\n",
    "        \n",
    "    def find_node(self, id: int):\n",
    "        for node in self.nodes:\n",
    "            if node.id == id:\n",
    "                return node\n",
    "    \n",
    "    def topological_sort(self) -> List[Node]:\n",
    "        return self.nodes\n",
    "\"\"\"\n",
    "print(len(tokenizer.encode(speedup_txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac464b9a-caae-41b6-88ce-fbd42fd2bf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be64b3a4-aff3-4330-8e09-e2ff43823861",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE_THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640f2d62-7976-4d26-beb1-08aa01043736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import inspect\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch import nn\n",
    "\n",
    "from transformers.integrations.deepspeed import is_deepspeed_zero3_enabled\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast, Seq2SeqLMOutput\n",
    "from transformers.models.auto import (\n",
    "    MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING,\n",
    "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING,\n",
    "    MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING,\n",
    "    MODEL_FOR_VISION_2_SEQ_MAPPING,\n",
    ")\n",
    "from transformers.utils import ExplicitEnum, ModelOutput, is_accelerate_available, logging\n",
    "from transformers.generation.beam_constraints import DisjunctiveConstraint, PhrasalConstraint\n",
    "from transformers.generation.beam_search import BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n",
    "from transformers.generation.configuration_utils import GenerationConfig\n",
    "from transformers.generation.logits_process import (\n",
    "    EncoderNoRepeatNGramLogitsProcessor,\n",
    "    EncoderRepetitionPenaltyLogitsProcessor,\n",
    "    EpsilonLogitsWarper,\n",
    "    EtaLogitsWarper,\n",
    "    ExponentialDecayLengthPenalty,\n",
    "    ForcedBOSTokenLogitsProcessor,\n",
    "    ForcedEOSTokenLogitsProcessor,\n",
    "    ForceTokensLogitsProcessor,\n",
    "    HammingDiversityLogitsProcessor,\n",
    "    InfNanRemoveLogitsProcessor,\n",
    "    LogitNormalization,\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    MinNewTokensLengthLogitsProcessor,\n",
    "    NoBadWordsLogitsProcessor,\n",
    "    NoRepeatNGramLogitsProcessor,\n",
    "    PrefixConstrainedLogitsProcessor,\n",
    "    RepetitionPenaltyLogitsProcessor,\n",
    "    SequenceBiasLogitsProcessor,\n",
    "    SuppressTokensAtBeginLogitsProcessor,\n",
    "    SuppressTokensLogitsProcessor,\n",
    "    TemperatureLogitsWarper,\n",
    "    TopKLogitsWarper,\n",
    "    TopPLogitsWarper,\n",
    "    TypicalLogitsWarper,\n",
    "    UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
    ")\n",
    "from transformers.generation.stopping_criteria import (\n",
    "    MaxLengthCriteria,\n",
    "    MaxTimeCriteria,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    validate_stopping_criteria,\n",
    ")\n",
    "\n",
    "from transformers.generation.utils import _crop_past_key_values\n",
    "import difflib\n",
    "\n",
    "@dataclass\n",
    "class GreedySearchDecoderOnlyOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Base class for outputs of decoder-only generation models using greedy search.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        sequences (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
    "            The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter\n",
    "            if all batches finished early due to the `eos_token_id`.\n",
    "        scores (`tuple(torch.FloatTensor)` *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`):\n",
    "            Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
    "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
    "            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n",
    "        attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_attentions=True`):\n",
    "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
    "            `torch.FloatTensor` of shape `(batch_size, num_heads, generated_length, sequence_length)`.\n",
    "        hidden_states (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
    "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
    "            `torch.FloatTensor` of shape `(batch_size, generated_length, hidden_size)`.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88cde95-4062-4a4c-8ef2-146c693f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def find_candidate_pred_tokens(input_ids, max_ngram_size=3, num_pred_tokens=10):\n",
    "    input_length = input_ids.size(1)\n",
    "\n",
    "    # Ensure max_ngram_size and num_pred_tokens are valid\n",
    "    if max_ngram_size <= 0 or num_pred_tokens <= 0 or max_ngram_size > input_length:\n",
    "        raise ValueError(\"Invalid max_ngram_size or num_pred_tokens\")\n",
    "\n",
    "    for ngram_size in range(max_ngram_size, 0, -1):\n",
    "        # Extract the last n tokens as our search ngram\n",
    "        ngram = input_ids[0, -ngram_size:].tolist()\n",
    "\n",
    "        # Create sliding windows of size ngram_size\n",
    "        windows = input_ids.unfold(dimension=1, size=ngram_size, step=1)\n",
    "\n",
    "        # Convert ngram to a tensor for comparison\n",
    "        ngram_tensor = torch.tensor(ngram, device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Find where the windows match the ngram\n",
    "        matches = (windows == ngram_tensor).all(dim=2)\n",
    "\n",
    "        # Get the indices of matches\n",
    "        match_indices = matches.nonzero(as_tuple=True)[1]\n",
    "\n",
    "        # Iterate through match indices to find a valid continuation\n",
    "        for idx in match_indices:\n",
    "            start_idx = idx + ngram_size\n",
    "            end_idx = start_idx + num_pred_tokens\n",
    "            # Ensure we don't go beyond the length of input_ids and avoid self-match\n",
    "            # if end_idx <= input_length and start_idx < input_length - ngram_size:\n",
    "            #     return input_ids[0, start_idx:end_idx]\n",
    "            if start_idx < input_length - ngram_size:\n",
    "                return input_ids[0, start_idx:min(end_idx, input_length)]\n",
    "\n",
    "    # If no match is found, return an empty tensor\n",
    "    return torch.tensor([], dtype=torch.long, device=input_ids.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5466bcc-865b-4333-9cae-4d3fa4afd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def find_candidate_pred_tokens_diff(input_ids, code_ids, orig_input_len=0, ngram_size=3, num_pred_tokens=10):\n",
    "    # start_time = time.perf_counter()\n",
    "    input_length = input_ids.size(1)\n",
    "    code_length = len(code_ids)\n",
    "\n",
    "    # Ensure max_ngram_size and num_pred_tokens are valid\n",
    "    if ngram_size <= 0 or ngram_size > input_length:\n",
    "        raise ValueError(\"Invalid max_ngram_size or num_pred_tokens\")\n",
    "\n",
    "    sm = difflib.SequenceMatcher(None, code_ids, input_ids[0, orig_input_len:].tolist())\n",
    "    \n",
    "    deleted = added = changed = same = last_deleted = 0\n",
    "    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "        if tag == 'replace':\n",
    "            changed += i2 - i1\n",
    "        elif tag == 'delete':\n",
    "            deleted += i2 - i1\n",
    "            last_deleted = i2 - i1\n",
    "        elif tag == 'insert':\n",
    "            added += j2 - j1\n",
    "        elif tag == 'equal':\n",
    "            same += i2 - i1\n",
    "    \n",
    "    approx_tokens_original = changed + deleted + same - last_deleted\n",
    "\n",
    "    lookback_start = max(input_length - ngram_size, orig_input_len)\n",
    "    search_ngram = input_ids[0, lookback_start:].tolist()\n",
    "\n",
    "    for ngram_start in range(max(0, approx_tokens_original - ngram_size), len(code_ids)):\n",
    "        # if there is a match, return the entire rest of the tokens.\n",
    "        if ngram_start + len(search_ngram) >= len(code_ids):\n",
    "            break\n",
    "        if search_ngram == code_ids[ngram_start:ngram_start + len(search_ngram)]:\n",
    "            return torch.tensor(code_ids[ngram_start + len(search_ngram):max(ngram_start + len(search_ngram) + num_pred_tokens, len(code_ids))], dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "    # If no match is found, return what the answer would be otherwise\n",
    "    # print(\"Diff searching took: \", time.perf_counter() - start_time)\n",
    "    return find_candidate_pred_tokens(input_ids, ngram_size, num_pred_tokens)\n",
    "    # return torch.tensor([], dtype=torch.long, device=input_ids.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7bc8977-4805-48d6-b1af-d0be832876ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\"\\x1b[31m\", \"\\x1b[32m\", \"\\x1b[34m\", \"\\x1b[35m\"]  # Red, Green, Blue, Magenta\n",
    "UNDERLINE = \"\\x1b[4m\"\n",
    "RESET = \"\\x1b[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4401af4-c003-4a8a-ad08-a19c1a523a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_search_pld(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        logits_processor: Optional[LogitsProcessorList] = None,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[Union[int, List[int]]] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_scores: Optional[bool] = None,\n",
    "        return_dict_in_generate: Optional[bool] = None,\n",
    "        synced_gpus: bool = False,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        draft_matching_window_size = 3,\n",
    "        draft_num_candidate_tokens = 10,\n",
    "        print_output=True,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "\n",
    "        global tokenizer\n",
    "\n",
    "        # init values\n",
    "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
    "        pad_token_id = pad_token_id if pad_token_id is not None else self.generation_config.pad_token_id\n",
    "        eos_token_id = eos_token_id if eos_token_id is not None else self.generation_config.eos_token_id\n",
    "        if isinstance(eos_token_id, int):\n",
    "            eos_token_id = [eos_token_id]\n",
    "        eos_token_id_tensor = torch.tensor(eos_token_id).to(input_ids.device) if eos_token_id is not None else None\n",
    "\n",
    "        # # init attention / hidden states / scores tuples\n",
    "        scores = () if (return_dict_in_generate and output_scores) else None\n",
    "\n",
    "        max_len = stopping_criteria[0].max_length\n",
    "\n",
    "        i = 0\n",
    "        current_color_index = 0\n",
    "\n",
    "        while True:\n",
    "            i += 1\n",
    "            cur_len = input_ids.shape[-1]\n",
    "\n",
    "            candidate_pred_tokens = find_candidate_pred_tokens(input_ids, draft_matching_window_size, draft_num_candidate_tokens)\n",
    "\n",
    "            if len(candidate_pred_tokens) == 0:\n",
    "                candidate_pred_tokens = torch.tensor([100], device=input_ids.device).unsqueeze(0)\n",
    "            else:\n",
    "                candidate_pred_tokens = candidate_pred_tokens.unsqueeze(0)\n",
    "            \n",
    "            candidate_input_ids = torch.cat((input_ids, candidate_pred_tokens), dim=1)\n",
    "            \n",
    "            candidate_length = candidate_input_ids.shape[1] - input_ids.shape[1]\n",
    "\n",
    "            candidate_kwargs = copy.copy(model_kwargs)\n",
    "            candidate_kwargs = self._extend_attention_mask(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "            candidate_kwargs = self._extend_token_type_ids(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "\n",
    "            model_inputs = self.prepare_inputs_for_generation(candidate_input_ids, **candidate_kwargs)\n",
    "            \n",
    "            # prepare model inputs\n",
    "            # model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "\n",
    "            # forward pass to get next token\n",
    "            outputs = self(\n",
    "                **model_inputs,\n",
    "                return_dict=True,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "\n",
    "            new_logits = outputs.logits[:, -candidate_length - 1 :]  # excludes the input prompt if present\n",
    "            selected_tokens = new_logits.argmax(dim=-1)\n",
    "            candidate_new_tokens = candidate_input_ids[:, -candidate_length:]\n",
    "            n_matches = ((~(candidate_new_tokens == selected_tokens[:, :-1])).cumsum(dim=-1) < 1).sum()\n",
    "\n",
    "            \n",
    "            # if last_assistant_token_is_eos and n_matches == candidate_length: # todo: do this earlier somehow\n",
    "            #     n_matches -= 1\n",
    "            \n",
    "            n_matches = min(n_matches, max_len - cur_len - 1)\n",
    "\n",
    "            # print(n_matches)\n",
    "            # i+= n_matches.item()\n",
    "\n",
    "            if print_output:\n",
    "                current_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            if input_ids.shape[-1] > NEWLINE_THRESHOLD: # Check that there are max 5 consecutive newlines.\n",
    "                flag = True\n",
    "                for i in range(NEWLINE_THRESHOLD):\n",
    "                    if not(input_ids[0, -i] == 185): # Is a newline\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    break\n",
    "\n",
    "            \n",
    "            valid_tokens = selected_tokens[:, : n_matches + 1]\n",
    "            input_ids = torch.cat((input_ids, valid_tokens), dim=-1)\n",
    "            new_cur_len = input_ids.shape[-1]\n",
    "\n",
    "            if print_output:\n",
    "                updated_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "                # Find and print the newly added text\n",
    "                if updated_text != current_text:\n",
    "                    new_text = updated_text[len(current_text):]\n",
    "                    if len(valid_tokens[0]) > 1:\n",
    "                        color = COLORS[current_color_index]\n",
    "                        print(f\"{color}{new_text}{RESET}\", end='')\n",
    "                        # Update color for next generation\n",
    "                        current_color_index = (current_color_index + 1) % len(COLORS)\n",
    "                    else:\n",
    "                        print(f\"{new_text}\", end='')\n",
    "\n",
    "            new_cache_size = new_cur_len - 1\n",
    "            outputs.past_key_values = _crop_past_key_values(self, outputs.past_key_values, new_cache_size)\n",
    "\n",
    "        \n",
    "            model_kwargs[\"past_key_values\"] = outputs.past_key_values\n",
    "\n",
    "            # stop if we exceed the maximum length\n",
    "\n",
    "            if (valid_tokens == eos_token_id_tensor.item()).any():\n",
    "                break\n",
    "            \n",
    "            if stopping_criteria(input_ids, scores):\n",
    "                break\n",
    "\n",
    "\n",
    "        if return_dict_in_generate:\n",
    "            return GreedySearchDecoderOnlyOutput(\n",
    "                sequences=input_ids,\n",
    "                scores=scores,\n",
    "                # attentions=decoder_attentions,\n",
    "                # hidden_states=decoder_hidden_states,\n",
    "            )\n",
    "        else:\n",
    "            return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15854661-e128-4d81-b89a-1773d659e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def assistant_greedy_search_pld(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        code_ids,\n",
    "        start_point: int,\n",
    "        logits_processor: Optional[LogitsProcessorList] = None,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[Union[int, List[int]]] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_scores: Optional[bool] = None,\n",
    "        synced_gpus: bool = False,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        prompt_matching_window_size = 3,\n",
    "        prompt_num_candidate_tokens = 10,\n",
    "        draft_num_candidate_rounds = 4,\n",
    "        print_output=True,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "\n",
    "        global tokenizer\n",
    "\n",
    "        # init values\n",
    "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
    "        pad_token_id = pad_token_id if pad_token_id is not None else self.generation_config.pad_token_id\n",
    "        eos_token_id = eos_token_id if eos_token_id is not None else self.generation_config.eos_token_id\n",
    "        if isinstance(eos_token_id, int):\n",
    "            eos_token_id = [eos_token_id]\n",
    "        eos_token_id_tensor = torch.tensor(eos_token_id).to(input_ids.device) if eos_token_id is not None else None\n",
    "\n",
    "        # # init attention / hidden states / scores tuples\n",
    "        # scores = () if (return_dict_in_generate and output_scores) else None\n",
    "        scores = None\n",
    "\n",
    "        max_len = stopping_criteria[0].max_length\n",
    "\n",
    "        i = 0\n",
    "        current_color_index = 0\n",
    "        matching_original = True\n",
    "\n",
    "        input_token_len = input_ids.shape[-1]\n",
    "    \n",
    "        for i in range(draft_num_candidate_rounds):\n",
    "            i += 1\n",
    "            cur_len = input_ids.shape[-1]\n",
    "\n",
    "            candidate_pred_tokens = find_candidate_pred_tokens_diff(input_ids, code_ids, start_point, prompt_matching_window_size, prompt_num_candidate_tokens)\n",
    "\n",
    "            if len(candidate_pred_tokens) == 0:\n",
    "                candidate_pred_tokens = torch.tensor([100], device=input_ids.device).unsqueeze(0)\n",
    "            else:\n",
    "                candidate_pred_tokens = candidate_pred_tokens.unsqueeze(0)\n",
    "            \n",
    "            candidate_input_ids = torch.cat((input_ids, candidate_pred_tokens), dim=1)\n",
    "            \n",
    "            candidate_length = candidate_input_ids.shape[1] - input_ids.shape[1]\n",
    "\n",
    "            candidate_kwargs = copy.copy(model_kwargs)\n",
    "            candidate_kwargs = self._extend_attention_mask(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "            candidate_kwargs = self._extend_token_type_ids(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "\n",
    "            model_inputs = self.prepare_inputs_for_generation(candidate_input_ids, **candidate_kwargs)\n",
    "            \n",
    "            # prepare model inputs\n",
    "            # model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "\n",
    "            # print(model_inputs)\n",
    "\n",
    "            # forward pass to get next token\n",
    "            outputs = self(\n",
    "                **model_inputs,\n",
    "                return_dict=True,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "\n",
    "            new_logits = outputs.logits[:, -candidate_length - 1 :]  # excludes the input prompt if present\n",
    "            selected_tokens = new_logits.argmax(dim=-1)\n",
    "            candidate_new_tokens = candidate_input_ids[:, -candidate_length:]\n",
    "            n_matches = ((~(candidate_new_tokens == selected_tokens[:, :-1])).cumsum(dim=-1) < 1).sum()\n",
    "\n",
    "            \n",
    "            # if last_assistant_token_is_eos and n_matches == candidate_length: # todo: do this earlier somehow\n",
    "            #     n_matches -= 1\n",
    "            \n",
    "            n_matches = min(n_matches, max_len - cur_len - 1)\n",
    "\n",
    "            # print(n_matches)\n",
    "            # i+= n_matches.item()\n",
    "\n",
    "            if print_output:\n",
    "                current_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            valid_tokens = selected_tokens[:, : n_matches + 1]\n",
    "            input_ids = torch.cat((input_ids, valid_tokens), dim=-1)\n",
    "            new_cur_len = input_ids.shape[-1]\n",
    "\n",
    "            if input_ids.shape[-1] > NEWLINE_THRESHOLD: # Check that there are max 5 consecutive newlines.\n",
    "                flag = True\n",
    "                for i in range(NEWLINE_THRESHOLD):\n",
    "                    if not(input_ids[0, -i] == 185): # Is a newline\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    break\n",
    "\n",
    "            if print_output:\n",
    "                updated_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "                # Find and print the newly added text\n",
    "                if updated_text != current_text:\n",
    "                    new_text = updated_text[len(current_text):]\n",
    "                    if len(valid_tokens[0]) > 1:\n",
    "                        color = COLORS[current_color_index]\n",
    "                        print(f\"{color}{new_text}{RESET}\", end='')\n",
    "                        # Update color for next generation\n",
    "                        current_color_index = (current_color_index + 1) % len(COLORS)\n",
    "                    else:\n",
    "                        print(f\"{new_text}\", end='')\n",
    "\n",
    "            new_cache_size = new_cur_len - 1\n",
    "            outputs.past_key_values = _crop_past_key_values(self, outputs.past_key_values, new_cache_size)\n",
    "\n",
    "        \n",
    "            model_kwargs[\"past_key_values\"] = outputs.past_key_values\n",
    "\n",
    "            # stop if we exceed the maximum length\n",
    "\n",
    "            if (valid_tokens == eos_token_id_tensor.item()).any():\n",
    "                break\n",
    "            \n",
    "            if stopping_criteria(input_ids, scores):\n",
    "                break\n",
    "\n",
    "\n",
    "        return input_ids[0, input_token_len:], model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4700d120-8047-4f4e-8f5e-420d34909e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_search_assistant_pld(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        code_ids,\n",
    "        assistant_model: torch.nn.Module,\n",
    "        logits_processor: Optional[LogitsProcessorList] = None,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[Union[int, List[int]]] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_scores: Optional[bool] = None,\n",
    "        return_dict_in_generate: Optional[bool] = None,\n",
    "        synced_gpus: bool = False,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        assistant_prompt_matching_window_size = 3,\n",
    "        assistant_prompt_candidate_tokens = 10,\n",
    "        assistant_draft_candidate_rounds = 4,\n",
    "        max_draft_num_candidate_tokens = 300,\n",
    "        print_output=True,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "\n",
    "        global tokenizer\n",
    "\n",
    "        # init values\n",
    "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
    "        pad_token_id = pad_token_id if pad_token_id is not None else self.generation_config.pad_token_id\n",
    "        eos_token_id = eos_token_id if eos_token_id is not None else self.generation_config.eos_token_id\n",
    "        if isinstance(eos_token_id, int):\n",
    "            eos_token_id = [eos_token_id]\n",
    "        eos_token_id_tensor = torch.tensor(eos_token_id).to(input_ids.device) if eos_token_id is not None else None\n",
    "\n",
    "        # # init attention / hidden states / scores tuples\n",
    "        scores = () if (return_dict_in_generate and output_scores) else None\n",
    "\n",
    "        max_len = stopping_criteria[0].max_length\n",
    "\n",
    "        i = 0\n",
    "        current_color_index = 0\n",
    "\n",
    "        assistant_model_kwargs = {}\n",
    "\n",
    "        generation_start_point = input_ids.shape[-1]\n",
    "\n",
    "        while True:\n",
    "            i += 1\n",
    "            cur_len = input_ids.shape[-1]\n",
    "\n",
    "            \n",
    "            input_ids = input_ids.to(assistant_model.device)\n",
    "            candidate_pred_tokens, assistant_model_kwargs = assistant_model.assistant_greedy_search_pld(input_ids,\n",
    "                    code_ids,\n",
    "                    generation_start_point,\n",
    "                  stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=cur_len + max_draft_num_candidate_tokens)]),\n",
    "                  draft_num_candidate_rounds=assistant_draft_candidate_rounds,\n",
    "                  prompt_matching_window_size=assistant_prompt_matching_window_size,\n",
    "                  prompt_num_candidate_tokens = assistant_prompt_candidate_tokens,\n",
    "                  use_cache=True, \n",
    "                  pad_token_id=tokenizer.pad_token_id,\n",
    "                  eos_token_id=tokenizer.eos_token_id,\n",
    "                    print_output=False\n",
    "            )\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            candidate_pred_tokens = candidate_pred_tokens.to(self.device)\n",
    "\n",
    "            # print(candidate_pred_tokens)\n",
    "            \n",
    "            # candidate_pred_tokens = find_candidate_pred_tokens(input_ids, draft_matching_window_size, draft_num_candidate_tokens)\n",
    "\n",
    "            if len(candidate_pred_tokens) == 0:\n",
    "                candidate_pred_tokens = torch.tensor([100], device=input_ids.device).unsqueeze(0)\n",
    "            else:\n",
    "                candidate_pred_tokens = candidate_pred_tokens.unsqueeze(0)\n",
    "            \n",
    "            candidate_input_ids = torch.cat((input_ids, candidate_pred_tokens), dim=1)\n",
    "            \n",
    "            candidate_length = candidate_input_ids.shape[1] - input_ids.shape[1]\n",
    "\n",
    "            candidate_kwargs = copy.copy(model_kwargs)\n",
    "            candidate_kwargs = self._extend_attention_mask(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "            candidate_kwargs = self._extend_token_type_ids(candidate_kwargs, candidate_input_ids.shape[1])\n",
    "\n",
    "            model_inputs = self.prepare_inputs_for_generation(candidate_input_ids, **candidate_kwargs)\n",
    "            \n",
    "            # prepare model inputs\n",
    "            # model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "\n",
    "            # forward pass to get next token\n",
    "            outputs = self(\n",
    "                **model_inputs,\n",
    "                return_dict=True,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "\n",
    "            new_logits = outputs.logits[:, -candidate_length - 1 :]  # excludes the input prompt if present\n",
    "            selected_tokens = new_logits.argmax(dim=-1)\n",
    "            candidate_new_tokens = candidate_input_ids[:, -candidate_length:]\n",
    "            n_matches = ((~(candidate_new_tokens == selected_tokens[:, :-1])).cumsum(dim=-1) < 1).sum()\n",
    "\n",
    "            \n",
    "            # if last_assistant_token_is_eos and n_matches == candidate_length: # todo: do this earlier somehow\n",
    "            #     n_matches -= 1\n",
    "            \n",
    "            n_matches = min(n_matches, max_len - cur_len - 1)\n",
    "\n",
    "            # print(n_matches)\n",
    "            # i+= n_matches.item()\n",
    "\n",
    "            if print_output:\n",
    "                current_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            valid_tokens = selected_tokens[:, : n_matches + 1]\n",
    "            input_ids = torch.cat((input_ids, valid_tokens), dim=-1)\n",
    "            new_cur_len = input_ids.shape[-1]\n",
    "\n",
    "            if input_ids.shape[-1] > NEWLINE_THRESHOLD: # Check that there are max 5 consecutive newlines.\n",
    "                flag = True\n",
    "                for i in range(NEWLINE_THRESHOLD):\n",
    "                    if not(input_ids[0, -i] == 185): # Is a newline\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    break\n",
    "\n",
    "            if print_output:\n",
    "                updated_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "                # Find and print the newly added text\n",
    "                if updated_text != current_text:\n",
    "                    new_text = updated_text[len(current_text):]\n",
    "                    if len(valid_tokens[0]) > 1:\n",
    "                        color = COLORS[current_color_index]\n",
    "                        print(f\"{color}{new_text}{RESET}\", end='')\n",
    "                        # Update color for next generation\n",
    "                        current_color_index = (current_color_index + 1) % len(COLORS)\n",
    "                    else:\n",
    "                        print(f\"{new_text}\", end='')\n",
    "\n",
    "            new_cache_size = new_cur_len - 1\n",
    "            outputs.past_key_values = _crop_past_key_values(self, outputs.past_key_values, new_cache_size)\n",
    "            # New cache size - 1 because the target model generates another token not yet considered by the drafter/assistant\n",
    "            if \"past_key_values\" in assistant_model_kwargs:\n",
    "                assistant_model_kwargs[\"past_key_values\"] = _crop_past_key_values(assistant_model, assistant_model_kwargs[\"past_key_values\"], new_cache_size - 1) \n",
    "\n",
    "        \n",
    "            model_kwargs[\"past_key_values\"] = outputs.past_key_values\n",
    "\n",
    "            # stop if we exceed the maximum length\n",
    "\n",
    "            if (valid_tokens == eos_token_id_tensor.item()).any():\n",
    "                break\n",
    "            \n",
    "            if stopping_criteria(input_ids, scores):\n",
    "                break\n",
    "\n",
    "\n",
    "        if return_dict_in_generate:\n",
    "            return GreedySearchDecoderOnlyOutput(\n",
    "                sequences=input_ids,\n",
    "                scores=scores,\n",
    "                # attentions=decoder_attentions,\n",
    "                # hidden_states=decoder_hidden_states,\n",
    "            )\n",
    "        else:\n",
    "            return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd3b3c4-7eb8-47f2-9bec-87d0a12bf98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32013, 1202]\n",
      "[32013, 185]\n",
      "[32013, 1672]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"...\"))\n",
    "print(tokenizer.encode(\"\"\"\n",
    "\"\"\"))\n",
    "print(tokenizer.encode(\"##\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575a21f7-2aed-47ab-9f27-7c52a3c506fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_text = \"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average\n",
    "average_throughput = np.mean(tokens_per_sec_arr)\n",
    "print(f\"Average Throughput: {average_throughput} tokens/sec\")\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(tokens_per_sec_arr, bins=20, color='blue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Throughput Values')\n",
    "plt.xlabel('Tokens per Second')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(average_throughput, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(average_throughput*0.9, max(plt.ylim())*0.9, f'Average: {average_throughput:.2f}', color = 'red')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "question = \"Can you please change x axis to start from 0\"\n",
    "prompt = \"[INST] Code:```python\\n{code_text}``` \\n\\n Question: {question} \\n\\n Modified code:[/INST]\".format(code_text=code_text, question=question)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# Move all tensor values in the inputs to GPU\n",
    "for key in inputs:\n",
    "    inputs[key] = inputs[key].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9dcce41-44b2-4260-b844-8348b785d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.greedy_search_assistant_pld = greedy_search_assistant_pld.__get__(model, type(model))\n",
    "model.greedy_search_pld = greedy_search_pld.__get__(model, type(model))\n",
    "# draft_model.greedy_search_pld = greedy_search_pld.__get__(draft_model, type(draft_model))\n",
    "draft_model.assistant_greedy_search_pld = assistant_greedy_search_pld.__get__(draft_model, type(draft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "039203dd-acd3-4e72-855b-f1f780a9d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device:  cuda:1\n",
      "Draft model device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Model device: \", model.device)\n",
    "print(\"Draft model device: \", draft_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebaeb3f8-710f-4813-81f4-df9386f21790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nuprl/CanItEdit\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da1d739d-f4fc-4b71-85b1-508a075ebb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import StoppingCriteriaList, MaxLengthCriteria\n",
    "\n",
    "# Define the variable for max_new_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45ba8f6d-6f73-4929-8ac9-76df5ccd12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 1115.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 76, 774, 285, 220, 476, 264, 420, 745, 430, 580, 356, 1022, 780, 526, 740, 64, 43, 840, 160, 663, 78, 867, 72, 255, 508, 381, 242, 116, 24, 508, 359, 1178, 307, 264, 224, 121, 119, 177, 176, 367, 313, 1943, 523, 1487, 63, 801, 84, 206, 29, 86, 168, 278, 185, 495, 313, 444, 318, 408, 228, 147, 53, 111, 250, 275, 269, 645, 334, 314, 253, 1179, 348, 267, 324, 75, 116, 61, 81, 337, 408, 649, 373, 197, 187, 1157, 612, 343, 253, 686, 1292, 530, 208, 708, 659, 320, 215, 978, 600, 1201, 188, 555, 449, 185, 210, 497]\n",
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "token_count = []\n",
    "for row in tqdm(ds):\n",
    "    token_count.append(len(tokenizer.encode(row['before'])))\n",
    "print(token_count)\n",
    "print(len(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c15603e-a8b4-4122-b00c-9656a71365e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_token_split_graphs(time_dict, token_list):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    np.random.seed(42)\n",
    "    z = np.array(token_list)\n",
    "    x = np.array(time_dict[\"with_assistant\"])\n",
    "    y = np.array(time_dict[\"without_assistant\"])\n",
    "    \n",
    "    # Calculate x/y\n",
    "    ratio = x / y\n",
    "    \n",
    "    # Create masks for the different z ranges\n",
    "    mask_1 = z < 250\n",
    "    mask_2 = (z >= 250) & (z < 500)\n",
    "    mask_3 = (z >= 500) & (z < 1000)\n",
    "    mask_4 = z >= 1000\n",
    "    \n",
    "    # Create histograms\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Histogram for z < 250\n",
    "    axs[0, 0].hist(ratio[mask_1], bins=30, color='blue', edgecolor='black')\n",
    "    axs[0, 0].set_title('token count < 250')\n",
    "    axs[0, 0].set_xlabel('with assistant/without assistant ratio (seconds)')\n",
    "    axs[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Histogram for 250 < z < 500\n",
    "    axs[0, 1].hist(ratio[mask_2], bins=30, color='green', edgecolor='black')\n",
    "    axs[0, 1].set_title('250 < token count < 500')\n",
    "    axs[0, 1].set_xlabel('with assistant/without assistant ratio (seconds)')\n",
    "    axs[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Histogram for 500 < z < 1000\n",
    "    axs[1, 0].hist(ratio[mask_3], bins=30, color='red', edgecolor='black')\n",
    "    axs[1, 0].set_title('500 < token count < 1000')\n",
    "    axs[1, 0].set_xlabel('with assistant/without assistant ratio (seconds)')\n",
    "    axs[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Histogram for z >= 1000\n",
    "    axs[1, 1].hist(ratio[mask_4], bins=30, color='purple', edgecolor='black')\n",
    "    axs[1, 1].set_title('token count >= 1000')\n",
    "    axs[1, 1].set_xlabel('with assistant/without assistant ratio (seconds)')\n",
    "    axs[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Average speedup ratio: \", np.mean(ratio))\n",
    "    print(\"Average time with assistant: \", np.mean(x))\n",
    "    print(\"Average time without assistant: \", np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e28282c5-8c9d-4cfc-8bbe-6d497420be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_tokens = [10, 20, 40, 80, 160, 320]\n",
    "time_taken = {x: {\"with_assistant\": [], \"without_assistant\": []} for x in lookup_tokens}\n",
    "outputs = {x: {\"with_assistant\": [], \"without_assistant\": []} for x in lookup_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9881114-6ac1-4d97-9a1d-a5693321de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 105/105 [15:33<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for lookup tokens:  10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAPeCAYAAADd/6nHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAADQuUlEQVR4nOzdeVwV9f7H8TcgHBABF1xAAXFX3NLK3DW31Eyra4uaZtut7KaZZVamZlcqyzQ1l25pm1pWltfMNZdMc9eyCJdUNHHBFAQFFb6/P/xxrkf2bQ5HXs/H4zxqvvOd73xm5nDm4+fMmXEzxhgBAAAAAAAAFnJ3dgAAAAAAAAAoeShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgHIVPXq1XX77bc7OwwAAADkQYcOHdSwYUNnhwEAuUJRCrgObdy4UWPHjtXZs2edHUqJ4Mz9vXXrVj311FOKiIiQr6+vQkNDdc8992jv3r0Z+j744INyc3PL8KpXr16GvmlpaXrzzTcVHh4ub29vNW7cWPPnz7dikwAAyNL1ft77/fffNXbsWB06dMjydZdEztzfhw4dyvT96ebmpgULFmToHxUVpdtuu01lypRR+fLl9cADD+jUqVMZ+hWX9zKQW6WcHQCAwrdx40aNGzdODz74oMqWLevscK57ztzfb7zxhn766Sf17dtXjRs31vHjxzVt2jQ1a9ZMP//8c4ZvSm02m/7zn/84tAUEBGQY96WXXtLrr7+uRx99VDfddJO+/fZb9evXT25ubrrvvvuKdJsAAMjK9X7e+/333zVu3Dh16NBB1atXt2y9JVVx2N/333+/evTo4dDWsmVLh+mjR4+qXbt2CggI0IQJE5SYmKi33npLv/76q7Zs2SIvLy973+LyXgZyzQC47kycONFIMgcPHsz3GGFhYaZnz56FF9R1rDD2d2Z2796dY5+ffvrJpKSkOLTt3bvX2Gw2079/f4f2QYMGGV9f3xzHPHr0qPH09DRDhgyxt6WlpZm2bduaatWqmcuXL+dyCwAAKFyufN6LiooyFy9ezLbPwoULjSSzZs2afK+nffv2JiIiIt/LlySFsb8zk5tjffDgQSPJTJw4McfxnnjiCePj42MOHz5sb1u5cqWRZGbNmmVvI4eDK+Lne8B1ZuzYsXruueckSeHh4fbLgNMvS758+bLGjx+vmjVrymazqXr16nrxxReVkpKS49gfffSRSpUqZR9fkjZv3qzbbrtNAQEBKl26tNq3b6+ffvopQ0xubm7av3+//WqigIAADR48WOfPn8/Vdm3evFk9evRQuXLl5Ovrq8aNG2vKlCkOfX744Qe1bdtWvr6+Klu2rHr37q2oqCiHPg8++GCm34Slx3g1Nzc3PfXUU/rmm2/UsGFD2Ww2RUREaNmyZQ7LZbe/8+rvv//W1KlT1aRJE7Vr1y7H/q1atXL4dkySateurYiIiAzbni41NVUJCQlZjvntt9/q0qVLevLJJ+1tbm5ueuKJJ3T06FFt2rQpl1sDAEDhcrXzXlJSkubMmaM2bdqofv36SkpKyrLv3Llz1bdvX0lSx44d7TnF2rVr7X3ee+89RUREyGazKTg4WEOGDMnV7QNWrFih0qVL6/7779fly5clSX/88Yf+8Y9/qHz58vL29taNN96oxYsXZ4jJzc1NP/30k4YPH66KFSvK19dXd955Z6Y/HcvMH3/8oXvuuUcVK1aUj4+P6tatq5deesmhz86dO9W9e3f5+/urTJky6tSpk37++WeHPpnlalfHeHXulX5v1A0bNujmm2+Wt7e3atSooY8//thhuZz2d17k5VhntuzFixeznP/VV1/p9ttvV2hoqL2tc+fOqlOnjr744gt7GzkcXBFFKeA6c9ddd+n++++XJL3zzjv65JNP9Mknn6hixYqSpEceeUSvvPKKmjVrpnfeeUft27dXZGRkjpfzzp49W4MHD9YLL7ygiRMnSrpSBGrXrp0SEhI0ZswYTZgwQWfPntWtt96qLVu2ZBjjnnvu0blz5xQZGal77rlHc+fO1bhx43LcppUrV6pdu3b6/fffNXToUL399tvq2LGjlixZYu+zatUqdevWTSdPntTYsWM1fPhwbdy4Ua1bty7QfQI2bNigJ598Uvfdd5/efPNNJScn6+6779bp06cl5by/c8MYo1WrVun+++9XcHCwhg4dqnLlymn69On5itkYoxMnTigwMDDDvPPnz8vf318BAQEqX768hgwZosTERIc+O3fulK+vr+rXr+/QfvPNN9vnAwBQXBTH897mzZv12GOPKSgoSA899JCSk5M1bdo0+fn5ZblMu3bt9PTTT0uSXnzxRXtOkR7X2LFjNWTIEAUHB+vtt9/W3XffrVmzZqlr1666dOlSluMuWbJEd9xxh/r27atPP/1UpUqV0m+//aZbbrlFUVFReuGFF/T222/L19dXffr00aJFizKM8a9//Uu7d+/WmDFj9MQTT+i///2vnnrqqRz3wy+//KIWLVrohx9+0KOPPqopU6aoT58++u9//2vv89tvv6lt27bavXu3nn/+eY0ePVoHDx5Uhw4dtHnz5hzXkZX9+/frH//4h7p06aK3335b5cqV04MPPqjffvtNUs77O7fyc6yvNm7cOJUpU0be3t666aabtGLFCof5f/31l06ePKkbb7wxw7I333yzw/uTHA4uyclXagEoAln9nGzXrl1GknnkkUcc2keMGGEkmR9++MHedvXP96ZMmWLc3NzM+PHj7fPT0tJM7dq1Tbdu3UxaWpq9/fz58yY8PNx06dLF3jZmzBgjyTz00EMO673zzjtNhQoVst2Wy5cvm/DwcBMWFmbOnDnjMO/q9TZt2tRUqlTJnD592t62e/du4+7ubgYOHGhvGzRokAkLC8uwnvQYrybJeHl5mf379zuMKclMnTrV3pbfn+/FxMSYV1991VSvXt1IMiEhIebll192WF9+fPLJJ0aS+eCDDxzaX3jhBTNy5Ejz+eefm/nz55tBgwYZSaZ169bm0qVL9n49e/Y0NWrUyDBuUlKSkWReeOGFAsUHAEBhKi7nvVOnTplJkyaZiIgII8kEBgaaYcOG5ern+Omy+jnZyZMnjZeXl+natatJTU21t0+bNs1IMh9++KG97eqf73311VfG09PTPProow7LderUyTRq1MgkJyfb29LS0kyrVq1M7dq17W1z5swxkkznzp0d8q5nnnnGeHh4mLNnz2a7Pe3atTN+fn4OPztLX1e6Pn36GC8vL3PgwAF727Fjx4yfn59p166dvS2zXO3qGK/Ow8LCwowks379envbyZMnjc1mM88++6y9Lb8/3yuMY3348GHTtWtXM2PGDLN48WIzefJkExoaatzd3c2SJUvs/bZu3WokmY8//jjDGM8995yRZD+O5HBwRRSlgOtQVkWSCRMmGEnm999/d2iPjY01khxO0ulFqTfeeMNIMm+++abDMjt27DCSzEcffWROnTrl8HrkkUeMzWazJz/pScSWLVscxpg0aZKRZOLj47PclvQT8TvvvJNln2PHjhlJ5vnnn88wr1u3biYwMNA+ndeiVI8ePTL09ff3N88884x9Oq9Fqc2bN5vbbrvNuLu7G5vNZu69916zfPlyh2Qxv6Kiooy/v79p2bJlru4b8O9//9tIMvPnz7e33XrrraZ+/foZ+qamphpJZujQoQWOEwCAwlAcznvR0dGmb9++xsvLy3h4eJiePXuaL7/8Msd7CmUmqyLJvHnzjCSzdOlSh/aUlBTj7+9v7r77bntbelFq3rx5plSpUuapp55yKAKdPn3a/mXjtTncuHHjjCRz9OhRY8z/Cj5ffPGFw3q//vprIynbIszJkydz3H+XL182pUuXNvfcc0+Gef/85z+Nu7u7PU/Ma1GqQYMGGfo2btzY3HnnnfbpvBalCvNYZ+b06dOmcuXKpm7duva29evXG0nm888/z9B/9OjRRpL9i1tyOLgifr4HlCCHDx+Wu7u7atWq5dBepUoVlS1bVocPH3ZoX7dunUaOHKmRI0c63EdKkvbt2ydJGjRokCpWrOjw+s9//qOUlBTFx8c7LHP17+AlqVy5cpKkM2fOZBnzgQMHJCnD03Su3S5Jqlu3boZ59evXV1xcXJ5+13+1a2OWrsSdXcw5Wbp0qZYtW6YKFSroq6++0oIFC9S1a1e5uxfsI/n48ePq2bOnAgIC9OWXX8rDwyPHZZ555hm5u7tr1apV9jYfH59M7zGWnJxsnw8AgLMVl/Pexo0btXDhQnl6euqDDz7Q4sWLdffdd8vT0zOPW5S1rHIdLy8v1ahRI0MOd/DgQQ0YMEB33323pk6d6nAvpv3798sYo9GjR2fI4caMGSNJOnnypMN4+cnh/vzzT0nZ53CnTp3S+fPns8zh0tLSdOTIkSyXz05R5HBFfazLly+vwYMHKzo6WkePHpX0v/dfbt6j5HBwRRSlgBIos5tEZiYiIkJ169bVJ598ooMHDzrMS0tLkyRNnDhRK1euzPRVpkwZh2WyShaNMfnYivzJattTU1MzbS+KmB955BG99NJL8vLy0u2336569erpjTfe0LFjx/I9Znx8vLp3766zZ89q2bJlCg4OztVyPj4+qlChgv7++297W1BQkI4fP55hG2NjYyUp12MDAFBUitN5r1evXoqMjFRwcLD9gSqjR4+2f7HmDEFBQWrVqpWWLl2qbdu2OcxLz+FGjBiRZQ537ReY5HBXWHGsQ0JCJMn+Hg0KCpL0v/fj1WJjY1W+fHnZbDZ7X3I4uBqKUsB1KKuTdlhYmNLS0uxXOaU7ceKEzp49q7CwMIf2wMBArVq1Sp6enurUqZND0aRmzZqSJH9/f3Xu3DnTV2F8a5S+nj179mTZJz3u6OjoDPP++OMPBQYGytfXV9KVb8gye0rNtd8w5kVui3zpqlWrptdee02HDx/WkiVLVL9+fb388ssKDQ1Vz5499eWXX2b7BJZrJScnq1evXtq7d6+WLFmiBg0a5HrZc+fOKS4uzuHG7E2bNtX58+czPMUo/WajTZs2zfX4AAAUtuJ23qtQoYJeeOEF7d27V2vXrlX79u319ttvq1atWmrfvr3mzp2b6yu2s8vhpIy5zsWLF3Xw4MEMOZy3t7eWLFmi2rVr67bbbrPf3FuSatSoIUny9PTMMofL7U26s5O+nuxyuIoVK6p06dJZ5nDu7u72Ik361VnX5nFW5nCFeayzkn6FWfp7tGrVqqpYsWKG4qIkbdmyxeH9SQ4HV0RRCrgOpRdgrj1p9+jRQ5I0efJkh/ZJkyZJknr27JlhrGrVqmnVqlW6cOGCunTpYn/qXPPmzVWzZk299dZbGZ5iIynXjwnOSbNmzRQeHq7Jkydn2J70b4GCgoLUtGlTffTRRw599uzZoxUrVti3W7pS5IqPj9cvv/xib4uNjc30STO5ldX+zomHh4d69uypRYsW6ejRo5owYYL279+vvn37Kjg4OMNPJjOTmpqqe++9V5s2bdLChQvVsmXLTPslJyfr3LlzGdrHjx8vY4xuu+02e1vv3r3l6emp9957z95mjNHMmTNVtWpVtWrVKk/bCQBAYSnu57327dvrk08+UWxsrKZPn65z585p8ODBqlKlih566KEcv3TKKqfo3LmzvLy89O677zpcBfPBBx8oPj4+0xwuICBAy5cvV6VKldSlSxf71TyVKlVShw4dNGvWrEyvvimsHK5ixYpq166dPvzwQ8XExDjMS98GDw8Pde3aVd9++63D05JPnDihefPmqU2bNvL395f0vy8q169fb++XlJSkjz76KN8x5jeHkwp+rDPbz3/99Zc+/PBDNW7c2H6FlCTdfffdWrJkicNPGVevXq29e/eqb9++9jZyOLiiUs4OAEDha968uSTppZde0n333SdPT0/16tVLTZo00aBBgzR79mydPXtW7du315YtW/TRRx+pT58+6tixY6bj1apVSytWrFCHDh3UrVs3/fDDD/L399d//vMfde/eXRERERo8eLCqVq2qv/76S2vWrJG/v7/D437zy93dXTNmzFCvXr3UtGlTDR48WEFBQfrjjz/022+/afny5ZKu/Iywe/fuatmypR5++GFduHBBU6dOVUBAgMaOHWsf77777tPIkSN155136umnn9b58+c1Y8YM1alTRzt27MhXjFnt7/REJzcqV66s559/Xs8//7zWr1+vDz74QPPmzdPEiROzXe7ZZ5/V4sWL1atXL/3999/69NNPHeYPGDBA0pX7btxwww26//77Va9ePUnS8uXLtXTpUt12223q3bu3fZlq1app2LBhmjhxoi5duqSbbrpJ33zzjX788Ud99tlnubpnBwAARcFVznsBAQF68skn9eSTT2rnzp36z3/+o3nz5mnSpEny8vLKcrmmTZvKw8NDb7zxhuLj42Wz2XTrrbeqUqVKGjVqlMaNG6fbbrtNd9xxh6Kjo/Xee+/ppptusm/3tQIDA7Vy5Uq1adNGnTt31oYNG1S1alVNnz5dbdq0UaNGjfToo4+qRo0aOnHihDZt2qSjR49q9+7ded7mzLz77rtq06aNmjVrpscee0zh4eE6dOiQvvvuO+3atUuS9Nprr9ljfPLJJ1WqVCnNmjVLKSkpevPNN+1jde3aVaGhoXr44Yf13HPPycPDQx9++KEqVqyYoeiVW9nt79zK77F+/vnndeDAAXXq1EnBwcE6dOiQZs2apaSkJE2ZMsWh74svvqiFCxeqY8eOGjp0qBITEzVx4kQ1atRIgwcPtvcjh4NLsv7e6gCsMH78eFO1alXj7u7u8ESSS5cumXHjxpnw8HDj6elpQkJCzKhRoxweCWzM/56+d7XNmzfbH897/vx5Y4wxO3fuNHfddZepUKGCsdlsJiwszNxzzz1m9erV9uXSn5Zy6tQph/Eye1pKVjZs2GC6dOli/Pz8jK+vr2ncuLGZOnWqQ59Vq1aZ1q1bGx8fH+Pv72969eqV4UmDxhizYsUK07BhQ+Pl5WXq1q1rPv300yyfvjdkyJAMy4eFhZlBgwY5tGW1vwsiMTExxz7t27c3krJ8pTtz5owZMGCAqVWrlildurSx2WwmIiLCTJgwIdMnxqSmppoJEyaYsLAw4+XlZSIiIsynn35a4G0CAKAgXPm8d+HChVw9aff99983NWrUMB4eHhmeDDdt2jRTr1494+npaSpXrmyeeOIJ+5PX0qU/fe9q+/fvN0FBQaZ+/fr2fOzAgQNm4MCBpkqVKsbT09NUrVrV3H777ebLL7+0L5eeq23dutVhvDVr1uT6qXV79uwxd955pylbtqzx9vY2devWNaNHj3bos2PHDtOtWzdTpkwZU7p0adOxY0ezcePGDGNt377dtGjRwnh5eZnQ0FAzadKkLJ++d20em75v2rdv79CW3f7Or9wc63nz5pl27dqZihUrmlKlSpnAwEBz5513mu3bt2faf8+ePaZr166mdOnSpmzZsqZ///7m+PHjGfqRw8HVuBlj4d3pAAAAAAAAAHFPKQAAAAAAADgBRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5Uo5OwCrpaWl6dixY/Lz85Obm5uzwwEAAMWIMUbnzp1TcHCw3N357i475FQAACAruc2pSlxR6tixYwoJCXF2GAAAoBg7cuSIqlWr5uwwijVyKgAAkJOccqoSV5Ty8/OTdGXH+Pv7OzkaAABQnCQkJCgkJMSeLyBr5FQAACAruc2pSlxRKv3ycn9/fxIoAACQKX6OljNyKgAAkJOccipulgAAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOZcsSv31118aMGCAKlSoIB8fHzVq1Ejbtm1zdlgAAADFwvr169WrVy8FBwfLzc1N33zzTZZ9H3/8cbm5uWny5MmWxQcAACC5YFHqzJkzat26tTw9PfX999/r999/19tvv61y5co5OzQAAIBiISkpSU2aNNH06dOz7bdo0SL9/PPPCg4OtigyAACA/ynl7ADy6o033lBISIjmzJljbwsPD3diRAAAAMVL9+7d1b1792z7/PXXX/rXv/6l5cuXq2fPnhZFBgAA8D8ud6XU4sWLdeONN6pv376qVKmSbrjhBr3//vvODgsAAMBlpKWl6YEHHtBzzz2niIgIZ4cDAABKKJe7UurPP//UjBkzNHz4cL344ovaunWrnn76aXl5eWnQoEEZ+qekpCglJcU+nZCQYGW4AHIpJiZGcXFx+Vo2MDBQoaGhhRwRAFy/3njjDZUqVUpPP/10rpcpaTlVQc5LEucmAAByw+WKUmlpabrxxhs1YcIESdINN9ygPXv2aObMmZkWpSIjIzVu3DirwwSQBzExMapbt76Sk8/na3lv79KKjo4i+QeAXNi+fbumTJmiHTt2yM3NLdfLlaScKiYmRnXr1VXyheR8j+Ht463oP6I5NwEAkA2XK0oFBQWpQYMGDm3169fXV199lWn/UaNGafjw4fbphIQEhYSEFGmMAPImLi7u/wtSn0qqn8elo5ScPEBxcXEk/gCQCz/++KNOnjzp8JmZmpqqZ599VpMnT9ahQ4cyXa4k5VRxcXFXClJ3SQrMzwBS8tfJnJsAAMiByxWlWrdurejoaIe2vXv3KiwsLNP+NptNNpvNitAAFFh9Sc2cHQQAXNceeOABde7c2aGtW7dueuCBBzR48OAslyuROVWgJB5MCABAkXG5otQzzzyjVq1aacKECbrnnnu0ZcsWzZ49W7Nnz3Z2aAAAAMVCYmKi9u/fb58+ePCgdu3apfLlyys0NFQVKlRw6O/p6akqVaqobt26VocKAABKMJd7+t5NN92kRYsWaf78+WrYsKHGjx+vyZMnq3///s4ODQAAoFjYtm2bbrjhBt1www2SpOHDh+uGG27QK6+84uTIAAAA/sflrpSSpNtvv1233367s8MAAAAoljp06CBjTK77Z3UfKQAAgKLkcldKAQAAAAAAwPVRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAgOvM+vXr1atXLwUHB8vNzU3ffPONfd6lS5c0cuRINWrUSL6+vgoODtbAgQN17Ngx5wUMAABKJIpSAAAA15mkpCQ1adJE06dPzzDv/Pnz2rFjh0aPHq0dO3bo66+/VnR0tO644w4nRAoAAEqyUs4OAAAAAIWre/fu6t69e6bzAgICtHLlSoe2adOm6eabb1ZMTIxCQ0OtCBEAAIArpQAAAEq6+Ph4ubm5qWzZss4OBQAAlCBcKQUAAFCCJScna+TIkbr//vvl7++fZb+UlBSlpKTYpxMSEqwIDwAAXMe4UgoAAKCEunTpku655x4ZYzRjxoxs+0ZGRiogIMD+CgkJsShKAABwvaIoBQAAUAKlF6QOHz6slStXZnuVlCSNGjVK8fHx9teRI0csihQAAFyv+PkeAABACZNekNq3b5/WrFmjChUq5LiMzWaTzWazIDoAAFBSUJQCAAC4ziQmJmr//v326YMHD2rXrl0qX768goKC9I9//EM7duzQkiVLlJqaquPHj0uSypcvLy8vL2eFDQAAShiKUgAAANeZbdu2qWPHjvbp4cOHS5IGDRqksWPHavHixZKkpk2bOiy3Zs0adejQwaowAQBACedyRamxY8dq3LhxDm1169bVH3/84aSIAAAAipcOHTrIGJPl/OzmAQAAWMXlilKSFBERoVWrVtmnS5Vyyc0AAAAAAAAosVyymlOqVClVqVLF2WEAAAAAAAAgn1yyKLVv3z4FBwfL29tbLVu2VGRkpEJDQzPtm5KSopSUFPt0QkKCVWECsFBUVFS+lw0MDMzyMwQAAAAAUDRcrijVokULzZ07V3Xr1lVsbKzGjRuntm3bas+ePfLz88vQPzIyMsM9qABcT2IluWvAgAH5HsHbu7Sio6MoTAEAAACAhVyuKNW9e3f7/zdu3FgtWrRQWFiYvvjiCz388MMZ+o8aNcr+xBnpypVSISEhlsQKwApnJaVJ+lRS/XwsH6Xk5AGKi4ujKAUAAAAAFnK5otS1ypYtqzp16mj//v2ZzrfZbLLZbBZHBcB69SU1c3YQAAAAAIBccnd2AAWVmJioAwcOKCgoyNmhAAAAAAAAIJdcrig1YsQIrVu3TocOHdLGjRt15513ysPDQ/fff7+zQwMAAAAAAEAuudzP944ePar7779fp0+fVsWKFdWmTRv9/PPPqlixorNDAwAAAAAAQC65XFFqwYIFzg4BAAAAAAAABeRyP98DAAAAAACA66MoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5Uo5OwAAAACgKMTExCguLi7Py0VFRRVBNAAA4FoUpQAAAHDdiYmJUd16dZV8IdnZoQAAgCxQlAIAAMB1Jy4u7kpB6i5JgXlceJ+kNUUQFAAAcEBRCgAAANevQEnBeVwm77/4AwAA+cCNzgEAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAHCdWb9+vXr16qXg4GC5ubnpm2++cZhvjNErr7yioKAg+fj4qHPnztq3b59zggUAACUWRSkAAIDrTFJSkpo0aaLp06dnOv/NN9/Uu+++q5kzZ2rz5s3y9fVVt27dlJycbHGkAACgJCvl7AAAAABQuLp3767u3btnOs8Yo8mTJ+vll19W7969JUkff/yxKleurG+++Ub33XeflaECAIASjCulAAAASpCDBw/q+PHj6ty5s70tICBALVq00KZNm7JcLiUlRQkJCQ4vAACAgqAoBQAAUIIcP35cklS5cmWH9sqVK9vnZSYyMlIBAQH2V0hISJHGCQAArn8UpQAAAJCjUaNGKT4+3v46cuSIs0MCAAAujqIUAABACVKlShVJ0okTJxzaT5w4YZ+XGZvNJn9/f4cXAABAQVCUAgAAKEHCw8NVpUoVrV692t6WkJCgzZs3q2XLlk6MDAAAlDQ8fQ8AAOA6k5iYqP3799unDx48qF27dql8+fIKDQ3VsGHD9Nprr6l27doKDw/X6NGjFRwcrD59+jgvaAAAUOJQlAIAALjObNu2TR07drRPDx8+XJI0aNAgzZ07V88//7ySkpL02GOP6ezZs2rTpo2WLVsmb29vZ4UMAABKIIpSAAAA15kOHTrIGJPlfDc3N7366qt69dVXLYwKAADAEfeUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlnPpotTrr78uNzc3DRs2zNmhAAAAAAAAIA9ctii1detWzZo1S40bN3Z2KAAAAAAAAMgjlyxKJSYmqn///nr//fdVrlw5Z4cDAAAAAACAPHLJotSQIUPUs2dPde7c2dmhAAAAAAAAIB9KOTuAvFqwYIF27NihrVu35qp/SkqKUlJS7NMJCQlFFRpQIDExMYqLi8v38oGBgQoNDS3EiJBbHDsAAAAAyDuXKkodOXJEQ4cO1cqVK+Xt7Z2rZSIjIzVu3LgijgwomJiYGNWtW1/JyefzPYa3d2lFR0dR3LAYxw4AAAAA8selilLbt2/XyZMn1axZM3tbamqq1q9fr2nTpiklJUUeHh4Oy4waNUrDhw+3TyckJCgkJMSymIHciIuL+/+ixqeS6udjhCglJw9QXFwchQ2LcewAAAAAIH9cqijVqVMn/frrrw5tgwcPVr169TRy5MgMBSlJstlsstlsVoUIFFB9Sc1y7IXiiGMHAAAAAHnhUkUpPz8/NWzY0KHN19dXFSpUyNAOAAAAAACA4ssln74HAAAAAAAA1+ZSV0plZu3atc4OAQAAAAAAAHnElVIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDnLilJ//vmnVasCAABwWeRMAACgpLCsKFWrVi117NhRn376qZKTk61aLQAAgEshZwIAACWFZUWpHTt2qHHjxho+fLiqVKmif/7zn9qyZYtVqwcAAHAJ5EwAAKCksKwo1bRpU02ZMkXHjh3Thx9+qNjYWLVp00YNGzbUpEmTdOrUKatCAQAAKLbImQAAQElh+Y3OS5UqpbvuuksLFy7UG2+8of3792vEiBEKCQnRwIEDFRsba3VIAAAAxQ45EwAAuN5ZXpTatm2bnnzySQUFBWnSpEkaMWKEDhw4oJUrV+rYsWPq3bu31SEBAAAUO+RMAADgelfKqhVNmjRJc+bMUXR0tHr06KGPP/5YPXr0kLv7lbpYeHi45s6dq+rVq1sVEgAAQLFDzgQAAEoKy4pSM2bM0EMPPaQHH3xQQUFBmfapVKmSPvjgA6tCAgAAKHbImQAAQElhWVFq3759Ofbx8vLSoEGDLIgGAACgeCJnAgAAJYVl95SaM2eOFi5cmKF94cKF+uijj6wKAwAAoFgjZwIAACWFZUWpyMhIBQYGZmivVKmSJkyYYFUYAAAAxRo5EwAAKCksK0rFxMQoPDw8Q3tYWJhiYmKsCgMAAKBYsypnSk1N1ejRoxUeHi4fHx/VrFlT48ePlzGm0NYBAACQHcvuKVWpUiX98ssvGZ4Us3v3blWoUMGqMAAAAIo1q3KmN954QzNmzNBHH32kiIgIbdu2TYMHD1ZAQICefvrpQlsPAABAViwrSt1///16+umn5efnp3bt2kmS1q1bp6FDh+q+++6zKgwAAIBizaqcaePGjerdu7d69uwpSapevbrmz5+vLVu2FNo6AAAAsmNZUWr8+PE6dOiQOnXqpFKlrqw2LS1NAwcO5P4IAAAA/8+qnKlVq1aaPXu29u7dqzp16mj37t3asGGDJk2alGn/lJQUpaSk2KcTEhIKLRYAAFAyWVaU8vLy0ueff67x48dr9+7d8vHxUaNGjRQWFmZVCAAAAMWeVTnTCy+8oISEBNWrV08eHh5KTU3Vv//9b/Xv3z/T/pGRkRo3blyhxgAAAEo2y4pS6erUqaM6depYvVoAAACXUtQ50xdffKHPPvtM8+bNU0REhHbt2qVhw4YpODhYgwYNytB/1KhRGj58uH06ISFBISEhRRYfAAC4/llWlEpNTdXcuXO1evVqnTx5UmlpaQ7zf/jhB6tCAQAAKLasypmee+45vfDCC/b7VDVq1EiHDx9WZGRkpkUpm80mm81WKOsGAACQLCxKDR06VHPnzlXPnj3VsGFDubm5WbVqAAAAl2FVznT+/Hm5u7s7tHl4eGQoggEAABQVy4pSCxYs0BdffKEePXpYtUoAAACXY1XO1KtXL/373/9WaGioIiIitHPnTk2aNEkPPfRQka4XAAAgnaU3Oq9Vq5ZVqwMAAHBJVuVMU6dO1ejRo/Xkk0/q5MmTCg4O1j//+U+98sorRb5uAAAASXLPuUvhePbZZzVlyhQZY6xaJQAAgMuxKmfy8/PT5MmTdfjwYV24cEEHDhzQa6+9Ji8vryJdLwAAQDrLrpTasGGD1qxZo++//14RERHy9PR0mP/1119bFQoAAECxRc4EAABKCsuKUmXLltWdd95p1eoAAABcEjkTAAAoKSwrSs2ZM8eqVQEAALgsciYAAFBSWHZPKUm6fPmyVq1apVmzZuncuXOSpGPHjikxMdHKMAAAAIo1ciYAAFASWHal1OHDh3XbbbcpJiZGKSkp6tKli/z8/PTGG28oJSVFM2fOtCoUAACAYoucCQAAlBSWXSk1dOhQ3XjjjTpz5ox8fHzs7XfeeadWr15tVRgAAADFGjkTAAAoKSy7UurHH3/Uxo0bMzxmuHr16vrrr7+sCgMAAKBYI2cCAAAlhWVXSqWlpSk1NTVD+9GjR+Xn52dVGAAAAMUaORMAACgpLCtKde3aVZMnT7ZPu7m5KTExUWPGjFGPHj2sCgMAAKBYI2cCAAAlhWU/33v77bfVrVs3NWjQQMnJyerXr5/27dunwMBAzZ8/36owAAAAijVyJgAAUFJYVpSqVq2adu/erQULFuiXX35RYmKiHn74YfXv39/hJp4AAAAlGTkTAAAoKSwrSklSqVKlNGDAACtXCQAA4HLImQAAQElgWVHq448/znb+wIEDLYoEAACg+CJnAgAAJYVlRamhQ4c6TF+6dEnnz5+Xl5eXSpcuTYIFAAAgciYAAFByWPb0vTNnzji8EhMTFR0drTZt2nDTTgAAgP9HzgQAAEoKy4pSmaldu7Zef/31DN8IAgAA4H/ImQAAwPXIqUUp6cqNPI8dO+bsMAAAAIo1ciYAAHC9seyeUosXL3aYNsYoNjZW06ZNU+vWrXM9zowZMzRjxgwdOnRIkhQREaFXXnlF3bt3L8xwAQAAnKKwciYAAIDizrKiVJ8+fRym3dzcVLFiRd166616++23cz1OtWrV9Prrr6t27doyxuijjz5S7969tXPnTkVERBRy1AAAANYqrJwJAACguLOsKJWWllYo4/Tq1cth+t///rdmzJihn3/+maIUAABweYWVMwEAABR3lhWlikJqaqoWLlyopKQktWzZMtM+KSkpSklJsU8nJCRYFR4AAAAKICYmRnFxcflaNioqqpCjAQAAhc2yotTw4cNz3XfSpEnZzv/111/VsmVLJScnq0yZMlq0aJEaNGiQad/IyEiNGzcuT7ECAAA4S2HmTK4sJiZGdevVVfKFZGeHAgAAiohlRamdO3dq586dunTpkurWrStJ2rt3rzw8PNSsWTN7Pzc3txzHqlu3rnbt2qX4+Hh9+eWXGjRokNatW5dpYWrUqFEOyV1CQoJCQkIKYYsAAAAKX2HmTK4sLi7uSkHqLkmB+Rhgn6Q1hRwUAAAoVJYVpXr16iU/Pz999NFHKleunCTpzJkzGjx4sNq2batnn30212N5eXmpVq1akqTmzZtr69atmjJlimbNmpWhr81mk81mK5yNAAAAKGKFmTNdFwIlBedjufz96g8AAFjI3aoVvf3224qMjLQnV5JUrlw5vfbaawV+kkxaWprDfaMAAABcVVHmTAAAAMWJZVdKJSQk6NSpUxnaT506pXPnzuV6nFGjRql79+4KDQ3VuXPnNG/ePK1du1bLly8vzHABAACcorByJgAAgOLOsqLUnXfeqcGDB+vtt9/WzTffLEnavHmznnvuOd111125HufkyZMaOHCgYmNjFRAQoMaNG2v58uXq0qVLUYUOAABgmcLKmQAAAIo7y4pSM2fO1IgRI9SvXz9dunTpyspLldLDDz+siRMn5nqcDz74oKhCBAAAcLrCypkAAACKO8uKUqVLl9Z7772niRMn6sCBA5KkmjVrytfX16oQAAAAij1yJgAAUFJYdqPzdLGxsYqNjVXt2rXl6+srY4zVIQAAABR75EwAAOB6Z1lR6vTp0+rUqZPq1KmjHj16KDY2VpL08MMPl7xHGwMAAGSBnAkAAJQUlhWlnnnmGXl6eiomJkalS5e2t997771atmyZVWEAAAAUa+RMAACgpLDsnlIrVqzQ8uXLVa1aNYf22rVr6/Dhw1aFAQAAUKyRMwEAgJLCsiulkpKSHL7tS/f333/LZrNZFQYAAECxRs4EAABKCsuKUm3bttXHH39sn3Zzc1NaWprefPNNdezY0aowAAAAijVyJgAAUFJY9vO9N998U506ddK2bdt08eJFPf/88/rtt9/0999/66effrIqDAAAgGKNnAkAAJQUll0p1bBhQ+3du1dt2rRR7969lZSUpLvuuks7d+5UzZo1rQoDAACgWCNnAgAAJYUlV0pdunRJt912m2bOnKmXXnrJilUCAAC4HHImAABQklhypZSnp6d++eUXK1YFAADgssiZAABASWLZz/cGDBigDz74wKrVAQAAuCRyJgAAUFJYdqPzy5cv68MPP9SqVavUvHlz+fr6OsyfNGmSVaEAAAAUW+RMAACgpCjyotSff/6p6tWra8+ePWrWrJkkae/evQ593NzcijoMAACAYo2cCQAAlDRFXpSqXbu2YmNjtWbNGknSvffeq3fffVeVK1cu6lUDAAC4DHImAABQ0hT5PaWMMQ7T33//vZKSkop6tQAAAC6FnAkAAJQ0lt3oPN21CRcAAAAyImcCAADXuyIvSrm5uWW4/wH3QwAAAHDkjJzpr7/+0oABA1ShQgX5+PioUaNG2rZtW5GuEwAAIF2R31PKGKMHH3xQNptNkpScnKzHH388w5Nkvv7666IOBQAAoNiyOmc6c+aMWrdurY4dO+r7779XxYoVtW/fPpUrV65QxgcAAMhJkRelBg0a5DA9YMCAol4lAACAy7E6Z3rjjTcUEhKiOXPm2NvCw8OLdJ0AAABXK/Ki1NWJDgAAADJndc60ePFidevWTX379tW6detUtWpVPfnkk3r00Ucz7Z+SkqKUlBT7dEJCglWhAgCA65TlNzoHAACA8/3555+aMWOGateureXLl+uJJ57Q008/rY8++ijT/pGRkQoICLC/QkJCLI4YAABcbyhKAQAAlEBpaWlq1qyZJkyYoBtuuEGPPfaYHn30Uc2cOTPT/qNGjVJ8fLz9deTIEYsjBgAA1xuKUgAAACVQUFCQGjRo4NBWv359xcTEZNrfZrPJ39/f4QUAAFAQFKUAAABKoNatWys6Otqhbe/evQoLC3NSRAAAoKShKAUAAFACPfPMM/r55581YcIE7d+/X/PmzdPs2bM1ZMgQZ4cGAABKCIpSAAAAJdBNN92kRYsWaf78+WrYsKHGjx+vyZMnq3///s4ODQAAlBClnB0AAAAAnOP222/X7bff7uwwAABACcWVUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYzuWKUpGRkbrpppvk5+enSpUqqU+fPoqOjnZ2WAAAAAAAAMgDlytKrVu3TkOGDNHPP/+slStX6tKlS+ratauSkpKcHRoAAAAAAAByqZSzA8irZcuWOUzPnTtXlSpV0vbt29WuXTsnRQUAAAAAAIC8cLmi1LXi4+MlSeXLl890fkpKilJSUuzTCQkJlsRVUsXExCguLi7fywcGBio0NLQQI8qbgsTv7NgLqqDHLiUlRTabLV/LRkVF5Xu914uC7ANXf+8BAAAAKJlcuiiVlpamYcOGqXXr1mrYsGGmfSIjIzVu3DiLIyuZYmJiVLdufSUnn8/3GN7epRUdHeWUf2AXNH5nxl5QhXHsJA9JqYUVUgkSK8ldAwYMyPcIrvzeAwAAAFByuXRRasiQIdqzZ482bNiQZZ9Ro0Zp+PDh9umEhASFhIRYEV6JExcX9/9FjU8l1c/HCFFKTh6guLg4p/zjumDxOzf2gir4sVsqaXQhLF8SnZWUJlf9uwEAAACA/HLZotRTTz2lJUuWaP369apWrVqW/Ww2W75/UoT8qi+pmbODKABXj78g8rvt6T89K+jyJVlJft8BAAAAKIlcrihljNG//vUvLVq0SGvXrlV4eLizQwIAAAAAAEAeuVxRasiQIZo3b56+/fZb+fn56fjx45KkgIAA+fj4ODk6AAAAAAAA5Ia7swPIqxkzZig+Pl4dOnRQUFCQ/fX55587OzQAAAAAAADkkstdKWWMcXYIAAAAAAAAKCCXu1IKAAAAAAAAro+iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAgBLu9ddfl5ubm4YNG+bsUAAAQAlCUQoAAKAE27p1q2bNmqXGjRs7OxQAAFDCUJQCAAAooRITE9W/f3+9//77KleunLPDAQAAJQxFKQAAgBJqyJAh6tmzpzp37pxj35SUFCUkJDi8AAAACqKUswMAAACA9RYsWKAdO3Zo69atueofGRmpcePGFXFUAACgJOFKKQAAgBLmyJEjGjp0qD777DN5e3vnaplRo0YpPj7e/jpy5EgRRwkAAK53XCkFAABQwmzfvl0nT55Us2bN7G2pqalav369pk2bppSUFHl4eDgsY7PZZLPZrA4VAABcxyhKAQAAlDCdOnXSr7/+6tA2ePBg1atXTyNHjsxQkAIAACgKFKUAAABKGD8/PzVs2NChzdfXVxUqVMjQDgAAUFS4pxQAAAAAAAAsx5VSAAAA0Nq1a50dAgAAKGG4UgoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlXK4otX79evXq1UvBwcFyc3PTN9984+yQAAAAAAAAkEcuV5RKSkpSkyZNNH36dGeHAgAAAAAAgHwq5ewA8qp79+7q3r27s8MAAAAAAABAAbjclVIAAAAAAABwfS53pVRepaSkKCUlxT6dkJBQ5OuMiYlRXFxcvpdPSUmRzWbL9/KBgYEKDQ3N17IFiT0qKipfy11P8rsPCmvfOXv9cD0F/bwqyOdNYazfmZ+XKJiCHHuOGwAAwPXhui9KRUZGaty4cZatLyYmRnXr1ldy8vkCjOIhKTXfS3t7l1Z0dFSeE/bCib2kipXkrgEDBpTQ9cMVFcbffH4/bwpr/c76vETBFPTYc9wAAACuD9d9UWrUqFEaPny4fTohIUEhISFFtr64uLj/T7I/lVQ/HyMslTS6AMtHKTl5gOLi4vKcrBde7CXRWUlpct6+c/b64YoK/jef/8+bwlm/8z4vUTAFO/YcNwAAgOvFdV+UstlsBfppR/7Vl9QsH8ul/4wqv8sXhoLGXpI5e985e/1wTc78vCnI+ovD5yUKhmMHAABQkrlcUSoxMVH79++3Tx88eFC7du1S+fLl+cYUAAAAAADARbhcUWrbtm3q2LGjfTr9p3mDBg3S3LlznRQVAAAAAAAA8sLd2QHkVYcOHWSMyfCiIAUAAJB7kZGRuummm+Tn56dKlSqpT58+io6OdnZYAACgBHG5ohQAAAAKbt26dRoyZIh+/vlnrVy5UpcuXVLXrl2VlJTk7NAAAEAJ4XI/3wMAAEDBLVu2zGF67ty5qlSpkrZv36527do5KSoAAFCSUJQCAACA4uPjJUnly5fPdH5KSopSUlLs0wkJCZbE5cqiovL/dNvAwEAe4gMAuO5RlAIAACjh0tLSNGzYMLVu3VoNGzbMtE9kZKTGjRtncWQuKlGSmzRgwIB8D+Ht463oP6IpTAEArmsUpQAAAEq4IUOGaM+ePdqwYUOWfUaNGmV/6rF05UqpkJAQK8JzPcmSjKS7JAXmY/k4KfnrZMXFxVGUAgBc1yhKAQAAlGBPPfWUlixZovXr16tatWpZ9rPZbLLZbBZGdh0IlBTs7CAAACi+KEoBAACUQMYY/etf/9KiRYu0du1ahYeHOzskAABQwlCUAgAAKIGGDBmiefPm6dtvv5Wfn5+OHz8uSQoICJCPj4+TowMAACWBu7MDAAAAgPVmzJih+Ph4dejQQUFBQfbX559/7uzQAABACcGVUgAAACWQMcbZIQAAgBKOK6UAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxXytkBAAAAAMgoKioq38sGBgYqNDS0EKMBABQ3MTExiouLy/fyxeFcQVEKAAAAKE4SJblJAwYMyPcQ3j7eiv4j2un/2AAAFI2YmBjVrVdXyReS8z1GcThXUJQCAAAAipNkSUbSXZIC87F8nJT8dbLi4uIoSgHAdSouLu5KQcrFzxUUpQAAAIDiKFBSsLODAAAUay5+ruBG5wAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMu5bFFq+vTpql69ury9vdWiRQtt2bLF2SEBAAC4HHIqAADgLC5ZlPr88881fPhwjRkzRjt27FCTJk3UrVs3nTx50tmhAQAAuAxyKgAA4EwuWZSaNGmSHn30UQ0ePFgNGjTQzJkzVbp0aX344YfODg0AAMBlkFMBAABnKuXsAPLq4sWL2r59u0aNGmVvc3d3V+fOnbVp06YM/VNSUpSSkmKfjo+PlyQlJCQUSXyJiYn//3/bJSVm1zULUQVcPvrK0tu3XxVLLpeMji7gup0Xezp3d3elpaXla9mCbX9Bt53l87+8c993rvx3U/DYS+6+kwr2eVPSly/Ysb+ybGJiYpGcy9PHNMYU+tjFjcvkVLGSLuZjgFPK//IFWbY4LH/6yn+clVMVdHlX/nxz9vKuHLuzl3fl2F19eVeO3ZnL2/OpAp4rnJ5TGRfz119/GUlm48aNDu3PPfecufnmmzP0HzNmjJHEixcvXrx48eKV69eRI0esSm2chpyKFy9evHjx4lXUr5xyKpe7UiqvRo0apeHDh9un09LS9Pfff6tChQpyc3NzYmQFk5CQoJCQEB05ckT+/v7ODue6w/4tWuzfosX+LVrs36Ll7P1rjNG5c+cUHBxs+bqLu+s1p3Jlzv57QdY4NsUTx6X44tgUTwU5LrnNqVyuKBUYGCgPDw+dOHHCof3EiROqUqVKhv42m002m82hrWzZskUZoqX8/f35oy1C7N+ixf4tWuzfosX+LVrO3L8BAQFOWa/VyKmuH3weFV8cm+KJ41J8cWyKp/wel9zkVC53o3MvLy81b95cq1evtrelpaVp9erVatmypRMjAwAAcB3kVAAAwNlc7kopSRo+fLgGDRqkG2+8UTfffLMmT56spKQkDR482NmhAQAAuAxyKgAA4EwuWZS69957derUKb3yyis6fvy4mjZtqmXLlqly5crODs0yNptNY8aMyXAZPQoH+7dosX+LFvu3aLF/ixb711rkVK6Nv5fii2NTPHFcii+OTfFkxXFxM6YEPPMYAAAAAAAAxYrL3VMKAAAAAAAAro+iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUKsamT5+u6tWry9vbWy1atNCWLVtytdyCBQvk5uamPn36FG2ALi6v+/fs2bMaMmSIgoKCZLPZVKdOHS1dutSiaF1PXvfv5MmTVbduXfn4+CgkJETPPPOMkpOTLYrWdaxfv169evVScHCw3Nzc9M033+S4zNq1a9WsWTPZbDbVqlVLc+fOLfI4XVVe9+/XX3+tLl26qGLFivL391fLli21fPlya4J1Qfl5/6b76aefVKpUKTVt2rTI4gNcRUH+llB0IiMjddNNN8nPz0+VKlVSnz59FB0d7eywIGnGjBlq3Lix/P397efr77//3tlh4Rqvv/663NzcNGzYMGeHUuKNHTtWbm5uDq969eoVybooShVTn3/+uYYPH64xY8Zox44datKkibp166aTJ09mu9yhQ4c0YsQItW3b1qJIXVNe9+/FixfVpUsXHTp0SF9++aWio6P1/vvvq2rVqhZH7hryun/nzZunF154QWPGjFFUVJQ++OADff7553rxxRctjrz4S0pKUpMmTTR9+vRc9T948KB69uypjh07ateuXRo2bJgeeeQRCidZyOv+Xb9+vbp06aKlS5dq+/bt6tixo3r16qWdO3cWcaSuKa/7N93Zs2c1cOBAderUqYgiA1xLfv+WULTWrVunIUOG6Oeff9bKlSt16dIlde3aVUlJSc4OrcSrVq2aXn/9dW3fvl3btm3Trbfeqt69e+u3335zdmj4f1u3btWsWbPUuHFjZ4eC/xcREaHY2Fj7a8OGDUWyHjdjjCmSkVEgLVq00E033aRp06ZJktLS0hQSEqJ//etfeuGFFzJdJjU1Ve3atdNDDz2kH3/8UWfPnuWbsyzkdf/OnDlTEydO1B9//CFPT0+rw3U5ed2/Tz31lKKiorR69Wp727PPPqvNmzcX2Yff9cDNzU2LFi3K9qrIkSNH6rvvvtOePXvsbffdd5/Onj2rZcuWWRCl68rN/s1MRESE7r33Xr3yyitFE9h1Ii/797777lPt2rXl4eGhb775Rrt27Sry+ABXkd/PKhS9U6dOqVKlSlq3bp3atWvn7HBwjfLly2vixIl6+OGHnR1KiZeYmKhmzZrpvffe02uvvaamTZtq8uTJzg6rRBs7dqxlORdXShVDFy9e1Pbt29W5c2d7m7u7uzp37qxNmzZludyrr76qSpUq8cGag/zs38WLF6tly5YaMmSIKleurIYNG2rChAlKTU21KmyXkZ/926pVK23fvt3+E78///xTS5cuVY8ePSyJ+Xq2adMmh2MhSd26dcv2swT5l5aWpnPnzql8+fLODuW6MWfOHP35558aM2aMs0MBgDyJj4+XJM4JxUxqaqoWLFigpKQktWzZ0tnhQNKQIUPUs2fPDDkrnGvfvn0KDg5WjRo11L9/f8XExBTJekoVyagokLi4OKWmpqpy5coO7ZUrV9Yff/yR6TIbNmzQBx98wLfHuZCf/fvnn3/qhx9+UP/+/bV06VLt379fTz75pC5dusQ/lK6Rn/3br18/xcXFqU2bNjLG6PLly3r88cf5+V4hOH78eKbHIiEhQRcuXJCPj4+TIrs+vfXWW0pMTNQ999zj7FCuC/v27dMLL7ygH3/8UaVKkbIAcB1paWkaNmyYWrdurYYNGzo7HEj69ddf1bJlSyUnJ6tMmTJatGiRGjRo4OywSrwFCxZox44d2rp1q7NDwVVatGihuXPnqm7duoqNjdW4cePUtm1b7dmzR35+foW6LjK868C5c+f0wAMP6P3331dgYKCzw7kupaWlqVKlSpo9e7Y8PDzUvHlz/fXXX5o4cSJFqUKwdu1aTZgwQe+9955atGih/fv3a+jQoRo/frxGjx7t7PCAXJk3b57GjRunb7/9VpUqVXJ2OC4vNTVV/fr107hx41SnTh1nhwMAeTJkyBDt2bOH2xAUI3Xr1tWuXbsUHx+vL7/8UoMGDdK6desoTDnRkSNHNHToUK1cuVLe3t7ODgdX6d69u/3/GzdurBYtWigsLExffPFFof8yi6JUMRQYGCgPDw+dOHHCof3EiROqUqVKhv4HDhzQoUOH1KtXL3tbWlqaJKlUqVKKjo5WzZo1izZoF5LX/StJQUFB8vT0lIeHh72tfv36On78uC5evCgvL68ijdmV5Gf/jh49Wg888IAeeeQRSVKjRo2UlJSkxx57TC+99JLc3fmlcX5VqVIl02Ph7+/PVVKFaMGCBXrkkUe0cOFCLj0vJOfOndO2bdu0c+dOPfXUU5KunNuMMSpVqpRWrFihW2+91clRAkBGTz31lJYsWaL169erWrVqzg4H/8/Ly0u1atWSJDVv3lxbt27VlClTNGvWLCdHVnJt375dJ0+eVLNmzextqampWr9+vaZNm6aUlBSHf3/BecqWLas6depo//79hT42/9Irhry8vNS8eXOHmz6npaVp9erVmf7uuV69evr111+1a9cu++uOO+6wP20rJCTEyvCLvbzuX0lq3bq19u/fby/2SdLevXsVFBREQeoa+dm/58+fz1B4Sj8B8SyGgmnZsqXDsZCklStXcg+FQjR//nwNHjxY8+fPV8+ePZ0dznXD398/w7nt8ccft3/T3aJFC2eHCAAOjDF66qmntGjRIv3www8KDw93dkjIRlpamlJSUpwdRonWqVOnDOf6G2+8Uf3799euXbsoSBUjiYmJOnDggIKCggp9bK6UKqaGDx+uQYMG6cYbb9TNN9+syZMnKykpSYMHD5YkDRw4UFWrVlVkZKS8vb0z/Fa9bNmyksRv2LOQl/0rSU888YSmTZumoUOH6l//+pf27dunCRMm6Omnn3bmZhRbed2/vXr10qRJk3TDDTfYf743evRo9erVi5PRNRITEx2+oTh48KB27dql8uXLKzQ0VKNGjdJff/2ljz/+WJL0+OOPa9q0aXr++ef10EMP6YcfftAXX3yh7777zlmbUKzldf/OmzdPgwYN0pQpU9SiRQsdP35ckuTj46OAgACnbENxlpf96+7unuEcVqlSpUzPeUBJk9PfEpxjyJAhmjdvnr799lv5+fnZzwkBAQFcnexko0aNUvfu3RUaGqpz585p3rx5Wrt2rZYvX+7s0Eo0Pz+/DOd0X19fVahQgXO9k40YMUK9evVSWFiYjh07pjFjxsjDw0P3339/4a/MoNiaOnWqCQ0NNV5eXubmm282P//8s31e+/btzaBBg7JcdtCgQaZ3795FH6QLy+v+3bhxo2nRooWx2WymRo0a5t///re5fPmyxVG7jrzs30uXLpmxY8eamjVrGm9vbxMSEmKefPJJc+bMGesDL+bWrFljJGV4pe/PQYMGmfbt22dYpmnTpsbLy8vUqFHDzJkzx/K4XUVe92/79u2z7Q9H+Xn/Xm3MmDGmSZMmlsQKFGc5/S3BOTI7JpI47xYDDz30kAkLCzNeXl6mYsWKplOnTmbFihXODguZaN++vRk6dKizwyjx7r33XhMUFGS8vLxM1apVzb333mv2799fJOtyM4bfxgAAAAAAAMBa3FMKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCi5h7ty5Klu2bI793Nzc9M033xR5PLlV3OIpTA8++KD69OmTbZ+1a9fKzc1NZ8+etSQmZxo7dqyaNm3q7DCcpnr16po8eXKBx/nggw/UtWvXggfkRIcOHZKbm5t27dqVY9+4uDhVqlRJR48eLfrAAEDkVMUROZUjcipyqnTkVCUDRSm4hHvvvVd79+61T7vKySo2Nlbdu3fPVd+iSrZy+jAfN26cBgwYkOdxp0yZorlz59qnO3TooGHDhuUvyAIqDonaiBEjtHr16lz1Lcr3b24S24LI6h8zW7du1WOPPVagsZOTkzV69GiNGTOmQOO4ksDAQA0cOLBEbTMA5yKnyj9yKmuQU5FT5Qc5leuiKAWX4OPjo0qVKjk7jDyrUqWKbDabs8PI1rfffqs77rgjz8sFBATk6pvWkqJMmTKqUKGCs8PIt4sXLxZo+YoVK6p06dIFGuPLL7+Uv7+/WrduXaBxXM3gwYP12Wef6e+//3Z2KABKAHKqokNOVTjIqcip8oucykUZwAn++9//moCAAHP58mVjjDE7d+40kszIkSPtfR5++GHTv39/Y4wxc+bMMQEBAfb/l+TwmjNnjjHGGEnm/fffN3369DE+Pj6mVq1a5ttvv802lo8//tg0b97clClTxlSuXNncf//95sSJE/b5f//9t+nXr58JDAw03t7eplatWubDDz80xhiTkpJihgwZYqpUqWJsNpsJDQ01EyZMsC8rySxatCjHvmFhYQ7bExYWZowxZv/+/eaOO+4wlSpVMr6+vubGG280K1eudIg/LCzM/Pvf/zaDBw82ZcqUMSEhIWbWrFkOMVz9at++vX1eTEyM8fLyMvHx8ebZZ581PXv2tM975513jCTz/fff29tq1qxp3n//fWOMMYMGDTK9e/e2//+16zl48KBZs2aNkWRWrVplmjdvbnx8fEzLli3NH3/84bAN7733nqlRo4bx9PQ0derUMR9//LF93sGDB40ks3PnTnvbmTNnjCSzZs0a+/yrX4MGDcr0WMfFxZn77rvPBAcHGx8fH9OwYUMzb948hz4LFy40DRs2NN7e3qZ8+fKmU6dOJjEx0RhjzJo1a8xNN91kSpcubQICAkyrVq3MoUOHjDHGjBkzxjRp0sQ+TlZ9s3v/vv3226Zhw4amdOnSplq1auaJJ54w586ds4+Z/newbNkyU69ePePr62u6detmjh07Zo/h2rHXrFmT6b5o3769GTJkiBk6dKipUKGC6dChQ44xpB/Pq19jxowxxlx5H77zzjv28Q8fPmzuuOMO4+vra/z8/Ezfvn3N8ePHM40lXc+ePc2IESMc2rLb58YY880335gbbrjB2Gw2Ex4ebsaOHWsuXbpkn3/mzBnz2GOPmUqVKhmbzWYiIiLMf//7X/v8L7/80jRo0MB4eXmZsLAw89ZbbzmsP6e/L2OM2bx5s2natKmx2WymefPm5uuvv3Z4z2b3GZIuPDzc/Oc//8l2/wBAZsipyKmuRk41xxhDTkVORU7lSihKwSnOnj1r3N3dzdatW40xxkyePNkEBgaaFi1a2PvUqlXLfrK+OoE6f/68efbZZ01ERISJjY01sbGx5vz588aYK8lCtWrVzLx588y+ffvM008/bcqUKWNOnz6dZSwffPCBWbp0qTlw4IDZtGmTadmypenevbt9/pAhQ0zTpk3N1q1bzcGDB83KlSvN4sWLjTHGTJw40YSEhJj169ebQ4cOmR9//NHhhHx1ApVd35MnT9pPpLGxsebkyZPGGGN27dplZs6caX799Vezd+9e8/LLLxtvb29z+PBh+zrCwsJM+fLlzfTp082+fftMZGSkcXd3tycpW7ZssScxsbGxDvti2rRppmvXrsYYYxYvXuyQ1Pbp08cEBgbak9qjR48aSWbfvn3GGMcE6uzZs6Zly5bm0UcftR+Ty5cv20+4LVq0MGvXrjW//fabadu2rWnVqpU9hq+//tp4enqa6dOnm+joaPP2228bDw8P88MPPxhjck6gLl++bL766isjyURHR5vY2Fhz9uzZTI/10aNHzcSJE83OnTvNgQMHzLvvvms8PDzM5s2bjTHGHDt2zJQqVcpMmjTJHDx40Pzyyy9m+vTp5ty5c+bSpUsmICDAjBgxwuzfv9/8/vvvZu7cufZjcXUClV3f7N6/77zzjvnhhx/MwYMHzerVq03dunXNE088YY9/zpw5xtPT03Tu3Nls3brVbN++3dSvX9/069fPGGPMuXPnzD333GNuu+02+9gpKSmZ7ov27dubMmXKmOeee8788ccf9vdLdjGkpKSYyZMnG39/f/v46cnV1QlUamqqadq0qWnTpo3Ztm2b+fnnn03z5s0dkvfMBAQEmAULFtinc9rn69evN/7+/mbu3LnmwIEDZsWKFaZ69epm7Nix9jhuueUWExERYVasWGEOHDhg/vvf/5qlS5caY4zZtm2bcXd3N6+++qqJjo42c+bMMT4+PvaENn27svv7OnfunKlYsaLp16+f2bNnj/nvf/9ratSo4fCeze4zJN29996bZeIPANkhpyKnSkdORU6VjpxqULb7B8ULRSk4TbNmzczEiRONMVdO1v/+97+Nl5eXOXfunP1kvXfvXmOMYwJlTMZvUNJJMi+//LJ9OjExMcM3UznZunWrkWQ/MfTq1csMHjw4077/+te/zK233mrS0tIynX91ApWXvtmJiIgwU6dOtU+HhYWZAQMG2KfT0tJMpUqVzIwZM4wxmScg6bp06WKmTZtmjLmSlKQntWlpaaZ8+fImMjLSntR++umnpmrVqvZlr06gjLlyQh46dKjD+Fd/q5fuu+++M5LMhQsXjDHGtGrVyjz66KMOy/Xt29f06NEjy/ivTqCuXs+ZM2ey2XOZ69mzp3n22WeNMcZs377dSHL41ijd6dOnjSSzdu3aTMe5+j2Zl77ZWbhwoalQoYJ9Ov0bwf3799vbpk+fbipXrmyfvva4ZKV9+/bmhhtuyFcMV/8tprs6gVqxYoXx8PAwMTEx9vm//fabkWS2bNmS6XrSj+n69evtbTntx06dOjl8i26MMZ988okJCgoyxhizfPly4+7ubqKjozNdvl+/fqZLly4Obc8995xp0KCBw3Zl9/c1a9YsU6FCBfv72RhjZsyY4fCeze4zJN0zzzxj/2YVAPKKnCrrvtkhpyKnIqe6gpwKzsQ9peA07du319q1a2WM0Y8//qi77rpL9evX14YNG7Ru3ToFBwerdu3aeR63cePG9v/39fWVv7+/Tp48mWX/7du3q1evXgoNDZWfn5/at28vSYqJiZEkPfHEE1qwYIGaNm2q559/Xhs3brQv++CDD2rXrl2qW7eunn76aa1YsSLL9eSlb7rExESNGDFC9evXV9myZVWmTBlFRUXZY8tsm93c3FSlSpVst1mSEhIStG7dOvu9D8qWLasmTZpo7dq1+vXXX+Xl5aXHHntMO3fuVGJiotatW2ffN3l1dXxBQUGSZI8vKioqw+/dW7duraioqHytKzupqakaP368GjVqpPLly6tMmTJavny5fX82adJEnTp1UqNGjdS3b1+9//77OnPmjCSpfPnyevDBB9WtWzf16tVLU6ZMUWxsbKbryUvfq61atUqdOnVS1apV5efnpwceeECnT5/W+fPn7X1Kly6tmjVr2qeDgoJyPNZZad68eb5iyElUVJRCQkIUEhJib2vQoIHKli2b5XG9cOGCJMnb29veltN+3L17t1599VWVKVPG/nr00UcVGxur8+fPa9euXapWrZrq1KmTZZyZvff27dun1NRUe1t2f19RUVFq3LixQ9wtW7Z0GDO7z5B0Pj4+edrHAHA1cipyKomc6mrkVORUcB0UpeA0HTp00IYNG7R79255enqqXr166tChg9auXVugk7Wnp6fDtJubm9LS0jLtm5SUpG7dusnf31+fffaZtm7dqkWLFkn6300Ku3fvrsOHD+uZZ57RsWPH1KlTJ40YMUKS1KxZMx08eFDjx4/XhQsXdM899+gf//hHpuvKS990I0aM0KJFizRhwgT9+OOP2rVrlxo1apThBop52eZ033//vRo0aOBwkrt2/5cvX94hqS2MY+Lm5iZJOcaXzt39yseUMcbedunSpXzFMXHiRE2ZMkUjR47UmjVrtGvXLnXr1s2+Pz08PLRy5Ur7vpk6darq1q2rgwcPSpLmzJmjTZs2qVWrVvr8889Vp04d/fzzz5muKy99pStP9Ln99tvVuHFjffXVV9q+fbumT58uyfGGmZkd66v3TV74+vrmK4aiUKFCBbm5udkT1nTZ7cfExESNGzdOu3btsr9+/fVX7du3T97e3vLx8SmU2PLz93W17D5D0v3999+qWLFiocQLoOQhpyKnyg1yKnIqcioURxSl4DRt27bVuXPn9M4779hPzOkn8LVr16pDhw5ZLuvl5eVQdc+vP/74Q6dPn9brr7+utm3bql69epl+Q1KxYkUNGjRIn376qSZPnqzZs2fb5/n7++vee+/V+++/r88//1xfffVVlk98yK6vp6dnhm366aef9OCDD+rOO+9Uo0aNVKVKFR06dChP2+jl5SVJGcb+9ttv1bt3b4e29u3ba8OGDVq9erV9/3fo0EHz58/X3r17i+SY1K9fXz/99JND208//aQGDRpIkv2kcvW3Odc+ijmrbbzWTz/9pN69e2vAgAFq0qSJatSo4fBYbOnKybF169YaN26cdu7cKS8vL3tSLUk33HCDRo0apY0bN6phw4aaN29eluvLqm9m+2r79u1KS0vT22+/rVtuuUV16tTRsWPHst2ezBTkbyM3MeRm/Pr16+vIkSM6cuSIve3333/X2bNn7cc1s7gbNGig33//PcO8rPZjs2bNFB0drVq1amV4ubu7q3Hjxjp69GiGY3x1nJm99+rUqSMPD49st/HqMX755RclJyfb2zJLlLP7DJGkPXv26IYbbsjVOgHgWuRU5FQSOVU6cipyKnIq10JRCk5Trlw5NW7cWJ999pn9xNyuXTvt2LFDe/fuzfYbpOrVq+vgwYPatWuX4uLilJKSkq8YQkND5eXlpalTp+rPP//U4sWLNX78eIc+r7zyir799lvt379fv/32m5YsWaL69etLkiZNmqT58+frjz/+0N69e7Vw4UJVqVIl08f65tS3evXqWr16tY4fP27/ZqN27dr6+uuvtWvXLu3evVv9+vXL07cJklSpUiX5+Pho2bJlOnHihOLj43X58mV9//33GR5b3K5dO507d05LlixxSKA+++wzBQUFZXnJbnr8mzdv1qFDhxQXF5frOJ977jnNnTtXM2bM0L59+zRp0iR9/fXX9m89fHx8dMstt+j1119XVFSU1q1bp5dfftlhjLCwMLm5uWnJkiU6deqUEhMTM11X7dq1tXLlSm3cuFFRUVH65z//qRMnTtjnb968WRMmTNC2bdsUExOjr7/+WqdOnVL9+vV18OBBjRo1Sps2bdLhw4e1YsUK7du3z/5euFpOfTN7/9aqVUuXLl2yvxc/+eQTzZw5M1f78GrVq1fXL7/8oujoaMXFxeXpG9DcxFC9enUlJiZq9erViouLy/Ty6M6dO6tRo0bq37+/duzYoS1btmjgwIFq3769brzxxizX361bN23YsME+ndN+fOWVV/Txxx9r3Lhx+u233xQVFaUFCxbY3x/t27dXu3btdPfdd2vlypU6ePCgvv/+ey1btkyS9Oyzz2r16tUaP3689u7dq48++kjTpk3L8I1bdvr16yc3Nzc9+uij+v3337V06VK99dZbDn2y+wyRpPPnz2v79u3q2rVrrtcLAFcjpyKnksipyKn+h5yKnMqlOPOGVsDQoUONJBMVFWVva9KkialSpYpDv2tvBJicnGzuvvtuU7Zs2QyPL772xpYBAQEOT3641rx580z16tWNzWYzLVu2NIsXL3a4od748eNN/fr1jY+Pjylfvrzp3bu3+fPPP40xxsyePds0bdrU+Pr6Gn9/f9OpUyezY8cO+9hXx5NT38WLF5tatWqZUqVK2R9ffPDgQdOxY0fj4+NjQkJCzLRp0zLc/PLax8am78P0x8oaY8z7779vQkJCjLu7u2nfvr1ZtWqVqVatWqb749r9f/r0aePm5mbuu+8+h37X3vwxOjra3HLLLcbHxyfD44uvvllm+qOqDx48aG/L7vHFxhjz+++/m5YtWxofHx/TtGlTs2LFigyP5n311VdNlSpVjJubW5ZP3Dh9+rTp3bu3KVOmjKlUqZJ5+eWXzcCBA+3b8fvvv5tu3bqZihUrGpvNZurUqWO/Aerx48dNnz59TFBQkP1Rt6+88opJTU01xjjeaDOnvlm9fydNmmSCgoKMj4+P6datm/n4448d9l9mN8RctGiRufqj/OTJk6ZLly6mTJkyOT6++NqbqOYmBmOMefzxx02FChUK/fHFv/32m/Hx8bE/6Sen/WiMMcuWLTOtWrUyPj4+xt/f39x8881m9uzZ9vmnT582gwcPNhUqVDDe3t6mYcOGZsmSJfb56Y8v9vT0NKGhofYbBafLzd/Xpk2bTJMmTYyXl5dp2rSp/clFufkMMebKZ1DdunWz3TcAkBNyKnIqY8ipyKmuIKeCK3EzJp8/nAXgsp5++mldvnxZ7733nrNDARz07dtXzZo106hRo5wdimVuueUWPf300+rXr5+zQwEA5BE5FYorciq4Cn6+B5RADRs21BNPPOHsMIAMJk6cqDJlyjg7DMvExcXprrvu0v333+/sUAAA+UBOheKKnAqugiulAAAAAAAAYDmulAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQqA5apXr67bb7/d2WEAAADkGXkMABQeilJAIVu7dq3c3Nwyff38888Z+m/cuFFt2rRR6dKlVaVKFT399NNKTEzM0C8lJUUjR45UcHCwfHx81KJFC61cudKKTcoQ79ixY3X27FnL110SOXN/JyYmasyYMbrttttUvnx5ubm5ae7cuVn2j4qK0m233aYyZcqofPnyeuCBB3Tq1KkM/dLS0vTmm28qPDxc3t7eaty4sebPn1+gMQEAyA3yGGu54v6OjY3VCy+8oI4dO8rPz09ubm5au3Ztlv2LIpfP7ZjA9YCiFFBEnn76aX3yyScOr1q1ajn02bVrlzp16qTz589r0qRJeuSRRzR79mz17ds3w3gPPvigJk2apP79+2vKlCny8PBQjx49tGHDBqs2SdKVk+S4ceNcKrlwZc7c33FxcXr11VcVFRWlJk2aZNv36NGjateunfbv368JEyZoxIgR+u6779SlSxddvHjRoe9LL72kkSNHqkuXLpo6dapCQ0PVr18/LViwIN9jAgCQG+Qx1nLF/R0dHa033nhDf/31lxo1apRt36LI5fMyJnBdMAAK1Zo1a4wks3Dhwhz7du/e3QQFBZn4+Hh72/vvv28kmeXLl9vbNm/ebCSZiRMn2tsuXLhgatasaVq2bFlose/evTvHPhMnTjSSzMGDB/O9nrCwMNOzZ898L1+SFMb+zkxujnVycrKJjY01xhizdetWI8nMmTMn075PPPGE8fHxMYcPH7a3rVy50kgys2bNsrcdPXrUeHp6miFDhtjb0tLSTNu2bU21atXM5cuX8zwmAAC5RR5jrbzu7/3795ukpKSiDSoHCQkJ5vTp08YYYxYuXGgkmTVr1mTatyhy+dyOCVwvuFIKKELnzp3T5cuXM52XkJCglStXasCAAfL397e3Dxw4UGXKlNEXX3xhb/vyyy/l4eGhxx57zN7m7e2thx9+WJs2bdKRI0fyHePff/+tqVOnqkmTJmrXrl22fceOHavnnntOkhQeHm7/WeKhQ4ckSZcvX9b48eNVs2ZN2Ww2Va9eXS+++KJSUlJyjOOjjz5SqVKl7ONL0ubNm3XbbbcpICBApUuXVvv27fXTTz9liMnNzU379+/Xgw8+qLJlyyogIECDBw/W+fPnc7UPNm/erB49eqhcuXLy9fVV48aNNWXKFIc+P/zwg9q2bStfX1+VLVtWvXv3VlRUlEOfBx98UNWrV88wfnqMV3Nzc9NTTz2lb775Rg0bNpTNZlNERISWLVvmsFx2+zuv8nKsJclms6lKlSq5Gvurr77S7bffrtDQUHtb586dVadOHYf38rfffqtLly7pySeftLe5ubnpiSee0NGjR7Vp06Y8jwkAQG6QxxT/POaTTz5RUFCQHn/8cW3dujVX21/Y/Pz8VL58+Rz7FUUun5cxgetFKWcHAFyvBg8erMTERHl4eKht27aaOHGibrzxRvv8X3/9VZcvX3ZokyQvLy81bdpUO3futLft3LlTderUcTg5SdLNN98s6cplviEhIbmOzRij1atX64MPPtCiRYt08eJFtWvXTs8//3y2y911113au3ev5s+fr3feeUeBgYGSpIoVK0qSHnnkEX300Uf6xz/+oWeffVabN29WZGSkoqKitGjRoizHnT17th5//HG9+OKLeu211yRdSZ66d++u5s2ba8yYMXJ3d9ecOXN066236scff7Rve7p77rlH4eHhioyM1I4dO/Sf//xHlSpV0htvvJHtNq1cuVK33367goKCNHToUFWpUkVRUVFasmSJhg4dKklatWqVunfvrho1amjs2LG6cOGCpk6dqtatW2vHjh2ZJnC5sWHDBn399dd68skn5efnp3fffVd33323YmJiVKFChRz3d27k91jnxV9//aWTJ09meC9LV96jS5cutU/v3LlTvr6+ql+/foZ+6fPbtGmTpzEBAMgN8pjin8f069dPJ0+e1Pz58zVr1iw1atRIDz/8sAYMGKAKFSpkudz58+dzVcTz8PBQuXLl8r6xmSiKXD4vYwLXDWdfqgVcb3766Sdz9913mw8++MB8++23JjIy0lSoUMF4e3ubHTt22PulXw68fv36DGP07dvXVKlSxT4dERFhbr311gz9fvvtNyPJzJw5M1exxcTEmFdffdVUr17dSDIhISHm5ZdfNvv378/19mV1GfauXbuMJPPII484tI8YMcJIMj/88IO97erL3qdMmWLc3NzM+PHj7fPT0tJM7dq1Tbdu3UxaWpq9/fz58yY8PNx06dLF3jZmzBgjyTz00EMO673zzjtNhQoVst2Wy5cvm/DwcBMWFmbOnDnjMO/q9TZt2tRUqlTJfim3MVd+/ubu7m4GDhxobxs0aJAJCwvLsJ70GK8myXh5eTns+927dxtJZurUqfa2/P7MoDCO9dWy+/le+ryPP/44w7znnnvOSDLJycnGGGN69uxpatSokaFfUlKSkWReeOGFPI8JAEBukcdcUdzzmAsXLpjPPvvMdOrUybi5uRmbzWbuvfdes2LFCpOamppljDm9Mtu+7GT3872iyOXzMiZwveBKKaCQtWrVSq1atbJP33HHHfrHP/6hxo0ba9SoUfbLmi9cuCDpyk+kruXt7W2fn943q35Xj5WVLVu2aMyYMVqxYoU8PT3Vp08fzZo1S507d5a7e+H8ijf9ypXhw4c7tD/77LN666239N1336ljx44O8958802NHDlSb775psPl7rt27dK+ffv08ssv6/Tp0w7LdOrUSZ988onS0tIcYn/88ccd+rVt21aLFi1SQkJChm+l0u3cuVMHDx7UO++8o7JlyzrMS79MPTY2Vrt27dLzzz/vcCl348aN1aVLlwJdsdO5c2fVrFnTYUx/f3/9+eef+R7TimN9rZzey+l9bDZbrt/LeRkTAICCIo/Ju6LIY9J5e3urX79+6tevnw4fPqy5c+dq7ty5+vzzzxUWFqZ//vOfGjVqlL3/wIED1aZNmxzH9fHxKXBs6Yoil8/LmMD1gqIUYIFatWqpd+/e+vrrr5WamioPDw/7STGz+xQkJyc7nDR9fHyy7Jc+PztLly7VsmXLVLFiRc2ZM0c9e/YsyOZk6vDhw3J3d8/whMEqVaqobNmyOnz4sEP7unXr9N1332nkyJEOiZwk7du3T5I0aNCgLNcXHx/vcPn11fcdkmSfd+bMmSyTuQMHDkiSGjZsmO12SVLdunUzzKtfv76WL1+upKQk+fr6ZjlGVq6NOT3uM2fO5HmsdFYc62vl9F6+uk9u38t5GRMAgIIijykeeUxmwsLCNGbMGD3++ON69NFH9d///ldvvPGGQ1GqRo0aqlGjRqGuNydFkcvnZUzgekFRCrBISEiILl68qKSkJPn7+ysoKEjSlW+wrhUbG6vg4GD7dFBQkP76669M+0ly6JuZRx55RJcvX9bcuXN1++23q27duho8eLAeeOCBHJfNq2tvhJmViIgInT17Vp988on++c9/Kjw83D4vLS1NkjRx4kQ1bdo00+XLlCnjMO3h4ZFpP2NMruIpDFlte2pqaqbtRRGzlcc6XU7v5fLly9u/8QsKCtKaNWtkjHHYX9e+l/MyJgAAhYU8JiMr85hrXb58WUuXLtWcOXP03XffyRijPn366NFHH3Xol5iYqMTExBzH8/DwyNO9ObNTFLl8XsYErhc8fQ+wyJ9//ilvb297EtKwYUOVKlVK27Ztc+h38eJF7dq1yyGJadq0qfbu3auEhASHvps3b7bPz061atX02muv6fDhw1qyZInq16+vl19+WaGhoerZs6e+/PJLXbx4MVfbkVXCEhYWprS0NPu3g+lOnDihs2fPKiwszKE9MDBQq1atkqenpzp16qRjx47Z56VfCu7v76/OnTtn+vL09MxVvNlJX8+ePXuy7JMed3R0dIZ5f/zxhwIDA+3fLpYrV05nz57N0O/ab1fzIrfJcbrCPNa5VbVqVVWsWDHDe1m68nPCa9/L58+fz/DEn2vfy3kZEwCA3CKP+Z/imMek+/333/Xcc8+pWrVq6t27t37//XeNHz9eR48e1aJFi9SjRw+H/m+99ZaCgoJyfN1000353pZrFUUun5cxgesFRSmgkJ06dSpD2+7du7V48WJ17drVfv+AgIAAde7cWZ9++qnOnTtn7/vJJ58oMTFRffv2tbf94x//UGpqqmbPnm1vS0lJ0Zw5c9SiRYtcP3nPw8NDPXv21KJFi3T06FFNmDBB+/fvV9++fRUcHJzh8vPMpCcu1yYt6cnB5MmTHdonTZokSZn+jKxatWpatWqVLly4oC5dutjvu9C8eXPVrFlTb731VqbfemW2j/OjWbNmCg8P1+TJkzNsT/q3fEFBQWratKk++ugjhz579uzRihUrHJKimjVrKj4+Xr/88ou9LTY2Ntsn9uQkq/2dk8I41nlx9913a8mSJfZHGkvS6tWrtXfvXof3cu/eveXp6an33nvP3maM0cyZM1W1alWH+7HldkwAAHKLPOaK4prHrF27VrfccosiIiI0ffp0de3aVevWrVN0dLRGjhypypUrZ7rcwIEDtXLlyhxfn332Wb635VpFkcvnZUzguuG0W6wD16mOHTuaHj16mNdee83Mnj3bDBs2zJQuXdoEBASY33//3aHv9u3bjc1mMzfccIOZMWOGeemll4y3t7fp2rVrhnH79u1rSpUqZZ577jkza9Ys06pVK1OqVCmzbt26Ase8bt06M3DgQBMcHJxj3y1bthhJpkePHubjjz828+fPN4mJicaYK09tkWTuueceM336dPt0nz59HMa4+qk1xhjzyy+/mPLly5vmzZub+Ph4Y4wxa9asMd7e3iY0NNSMGTPGzJ4924wZM8a0a9fO3H777fZl05+2curUKYd1zJkzJ1dPe1m2bJnx9PQ0YWFhZuzYsWbWrFnmmWeecTgGK1euNKVKlTL16tUzEydONK+++qqpWLGiKVeunPnzzz/t/eLi4oyvr6+pUaOGmTx5spkwYYIJCQkxzZo1y/SpNUOGDMkQT1hYmBk0aFCu9nd+5OVYG2PM1KlTzfjx480TTzxhJJm77rrLjB8/3owfP96cPXvW3i8mJsZUqFDB1KxZ07z77rtmwoQJply5cqZRo0YZnpKX/vS8xx57zLz//vumZ8+eRpL57LPPHPrlZUwAAHKDPKZ45zFjx441zZo1M++9955DnmG19Fznvvvusz8dMb3takWRy+dlTOB6QFEKKGRTpkwxN998sylfvrwpVaqUCQoKMgMGDDD79u3LtP+PP/5oWrVqZby9vU3FihXNkCFDTEJCQoZ+Fy5cMCNGjDBVqlQxNpvN3HTTTWbZsmWFGntuix3jx483VatWNe7u7g4J06VLl8y4ceNMeHi48fT0NCEhIWbUqFEZCgjXJnPGGLN582bj5+dn2rVrZ86fP2+MMWbnzp3mrrvuMhUqVDA2m82EhYWZe+65x6xevdq+XEGTOWOM2bBhg+nSpYvx8/Mzvr6+pnHjxg6PMzbGmFWrVpnWrVsbHx8f4+/vb3r16pWhyGiMMStWrDANGzY0Xl5epm7duubTTz/N8lHKuUnmjMl6fxdEbo91WFhYlo9VvjaOPXv2mK5du5rSpUubsmXLmv79+5vjx49nGDM1NdVMmDDBhIWFGS8vLxMREWE+/fTTTNef2zEBAMgt8pjim8cU5Iu3wpRV7pPZNR1FkcvndkzgeuBmjIV3zwMAAAAAAADEPaUAAAAAAADgBBSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLlXJ2AFZLS0vTsWPH5OfnJzc3N2eHAwAAihFjjM6dO6fg4GC5u/PdXXbIqQAAQFZym1OVuKLUsWPHFBIS4uwwAABAMXbkyBFVq1bN2WEUa+RUAAAgJznlVCWuKOXn5yfpyo7x9/d3cjQAAKA4SUhIUEhIiD1fQNbIqQAAQFZym1OVuKJU+uXl/v7+JFAAACBT/BwtZ+RUAAAgJznlVNwsAQAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByTi1KzZgxQ40bN5a/v7/8/f3VsmVLff/999kus3DhQtWrV0/e3t5q1KiRli5dalG0AAAA1ouMjNRNN90kPz8/VapUSX369FF0dHSOy+WUMxlj9MorrygoKEg+Pj7q3Lmz9u3bV1SbAQAAkIFTi1LVqlXT66+/ru3bt2vbtm269dZb1bt3b/3222+Z9t+4caPuv/9+Pfzww9q5c6f69OmjPn36aM+ePRZHDgAAYI1169ZpyJAh+vnnn7Vy5UpdunRJXbt2VVJSUpbL5CZnevPNN/Xuu+9q5syZ2rx5s3x9fdWtWzclJydbsVkAAAByM8YYZwdxtfLly2vixIl6+OGHM8y79957lZSUpCVLltjbbrnlFjVt2lQzZ87M1fgJCQkKCAhQfHy8/P39Cy1uAADg+lwhTzh16pQqVaqkdevWqV27dpn2ySlnMsYoODhYzz77rEaMGCFJio+PV+XKlTV37lzdd999OcbhCvsKAAA4R27zhFIWxpSt1NRULVy4UElJSWrZsmWmfTZt2qThw4c7tHXr1k3ffPNNluOmpKQoJSXFPp2QkFAo8QKFLSYmRnFxcflePjAwUKGhoYUYEQCgOIqPj5d05Yu8rOSUMx08eFDHjx9X586d7fMDAgLUokULbdq0KdOiFDkVrEJOBAAlh9OLUr/++qtatmyp5ORklSlTRosWLVKDBg0y7Xv8+HFVrlzZoa1y5co6fvx4luNHRkZq3LhxhRozUNhiYmJUv25dnS/ATyZKe3srKjqaJAwArmNpaWkaNmyYWrdurYYNG2bZL6ecKf2/ecmryKlghZiYGNWrW08Xki/kewwfbx/9Ef0HOREAuACnF6Xq1q2rXbt2KT4+Xl9++aUGDRqkdevWZVmYyqtRo0Y5fFOYkJCgkJCQQhkbKCxxcXE6n5ysTyXVz8fyUZIGJCcrLi6OBAwArmNDhgzRnj17tGHDBsvXTU4FK8TFxelC8gXdpbsUqMC8L684fZ38NTkRALgIpxelvLy8VKtWLUlS8+bNtXXrVk2ZMkWzZs3K0LdKlSo6ceKEQ9uJEydUpUqVLMe32Wyy2WyFGzRQROpLaubsIAAAxdJTTz2lJUuWaP369apWrVq2fXPKmdL/e+LECQUFBTn0adq0aaZjklPBSoEKVLCCnR0GAKCIOfXpe5lJS0tzuF/B1Vq2bKnVq1c7tK1cuTLLe1ABAAC4OmOMnnrqKS1atEg//PCDwsPDc1wmp5wpPDxcVapUceiTkJCgzZs3k1cBAADLOPVKqVGjRql79+4KDQ3VuXPnNG/ePK1du1bLly+XJA0cOFBVq1ZVZGSkJGno0KFq37693n77bfXs2VMLFizQtm3bNHv2bGduBgAAQJEZMmSI5s2bp2+//VZ+fn72ez4FBATIx8dHUt5zJjc3Nw0bNkyvvfaaateurfDwcI0ePVrBwcHq06ePU7YTAACUPE4tSp08eVIDBw5UbGysAgIC1LhxYy1fvlxdunSRdOVGh+7u/7uYq1WrVpo3b55efvllvfjii6pdu7a++eabbG/0CQAA4MpmzJghSerQoYND+5w5c/Tggw9Kyl/O9PzzzyspKUmPPfaYzp49qzZt2mjZsmXy9vYu8m0CAACQnFyU+uCDD7Kdv3bt2gxtffv2Vd++fYsoIgAAgOLFGJNjn/zkTG5ubnr11Vf16quvFiQ8AACAfCt295QCAAAAAADA9Y+iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAP6vvXuPi7LO////HFAGPIAH5GChYippHvCwEnbQVhLNr6vb52OWtR627FOrn7XI2mU/pam70WaedrMsU8ntoLWZtmWmkdSapHmg0hTFUDSBxFQEExXevz/6OevEQRiGaxh43G+366bXdb2va17v9zUzvK7XXHMNAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAEAd9umnn2rEiBFq27atbDab1qxZU2n7CRMmyGazlZmuu+46R5snn3yyzPprr722lnsCAADgjKIUAABAHVZUVKRevXpp0aJFVWq/cOFC5eTkOKYjR46oVatWGj16tFO76667zqnd5s2bayN8AACACjXydAAAAACo2LBhwzRs2LAqtw8KClJQUJBjfs2aNTp58qQmTpzo1K5Ro0YKCwtzW5wAAADVxZVSAAAA9djSpUsVFxen9u3bOy0/cOCA2rZtq44dO+ruu+9WdnZ2pfspLi5WQUGB0wQAAFATFKUAAADqqWPHjumDDz7Qfffd57Q8JiZGycnJWr9+vV544QVlZWXppptu0pkzZyrcV1JSkuMqrKCgIEVERNR2+AAAoJ6jKAUAAFBPvfLKK2rRooVGjRrltHzYsGEaPXq0evbsqfj4eK1bt06nTp3Sm2++WeG+EhMTdfr0acd05MiRWo4eAADUd9xTCgAAoB4yxmjZsmX6zW9+Iz8/v0rbtmjRQl26dFFmZmaFbex2u+x2u7vDBAAADRhXSgEAANRDn3zyiTIzM3XvvfdesW1hYaEOHjyo8PBwCyIDAAD4CUUpAACAOqywsFDp6elKT0+XJGVlZSk9Pd1xY/LExESNGzeuzHZLly5VTEyMunfvXmbdtGnT9Mknn+jQoUPasmWLfv3rX8vX11d33XVXrfYFAADgcnx9DwAAoA7bvn27brnlFsd8QkKCJGn8+PFKTk5WTk5OmV/OO336tN5++20tXLiw3H0ePXpUd911l06cOKE2bdroxhtv1Oeff642bdrUXkcAAAB+hqIUAABAHTZo0CAZYypcn5ycXGZZUFCQzp49W+E2K1eudEdoAAAANcLX9wAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACW82hRKikpSb/4xS/UvHlzhYSEaNSoUcrIyKh0m+TkZNlsNqfJ39/foogBAAAAAADgDh4tSn3yySeaPHmyPv/8c23cuFEXLlzQkCFDVFRUVOl2gYGBysnJcUyHDx+2KGIAAAAAAAC4QyNPPvj69eud5pOTkxUSEqIdO3bo5ptvrnA7m82msLCw2g4PAAAAAAAAtaRO3VPq9OnTkqRWrVpV2q6wsFDt27dXRESERo4cqT179lgRHgAAAAAAANykzhSlSktL9dBDD+mGG25Q9+7dK2wXFRWlZcuWae3atXr11VdVWlqqAQMG6OjRo+W2Ly4uVkFBgdMEAAAAAAAAz/Lo1/cuN3nyZO3evVubN2+utF1sbKxiY2Md8wMGDFDXrl314osvavbs2WXaJyUlaebMmW6PFwAAAAAAAK6rE1dKTZkyRe+99542bdqkq6++ulrbNm7cWL1791ZmZma56xMTE3X69GnHdOTIEXeEDAAAAAAAgBrw6JVSxhj97//+r9555x2lpqYqMjKy2vsoKSnR119/rdtuu63c9Xa7XXa7vaahAgAAAAAAwI08WpSaPHmyXn/9da1du1bNmzdXbm6uJCkoKEgBAQGSpHHjxumqq65SUlKSJGnWrFm6/vrr1alTJ506dUpz5szR4cOHdd9993msHwAAAAAAAKgejxalXnjhBUnSoEGDnJYvX75cEyZMkCRlZ2fLx+c/3zI8efKkJk2apNzcXLVs2VJ9+/bVli1b1K1bN6vCBgAAAAAAQA15/Ot7V5Kamuo0P3/+fM2fP7+WIgIAAAAAAIAV6sSNzgEAAAAAANCwUJQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAABAHfbpp59qxIgRatu2rWw2m9asWVNp+9TUVNlstjJTbm6uU7tFixapQ4cO8vf3V0xMjLZt21aLvQAAACiLohQAAEAdVlRUpF69emnRokXV2i4jI0M5OTmOKSQkxLFu1apVSkhI0IwZM7Rz50716tVL8fHx+v77790dPgAAQIUaeToAAAAAVGzYsGEaNmxYtbcLCQlRixYtyl03b948TZo0SRMnTpQkLV68WO+//76WLVumP/7xjzUJFwAAoMq4UgoAAKAeio6OVnh4uG699VZ99tlnjuXnz5/Xjh07FBcX51jm4+OjuLg4paWleSJUAADQQFGUAgAAqEfCw8O1ePFivf3223r77bcVERGhQYMGaefOnZKk/Px8lZSUKDQ01Gm70NDQMvedulxxcbEKCgqcJgAAgJrg63sAAAD1SFRUlKKiohzzAwYM0MGDBzV//nz94x//cHm/SUlJmjlzpjtCBAAAkMSVUgAAAPVe//79lZmZKUkKDg6Wr6+v8vLynNrk5eUpLCyswn0kJibq9OnTjunIkSO1GjMAAKj/KEoBAADUc+np6QoPD5ck+fn5qW/fvkpJSXGsLy0tVUpKimJjYyvch91uV2BgoNMEAABQE3x9DwAAoA4rLCx0XOUkSVlZWUpPT1erVq3Url07JSYm6rvvvtOKFSskSQsWLFBkZKSuu+46nTt3Ti+//LI+/vhjbdiwwbGPhIQEjR8/Xv369VP//v21YMECFRUVOX6NDwAAwAoUpQAAAOqw7du365ZbbnHMJyQkSJLGjx+v5ORk5eTkKDs727H+/PnzeuSRR/Tdd9+pSZMm6tmzpz766COnfYwZM0bHjx/X9OnTlZubq+joaK1fv77Mzc8BAABqE0UpAACAOmzQoEEyxlS4Pjk52Wn+scce02OPPXbF/U6ZMkVTpkypaXgAAAAu455SAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOU8WpRKSkrSL37xCzVv3lwhISEaNWqUMjIyrrjdW2+9pWuvvVb+/v7q0aOH1q1bZ0G0AAAAAAAAcBePFqU++eQTTZ48WZ9//rk2btyoCxcuaMiQISoqKqpwmy1btuiuu+7Svffeq127dmnUqFEaNWqUdu/ebWHkAAAAAAAAqIlGnnzw9evXO80nJycrJCREO3bs0M0331zuNgsXLtTQoUP16KOPSpJmz56tjRs36rnnntPixYtrPWYAAAAAAADUnEeLUj93+vRpSVKrVq0qbJOWlqaEhASnZfHx8VqzZk257YuLi1VcXOyYLygoqHmgtSw7O1v5+fkubx8cHKx27dq5MaKqq2nsxcXFstvtLm/vrX3fu3evm6OBN/Hm1zwAAAAAuKrOFKVKS0v10EMP6YYbblD37t0rbJebm6vQ0FCnZaGhocrNzS23fVJSkmbOnOnWWGtTdna2ukZF6ey5cy7vo4m/v/ZmZFh+kuqO2H0lldQgBm/uOxomb37NAwAAAEBN1Jmi1OTJk7V7925t3rzZrftNTEx0urKqoKBAERERbn0Md8rPz9fZc+f0qqSuLmy/V9I9584pPz/f8hPUmsa+TtITUoPuOxoeb37NAwAAAEBN1Imi1JQpU/Tee+/p008/1dVXX11p27CwMOXl5Tkty8vLU1hYWLnt7XZ7jb4O5ildJfXxdBAucjX2S19ga8h9R8Plzc97AAAAAHCFR399zxijKVOm6J133tHHH3+syMjIK24TGxurlJQUp2UbN25UbGxsbYUJAAAAAAAAN/PolVKTJ0/W66+/rrVr16p58+aO+0IFBQUpICBAkjRu3DhdddVVSkpKkiRNnTpVAwcO1Ny5czV8+HCtXLlS27dv10svveSxfgAAAAAAAKB6PHql1AsvvKDTp09r0KBBCg8Pd0yrVq1ytMnOzlZOTo5jfsCAAXr99df10ksvqVevXvrnP/+pNWvWVHpzdAAAAAAAANQtHr1SyhhzxTapqalllo0ePVqjR4+uhYgAAAAAAABgBY9eKQUAAAAAAICGiaIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAA1GGffvqpRowYobZt28pms2nNmjWVtl+9erVuvfVWtWnTRoGBgYqNjdWHH37o1ObJJ5+UzWZzmq699tpa7AUAAEBZFKUAAADqsKKiIvXq1UuLFi2qUvtPP/1Ut956q9atW6cdO3bolltu0YgRI7Rr1y6ndtddd51ycnIc0+bNm2sjfAAAgAo18nQAAAAAqNiwYcM0bNiwKrdfsGCB0/xTTz2ltWvX6l//+pd69+7tWN6oUSOFhYW5K0wAAIBq40opAACAeqy0tFRnzpxRq1atnJYfOHBAbdu2VceOHXX33XcrOzvbQxECAICGiiulAAAA6rFnn31WhYWFuuOOOxzLYmJilJycrKioKOXk5GjmzJm66aabtHv3bjVv3rzc/RQXF6u4uNgxX1BQUOuxAwCA+o2iFAAAQD31+uuva+bMmVq7dq1CQkIcyy//OmDPnj0VExOj9u3b680339S9995b7r6SkpI0c+bMWo8ZAAA0HHx9DwAAoB5auXKl7rvvPr355puKi4urtG2LFi3UpUsXZWZmVtgmMTFRp0+fdkxHjhxxd8gAAKCBoSgFAABQz7zxxhuaOHGi3njjDQ0fPvyK7QsLC3Xw4EGFh4dX2MZutyswMNBpAgAAqAm+vgcAAFCHFRYWOl3BlJWVpfT0dLVq1Urt2rVTYmKivvvuO61YsULST1/ZGz9+vBYuXKiYmBjl5uZKkgICAhQUFCRJmjZtmkaMGKH27dvr2LFjmjFjhnx9fXXXXXdZ30EAANBgcaUUAABAHbZ9+3b17t1bvXv3liQlJCSod+/emj59uiQpJyfH6ZfzXnrpJV28eFGTJ09WeHi4Y5o6daqjzdGjR3XXXXcpKipKd9xxh1q3bq3PP/9cbdq0sbZzAACgQeNKKQAAgDps0KBBMsZUuD45OdlpPjU19Yr7XLlyZQ2jAgAAqDmXrpT69ttv3R0HAABAvUK+BAAAUDmXilKdOnXSLbfcoldffVXnzp1zd0wAAABej3wJAACgci4VpXbu3KmePXsqISFBYWFh+p//+R9t27bN3bEBAAB4LfIlAACAyrlUlIqOjtbChQt17NgxLVu2TDk5ObrxxhvVvXt3zZs3T8ePH3d3nAAAAF6FfAkAAKByNfr1vUaNGun222/XW2+9pb/+9a/KzMzUtGnTFBERoXHjxiknJ8ddcQIAAHgl8iUAAIDy1agotX37dv3ud79TeHi45s2bp2nTpungwYPauHGjjh07ppEjR7orTgAAAK9EvgQAAFC+Rq5sNG/ePC1fvlwZGRm67bbbtGLFCt12223y8fmpxhUZGank5GR16NDBnbECAAB4DfIlAACAyrlUlHrhhRf029/+VhMmTFB4eHi5bUJCQrR06dIaBQcAAOCtyJcAAAAq51JR6sCBA1ds4+fnp/Hjx7uyewAAAK9HvgQAAFA5l+4ptXz5cr311ltllr/11lt65ZVXahwUAACAtyNfAgAAqJxLRamkpCQFBweXWR4SEqKnnnqqxkEBAAB4O/IlAACAyrlUlMrOzlZkZGSZ5e3bt1d2dnaNgwIAAPB25EsAAACVc6koFRISoq+++qrM8i+//FKtW7eucVAAAADejnwJAACgci4Vpe666y79/ve/16ZNm1RSUqKSkhJ9/PHHmjp1qu688053xwgAAOB1yJcAAAAq59Kv782ePVuHDh3S4MGD1ajRT7soLS3VuHHjuEcCAACAyJcAAACuxKWilJ+fn1atWqXZs2fryy+/VEBAgHr06KH27du7Oz4AAACvRL4EAABQOZeKUpd06dJFXbp0cVcsAAAA9Q75EgAAQPlcKkqVlJQoOTlZKSkp+v7771VaWuq0/uOPP3ZLcAAAAN6KfAkAAKByLhWlpk6dquTkZA0fPlzdu3eXzWZzd1wAAABejXwJAACgci4VpVauXKk333xTt912m7vjAQAAqBfIlwAAACrn48pGfn5+6tSpk7tjAQAAqDfIlwAAACrnUlHqkUce0cKFC2WMcXc8AAAA9QL5EgAAQOVc+vre5s2btWnTJn3wwQe67rrr1LhxY6f1q1evdktwAAAA3op8CQAAoHIuFaVatGihX//61+6OBQAAoN4gXwIAAKicS0Wp5cuXuzsOAACAeoV8CQAAoHIu3VNKki5evKiPPvpIL774os6cOSNJOnbsmAoLC90WHAAAgDcjXwIAAKiYS1dKHT58WEOHDlV2draKi4t16623qnnz5vrrX/+q4uJiLV682N1xAgAAeBXyJQAAgMq5dKXU1KlT1a9fP508eVIBAQGO5b/+9a+VkpLituAAAAC8FfkSAABA5Vy6Uurf//63tmzZIj8/P6flHTp00HfffeeWwAAAALwZ+RIAAEDlXLpSqrS0VCUlJWWWHz16VM2bN69xUAAAAN6OfAkAAKByLhWlhgwZogULFjjmbTabCgsLNWPGDN12223uig0AAMBrkS8BAABUzqWv782dO1fx8fHq1q2bzp07p7Fjx+rAgQMKDg7WG2+84e4YAQAAvA75EgAAQOVcKkpdffXV+vLLL7Vy5Up99dVXKiws1L333qu7777b6UaeAAAADRX5EgAAQOVcKkpJUqNGjXTPPfe4MxYAAIB6hXwJAACgYi4VpVasWFHp+nHjxrkUDAAAQH1BvgQAAFA5l4pSU6dOdZq/cOGCzp49Kz8/PzVp0oQkCwAANHjkSwAAAJVz6df3Tp486TQVFhYqIyNDN954IzfuBAAAEPkSAADAlbhUlCpP586d9fTTT5f5VBAAAAA/IV8CAAD4D7cVpaSfbuZ57NixKrf/9NNPNWLECLVt21Y2m01r1qyptH1qaqpsNluZKTc3t4aRAwAAWKO28yXpp5ypT58+stvt6tSpk5KTk8u0WbRokTp06CB/f3/FxMRo27Zt1egFAABAzbl0T6l3333Xad4Yo5ycHD333HO64YYbqryfoqIi9erVS7/97W91++23V3m7jIwMBQYGOuZDQkKqvC0AAIAVPJUvZWVlafjw4XrggQf02muvKSUlRffdd5/Cw8MVHx8vSVq1apUSEhK0ePFixcTEaMGCBYqPj1dGRgZ5FQAAsIxLRalRo0Y5zdtsNrVp00a//OUvNXfu3CrvZ9iwYRo2bFi1Hz8kJEQtWrSo9nYAAABW8VS+tHjxYkVGRjoeo2vXrtq8ebPmz5/vKErNmzdPkyZN0sSJEx3bvP/++1q2bJn++Mc/VvmxAAAAasKlolRpaam746iW6OhoFRcXq3v37nryySer9WkjAACAFTyVL6WlpSkuLs5pWXx8vB566CFJ0vnz57Vjxw4lJiY61vv4+CguLk5paWlWhgoAABo4l4pSnhIeHq7FixerX79+Ki4u1ssvv6xBgwZp69at6tOnT7nbFBcXq7i42DFfUFBgVbgAAACWy83NVWhoqNOy0NBQFRQU6Mcff9TJkydVUlJSbpt9+/ZVuF9P5FTZ2dnKz893efvg4GC1a9fOjRE1HIx9w+Ttx70m8RcXF8tut7v82J7uOxomb3/NSi4WpRISEqrcdt68ea48RLmioqIUFRXlmB8wYIAOHjyo+fPn6x//+Ee52yQlJWnmzJluiwEAAKAqPJUv1Rarc6rs7GxdG3Wtfjz3o8v7CPAP0L6MfR5PuL0NY98weftxr2n8NtlkZFx+fJ7zsJq3v2YvcakotWvXLu3atUsXLlxwFIn2798vX19fpyuWbDabe6KsRP/+/bV58+YK1ycmJjolhQUFBYqIiKj1uAAAQMPmqXwpLCxMeXl5Tsvy8vIUGBiogIAA+fr6ytfXt9w2YWFhFe7X6pwqPz9fP577UbfrdgUruPrbK1+rz61Wfn4+J4nVxNg3TN5+3GsS/wEd0CZt8tq+o2Hy9tfsJS4VpUaMGKHmzZvrlVdeUcuWLSVJJ0+e1MSJE3XTTTfpkUcecWuQlUlPT1d4eHiF6+12e40uwwQAAHCFp/Kl2NhYrVu3zmnZxo0bFRsbK0ny8/NT3759lZKS4rgZe2lpqVJSUjRlypQK9+upnCpYwWqrtpY/Lhj7hsrbj7sr8ecr3+VtAU/z9uetS0WpuXPnasOGDY4ES5JatmypP//5zxoyZEiVk6zCwkJlZmY65rOyspSenq5WrVqpXbt2SkxM1HfffacVK1ZIkhYsWKDIyEhdd911OnfunF5++WV9/PHH2rBhgyvdAAAAqDWeypceeOABPffcc3rsscf029/+Vh9//LHefPNNvf/++459JCQkaPz48erXr5/69++vBQsWqKioyPFrfAAAAFZwqShVUFCg48ePl1l+/PhxnTlzpsr72b59u2655RbH/KVLwsePH6/k5GTl5OQoOzvbsf78+fN65JFH9N1336lJkybq2bOnPvroI6d9AAAA1AWeypciIyP1/vvv6+GHH9bChQt19dVX6+WXX1Z8fLyjzZgxY3T8+HFNnz5dubm5io6O1vr168vc/BwAAKA2uVSU+vWvf62JEydq7ty56t+/vyRp69atevTRR3X77bdXeT+DBg2SMRXfTC45Odlp/rHHHtNjjz3mSsgAAACW8lS+dGmbXbt2VbrfKVOmVPp1PQAAgNrmUlFq8eLFmjZtmsaOHasLFy78tKNGjXTvvfdqzpw5bg0QAADAG5EvAQAAVM6lolSTJk30/PPPa86cOTp48KAk6ZprrlHTpk3dGhwAAIC3Il8CAAConE9NNs7JyVFOTo46d+6spk2bVnppOQAAQENEvgQAAFA+l4pSJ06c0ODBg9WlSxfddtttysnJkSTde++9tfbzxgAAAN6EfAkAAKByLhWlHn74YTVu3FjZ2dlq0qSJY/mYMWO0fv16twUHAADgrciXAAAAKufSPaU2bNigDz/8UFdffbXT8s6dO+vw4cNuCQwAAMCbkS8BAABUzqUrpYqKipw+8bvkhx9+kN1ur3FQAAAA3o58CQAAoHIuFaVuuukmrVixwjFvs9lUWlqqZ555RrfccovbggMAAPBW5EsAAACVc+nre88884wGDx6s7du36/z583rssce0Z88e/fDDD/rss8/cHSMAAIDXIV8CAAConEtXSnXv3l379+/XjTfeqJEjR6qoqEi33367du3apWuuucbdMQIAAHgd8iUAAIDKVftKqQsXLmjo0KFavHix/u///q82YgIAAPBq5EsAAABXVu0rpRo3bqyvvvqqNmIBAACoF8iXAAAArsylr+/dc889Wrp0qbtjAQAAqDfIlwAAACrn0o3OL168qGXLlumjjz5S37591bRpU6f18+bNc0twAAAA3op8CQAAoHLVKkp9++236tChg3bv3q0+ffpIkvbv3+/UxmazuS86AAAAL0O+BAAAUDXVKkp17txZOTk52rRpkyRpzJgx+tvf/qbQ0NBaCQ4AAMDbkC8BAABUTbXuKWWMcZr/4IMPVFRU5NaAAAAAvBn5EgAAQNW4dKPzS36edAEAAMAZ+RIAAED5qlWUstlsZe6BwD0RAAAA/oN8CQAAoGqqdU8pY4wmTJggu90uSTp37pweeOCBMr8ms3r1avdFCAAA4EXIlwAAAKqmWkWp8ePHO83fc889bg0GAADA25EvAQAAVE21ilLLly+vrTgAAADqBfIlAACAqqnRjc4BAAAAAAAAV1CUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAOAFFi1apA4dOsjf318xMTHatm1bhW0HDRokm81WZho+fLijzYQJE8qsHzp0qBVdAQAAkCQ18nQAAAAAqNyqVauUkJCgxYsXKyYmRgsWLFB8fLwyMjIUEhJSpv3q1at1/vx5x/yJEyfUq1cvjR492qnd0KFDtXz5cse83W6vvU4AAAD8DFdKAQAA1HHz5s3TpEmTNHHiRHXr1k2LFy9WkyZNtGzZsnLbt2rVSmFhYY5p48aNatKkSZmilN1ud2rXsmVLK7oDAAAgiaIUAABAnXb+/Hnt2LFDcXFxjmU+Pj6Ki4tTWlpalfaxdOlS3XnnnWratKnT8tTUVIWEhCgqKkoPPvigTpw44dbYAQAAKsPX9wAAAOqw/Px8lZSUKDQ01Gl5aGio9u3bd8Xtt23bpt27d2vp0qVOy4cOHarbb79dkZGROnjwoP70pz9p2LBhSktLk6+vb5n9FBcXq7i42DFfUFDgYo8AAAB+QlEKAACgHlu6dKl69Oih/v37Oy2/8847Hf/v0aOHevbsqWuuuUapqakaPHhwmf0kJSVp5syZtR4vAABoOPj6HgAAQB0WHBwsX19f5eXlOS3Py8tTWFhYpdsWFRVp5cqVuvfee6/4OB07dlRwcLAyMzPLXZ+YmKjTp087piNHjlS9EwAAAOWgKAUAAFCH+fn5qW/fvkpJSXEsKy0tVUpKimJjYyvd9q233lJxcbHuueeeKz7O0aNHdeLECYWHh5e73m63KzAw0GkCAACoCYpSAAAAdVxCQoKWLFmiV155RXv37tWDDz6ooqIiTZw4UZI0btw4JSYmltlu6dKlGjVqlFq3bu20vLCwUI8++qg+//xzHTp0SCkpKRo5cqQ6deqk+Ph4S/oEAADAPaUAAADquDFjxuj48eOaPn26cnNzFR0drfXr1ztufp6dnS0fH+fPGjMyMrR582Zt2LChzP58fX311Vdf6ZVXXtGpU6fUtm1bDRkyRLNnz5bdbrekTwAAABSlAAAAvMCUKVM0ZcqUctelpqaWWRYVFSVjTLntAwIC9OGHH7ozPAAAgGrj63sAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy3m0KPXpp59qxIgRatu2rWw2m9asWXPFbVJTU9WnTx/Z7XZ16tRJycnJtR4nAAAAAAAA3MujRamioiL16tVLixYtqlL7rKwsDR8+XLfccovS09P10EMP6b777uMnjQEAAAAAALxMI08++LBhwzRs2LAqt1+8eLEiIyM1d+5cSVLXrl21efNmzZ8/X/Hx8bUVJgAAAAAAANzMq+4plZaWpri4OKdl8fHxSktL81BEAAAAAAAAcIVHr5SqrtzcXIWGhjotCw0NVUFBgX788UcFBASU2aa4uFjFxcWO+YKCglqPMzs7W/n5+S5tu3fvXjdHUz3eHLs7uNr/+tD3mqrJc0f66bVqt9st31aSgoOD1a5dO5e3rwtcfQ56uu81fd54On5v5umxr8njc9wBAADqB68qSrkiKSlJM2fOtOzxsrOz1TUqSmfPnbPsMd3Fm2N3h4be/5pwx9j5SirxwLaS1MTfX3szMrzyJDdHP13yes8997i0vSf77o7njTcfO0/y9NjX9PE57gAAAPWDVxWlwsLClJeX57QsLy9PgYGB5V4lJUmJiYlKSEhwzBcUFCgiIqLWYszPz9fZc+f0qqSuLmy/TtITbo6pqrw5dneoSf+9ve815a7nTk3G3tXH3ivpnnPnlJ+f75UnuKcklcq1/nu67zV93ng6fm/m6bGvyeNz3AEAAOoPrypKxcbGat26dU7LNm7cqNjY2Aq3sdvtNfpaj6u6SurjwnZ14Utg3hy7O7jS//rS95qq6XOnJmPv6mPXF97cf2+O3dt5euw9/fgAAADwLI/e6LywsFDp6elKT0+XJGVlZSk9PV3Z2dmSfrrKady4cY72DzzwgL799ls99thj2rdvn55//nm9+eabevjhhz0RPgAAAAAAAFzk0aLU9u3b1bt3b/Xu3VuSlJCQoN69e2v69OmSpJycHEeBSpIiIyP1/vvva+PGjerVq5fmzp2rl19+WfHx8R6JHwAAAAAAAK7x6Nf3Bg0aJGNMheuTk5PL3WbXrl21GBUAAAAAAABqm0evlAIAAAAAAEDDRFEKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAXmDRokXq0KGD/P39FRMTo23btlXYNjk5WTabzWny9/d3amOM0fTp0xUeHq6AgADFxcXpwIEDtd0NAAAAB4pSAAAAddyqVauUkJCgGTNmaOfOnerVq5fi4+P1/fffV7hNYGCgcnJyHNPhw4ed1j/zzDP629/+psWLF2vr1q1q2rSp4uPjde7cudruDgAAgCSKUgAAAHXevHnzNGnSJE2cOFHdunXT4sWL1aRJEy1btqzCbWw2m8LCwhxTaGioY50xRgsWLNDjjz+ukSNHqmfPnlqxYoWOHTumNWvWWNAjAAAAilIAAAB12vnz57Vjxw7FxcU5lvn4+CguLk5paWkVbldYWKj27dsrIiJCI0eO1J49exzrsrKylJub67TPoKAgxcTEVLpPAAAAd6IoBQAAUIfl5+erpKTE6UonSQoNDVVubm6520RFRWnZsmVau3atXn31VZWWlmrAgAE6evSoJDm2q84+i4uLVVBQ4DQBAADUBEUpAACAeiY2Nlbjxo1TdHS0Bg4cqNWrV6tNmzZ68cUXXd5nUlKSgoKCHFNERIQbIwYAAA0RRSkAAIA6LDg4WL6+vsrLy3NanpeXp7CwsCrto3Hjxurdu7cyMzMlybFddfaZmJio06dPO6YjR45UtysAAABOKEoBAADUYX5+furbt69SUlIcy0pLS5WSkqLY2Ngq7aOkpERff/21wsPDJUmRkZEKCwtz2mdBQYG2bt1a4T7tdrsCAwOdJgAAgJpo5OkAAAAAULmEhASNHz9e/fr1U//+/bVgwQIVFRVp4sSJkqRx48bpqquuUlJSkiRp1qxZuv7669WpUyedOnVKc+bM0eHDh3XfffdJ+umX+R566CH9+c9/VufOnRUZGaknnnhCbdu21ahRozzVTQAA0MBQlAIAAKjjxowZo+PHj2v69OnKzc1VdHS01q9f77hReXZ2tnx8/nMB/MmTJzVp0iTl5uaqZcuW6tu3r7Zs2aJu3bo52jz22GMqKirS/fffr1OnTunGG2/U+vXr5e/vb3n/AABAw0RRCgAAwAtMmTJFU6ZMKXddamqq0/z8+fM1f/78Svdns9k0a9YszZo1y10hAgAAVAv3lAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsVyeKUosWLVKHDh3k7++vmJgYbdu2rcK2ycnJstlsTpO/v7+F0QIAAAAAAKCmPF6UWrVqlRISEjRjxgzt3LlTvXr1Unx8vL7//vsKtwkMDFROTo5jOnz4sIURAwAAAAAAoKY8XpSaN2+eJk2apIkTJ6pbt25avHixmjRpomXLllW4jc1mU1hYmGMKDQ21MGIAAAAAAADUlEeLUufPn9eOHTsUFxfnWObj46O4uDilpaVVuF1hYaHat2+viIgIjRw5Unv27KmwbXFxsQoKCpwmAAAAAAAAeJZHi1L5+fkqKSkpc6VTaGiocnNzy90mKipKy5Yt09q1a/Xqq6+qtLRUAwYM0NGjR8ttn5SUpKCgIMcUERHh9n4AAAAAAACgejz+9b3qio2N1bhx4xQdHa2BAwdq9erVatOmjV588cVy2ycmJur06dOO6ciRIxZHDAAAAAAAgJ9r5MkHDw4Olq+vr/Ly8pyW5+XlKSwsrEr7aNy4sXr37q3MzMxy19vtdtnt9hrHCgAAAAAAAPfx6JVSfn5+6tu3r1JSUhzLSktLlZKSotjY2Crto6SkRF9//bXCw8NrK0wAAAAAAAC4mUevlJKkhIQEjR8/Xv369VP//v21YMECFRUVaeLEiZKkcePG6aqrrlJSUpIkadasWbr++uvVqVMnnTp1SnPmzNHhw4d13333ebIbAAAAAAAAqAaPF6XGjBmj48ePa/r06crNzVV0dLTWr1/vuPl5dna2fHz+c0HXyZMnNWnSJOXm5qply5bq27evtmzZom7dunmqCwAAAAAAAKgmjxelJGnKlCmaMmVKuetSU1Od5ufPn6/58+dbEBUAAAAAAABqi9f9+h4AAAAAAAC8H0UpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAA8AKLFi1Shw4d5O/vr5iYGG3btq3CtkuWLNFNN92kli1bqmXLloqLiyvTfsKECbLZbE7T0KFDa7sbAAAADhSlAAAA6rhVq1YpISFBM2bM0M6dO9WrVy/Fx8fr+++/L7d9amqq7rrrLm3atElpaWmKiIjQkCFD9N133zm1Gzp0qHJychzTG2+8YUV3AAAAJFGUAgAAqPPmzZunSZMmaeLEierWrZsWL16sJk2aaNmyZeW2f+211/S73/1O0dHRuvbaa/Xyyy+rtLRUKSkpTu3sdrvCwsIcU8uWLa3oDgAAgCSKUgAAAHXa+fPntWPHDsXFxTmW+fj4KC4uTmlpaVXax9mzZ3XhwgW1atXKaXlqaqpCQkIUFRWlBx98UCdOnHBr7AAAAJVp5OkAAAAAULH8/HyVlJQoNDTUaXloaKj27dtXpX384Q9/UNu2bZ0KW0OHDtXtt9+uyMhIHTx4UH/60580bNgwpaWlydfXt8w+iouLVVxc7JgvKChwsUcAAAA/oSgFAABQjz399NNauXKlUlNT5e/v71h+5513Ov7fo0cP9ezZU9dcc41SU1M1ePDgMvtJSkrSzJkzLYkZAAA0DHx9DwAAoA4LDg6Wr6+v8vLynJbn5eUpLCys0m2fffZZPf3009qwYYN69uxZaduOHTsqODhYmZmZ5a5PTEzU6dOnHdORI0eq1xEAAICfoSgFAABQh/n5+alv375ONym/dNPy2NjYCrd75plnNHv2bK1fv179+vW74uMcPXpUJ06cUHh4eLnr7Xa7AgMDnSYAAICaoCgFAABQxyUkJGjJkiV65ZVXtHfvXj344IMqKirSxIkTJUnjxo1TYmKio/1f//pXPfHEE1q2bJk6dOig3Nxc5ebmqrCwUJJUWFioRx99VJ9//rkOHTqklJQUjRw5Up06dVJ8fLxH+ggAABoe7ikFAABQx40ZM0bHjx/X9OnTlZubq+joaK1fv95x8/Ps7Gz5+Pzns8YXXnhB58+f13//93877WfGjBl68skn5evrq6+++kqvvPKKTp06pbZt22rIkCGaPXu27Ha7pX0DAAANF0UpAAAALzBlyhRNmTKl3HWpqalO84cOHap0XwEBAfrwww/dFBkAAIBr+PoeAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpQAAAAAAAGA5ilIAAAAAAACwHEUpAAAAAAAAWI6iFAAAAAAAACxHUQoAAAAAAACWoygFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABguTpRlFq0aJE6dOggf39/xcTEaNu2bZW2f+utt3TttdfK399fPXr00Lp16yyKFAAAwDPcnS8ZYzR9+nSFh4crICBAcXFxOnDgQG12AQAAwInHi1KrVq1SQkKCZsyYoZ07d6pXr16Kj4/X999/X277LVu26K677tK9996rXbt2adSoURo1apR2795tceQAAADWqI186ZlnntHf/vY3LV68WFu3blXTpk0VHx+vc+fOWdUtAADQwHm8KDVv3jxNmjRJEydOVLdu3bR48WI1adJEy5YtK7f9woULNXToUD366KPq2rWrZs+erT59+ui5556zOHIAAABruDtfMsZowYIFevzxxzVy5Ej17NlTK1as0LFjx7RmzRoLewYAABoyjxalzp8/rx07diguLs6xzMfHR3FxcUpLSyt3m7S0NKf2khQfH19hewAAAG9WG/lSVlaWcnNzndoEBQUpJiaGnAoAAFimkScfPD8/XyUlJQoNDXVaHhoaqn379pW7TW5ubrntc3Nzy21fXFys4uJix/zp06clSQUFBTUJvUKFhYWSpB2SCl3Yfu///6+r22dc2n7HDkcsVd42I6NGj13T2D3Zd6lm/ff2vks/neCUlpa6tK0nnzuMnVze3tv77un4a7Ktp7f39NjX5PEvPXZhYWGt/C2/tE9jjNv37arayJcu/esNOVWOcnRe56u9/QmdkOT689SbX+M13f7Sa9QTY+/Jx77Em4+dtx73SzwV/3Edd3lbyfN99/btvTl2T27vrtesx3Mq40HfffedkWS2bNnitPzRRx81/fv3L3ebxo0bm9dff91p2aJFi0xISEi57WfMmGEkMTExMTExMTFVeTpy5Ih7kh03qI186bPPPjOSzLFjx5zajB492txxxx3l7pOciomJiYmJiam605VyKo9eKRUcHCxfX1/l5eU5Lc/Ly1NYWFi524SFhVWrfWJiohISEhzzpaWl+uGHH9S6dWvZbDaX4i4oKFBERISOHDmiwMBAl/aB8jG2tYexrV2Mb+1hbGsX4+vMGKMzZ86obdu2ng7FoTbypUv/5uXlKTw83KlNdHR0ufusjZyqrmvIr4+G3HeJ/tN/+t9Q+9+Q+y65t/9Vzak8WpTy8/NT3759lZKSolGjRkn6KcFJSUnRlClTyt0mNjZWKSkpeuihhxzLNm7cqNjY2HLb2+122e12p2UtWrRwR/gKDAxskE9UKzC2tYexrV2Mb+1hbGsX4/sfQUFBng7BSW3kS5GRkQoLC1NKSoqjCFVQUKCtW7fqwQcfLHeftZlT1XUN+fXRkPsu0X/6T/8bav8bct8l9/W/KjmVR4tSkpSQkKDx48erX79+6t+/vxYsWKCioiJNnDhRkjRu3DhdddVVSkpKkiRNnTpVAwcO1Ny5czV8+HCtXLlS27dv10svveTJbgAAANQad+dLNptNDz30kP785z+rc+fOioyM1BNPPKG2bds6Cl8AAAC1zeNFqTFjxuj48eOaPn26cnNzFR0drfXr1ztuvJmdnS0fn//8SOCAAQP0+uuv6/HHH9ef/vQnde7cWWvWrFH37t091QUAAIBaVRv50mOPPaaioiLdf//9OnXqlG688UatX79e/v7+lvcPAAA0TB4vSknSlClTKrz8PDU1tcyy0aNHa/To0bUcVcXsdrtmzJhR5hJ21BxjW3sY29rF+NYexrZ2Mb7ew935ks1m06xZszRr1ix3hVjvNOTXR0Puu0T/6T/9b6j9b8h9lzzTf5sxdeg3jwEAAAAAANAg+Fy5CQAAAAAAAOBeFKUAAAAAAABgOYpSAAAAAAAAsBxFqQosWrRIHTp0kL+/v2JiYrRt27YK265evVr9+vVTixYt1LRpU0VHR+sf//iHhdF6l+qM7eVWrlwpm83GT1VXojpjm5ycLJvN5jTxi0uVq+5z99SpU5o8ebLCw8Nlt9vVpUsXrVu3zqJovUt1xnbQoEFlnrs2m03Dhw+3MGLvUd3n7YIFCxQVFaWAgABFRETo4Ycf1rlz5yyKFqhd1Xk9LFmyRDfddJNatmypli1bKi4urkx7Y4ymT5+u8PBwBQQEKC4uTgcOHKjtbrjM3f2fMGFCmffioUOH1nY3XObu/L4+H/+q9N+bjr+7zz/q87G/XEX996ZjL7n/HKk+H/+q9N/tx9+gjJUrVxo/Pz+zbNkys2fPHjNp0iTTokULk5eXV277TZs2mdWrV5tvvvnGZGZmmgULFhhfX1+zfv16iyOv+6o7tpdkZWWZq666ytx0001m5MiR1gTrZao7tsuXLzeBgYEmJyfHMeXm5loctfeo7vgWFxebfv36mdtuu81s3rzZZGVlmdTUVJOenm5x5HVfdcf2xIkTTs/b3bt3G19fX7N8+XJrA/cC1R3b1157zdjtdvPaa6+ZrKws8+GHH5rw8HDz8MMPWxw54H7VfT2MHTvWLFq0yOzatcvs3bvXTJgwwQQFBZmjR4862jz99NMmKCjIrFmzxnz55ZfmV7/6lYmMjDQ//vijVd2qstro//jx483QoUOd3pN/+OEHq7pULbWR39fn41+V/nvL8a+N84/6fOwvqaz/3nLsjamdc6T6fPyr0n93H3+KUuXo37+/mTx5smO+pKTEtG3b1iQlJVV5H7179zaPP/54bYTn1VwZ24sXL5oBAwaYl19+2YwfP56iVAWqO7bLly83QUFBFkXn/ao7vi+88ILp2LGjOX/+vFUheq2avufOnz/fNG/e3BQWFtZWiF6rumM7efJk88tf/tJpWUJCgrnhhhtqNU7ACjV9r7l48aJp3ry5eeWVV4wxxpSWlpqwsDAzZ84cR5tTp04Zu91u3njjDfcG7wbu7r8xxqvyMnfn9w3t+BtT9vzGW46/u88/GsKxv9L5l7cce2Pcf45U349/Vc4R3X38+frez5w/f147duxQXFycY5mPj4/i4uKUlpZ2xe2NMUpJSVFGRoZuvvnm2gzV67g6trNmzVJISIjuvfdeK8L0Sq6ObWFhodq3b6+IiAiNHDlSe/bssSJcr+PK+L777ruKjY3V5MmTFRoaqu7du+upp55SSUmJVWF7hZq+50rS0qVLdeedd6pp06a1FaZXcmVsBwwYoB07djgu6/7222+1bt063XbbbZbEDNQWd7zXnD17VhcuXFCrVq0kSVlZWcrNzXXaZ1BQkGJiYqq8T6vURv8vSU1NVUhIiKKiovTggw/qxIkTbo3dHWojv29Ix7+y85u6fvxr4/yjIRz7qpx/1fVjL9XOOVJDOP5VOUd05/Fv5PKW9VR+fr5KSkoUGhrqtDw0NFT79u2rcLvTp0/rqquuUnFxsXx9ffX888/r1ltvre1wvYorY7t582YtXbpU6enpFkTovVwZ26ioKC1btkw9e/bU6dOn9eyzz2rAgAHas2ePrr76aivC9hqujO+3336rjz/+WHfffbfWrVunzMxM/e53v9OFCxc0Y8YMK8L2Cq6+516ybds27d69W0uXLq2tEL2WK2M7duxY5efn68Ybb5QxRhcvXtQDDzygP/3pT1aEDNSamr7XSNIf/vAHtW3b1pHc5+bmOvbx831eWldX1Eb/JWno0KG6/fbbFRkZqYMHD+pPf/qThg0bprS0NPn6+rq1DzVRG/l9Qzj+Vzq/8YbjXxvnH/X92Ffl/Msbjr1UO+dI9f34V+Uc0d3Hn6KUmzRv3lzp6ekqLCxUSkqKEhIS1LFjRw0aNMjToXmtM2fO6De/+Y2WLFmi4OBgT4dT78TGxio2NtYxP2DAAHXt2lUvvviiZs+e7cHI6ofS0lKFhITopZdekq+vr/r27avvvvtOc+bMoSjlRkuXLlWPHj3Uv39/T4dSL6Smpuqpp57S888/r5iYGGVmZmrq1KmaPXu2nnjiCU+HB3jM008/rZUrVyo1NbVB/ihIRf2/8847Hf/v0aOHevbsqWuuuUapqakaPHiwJ0J1q4ae31+p//Xx+Df084+q9r8+HvtLGvo5UlX67+7jT1HqZ4KDg+Xr66u8vDyn5Xl5eQoLC6twOx8fH3Xq1EmSFB0drb179yopKanB/NGqiuqO7cGDB3Xo0CGNGDHCsay0tFSS1KhRI2VkZOiaa66p3aC9hKvP28s1btxYvXv3VmZmZm2E6NVcGd/w8HA1btzY6dOCrl27Kjc3V+fPn5efn1+txuwtavLcLSoq0sqVKzVr1qzaDNFruTK2TzzxhH7zm9/ovvvuk/RTolFUVKT7779f//d//ycfH771D+9Uk/eaZ599Vk8//bQ++ugj9ezZ07H80nZ5eXkKDw932md0dLT7gneD2uh/eTp27Kjg4GBlZmbWqRPT2sjvG8Lxr+75TV08/rVx/lGfj72r51918dhLtXOOVJ+Pf3mqco5Y0+NPdvkzfn5+6tu3r1JSUhzLSktLlZKS4lQxvJLS0lIVFxfXRoheq7pje+211+rrr79Wenq6Y/rVr36lW265Renp6YqIiLAy/DrNHc/bkpISff31105vrviJK+N7ww03KDMz0/GHXJL279+v8PBwClKXqclz96233lJxcbHuueee2g7TK7kytmfPni1TeLpUWDXG1F6wQC1z9b3mmWee0ezZs7V+/Xr169fPaV1kZKTCwsKc9llQUKCtW7dWK2e0Qm30vzxHjx7ViRMn6lwuURv5fUM4/j93pfObunj8a+P8oz4fe1fPv+risZdq5xypPh//8lTlHLHGx99tt0yvR1auXGnsdrtJTk4233zzjbn//vtNixYtHD+F+Jvf/Mb88Y9/dLR/6qmnzIYNG8zBgwfNN998Y5599lnTqFEjs2TJEk91oc6q7tj+nDf90oPVqju2M2fONB9++KE5ePCg2bFjh7nzzjuNv7+/2bNnj6e6UKdVd3yzs7NN8+bNzZQpU0xGRoZ57733TEhIiPnzn//sqS7UWa6+L9x4441mzJgxVofrVao7tjNmzDDNmzc3b7zxhvn222/Nhg0bzDXXXGPuuOMOT3UBcJvqvh6efvpp4+fnZ/75z386/ez1mTNnnNq0aNHCrF271nz11Vdm5MiRdfpnwd3Z/zNnzphp06aZtLQ0k5WVZT766CPTp08f07lzZ3Pu3DmP9LEytZHf1+fjf6X+e9Pxr43zj/p87H/u5/33pmNvTO2cI9Xn43+l/tfG8acoVYG///3vpl27dsbPz8/079/ffP755451AwcONOPHj3fM/9///Z/p1KmT8ff3Ny1btjSxsbFm5cqVHojaO1RnbH+OolTlqjO2Dz30kKNtaGioue2228zOnTs9ELX3qO5zd8uWLSYmJsbY7XbTsWNH85e//MVcvHjR4qi9Q3XHdt++fUaS2bBhg8WRep/qjO2FCxfMk08+aa655hrj7+9vIiIizO9+9ztz8uRJ6wMHakF1Xg/t27c3kspMM2bMcLQpLS01TzzxhAkNDTV2u90MHjzYZGRkWNij6nFn/8+ePWuGDBli2rRpYxo3bmzat29vJk2a5DjRqYvcnd/X5+N/pf572/F39/lHfT72P/fz/nvbsTfG/edI9fn4X6n/tXH8bcZwPT4AAAAAAACsxT2lAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJajKAUAAAAAAADLUZQCAAAAAACA5ShKAQAAAAAAwHIUpeAVkpOT1aJFiyu2s9lsWrNmTa3HU1V1LR53mjBhgkaNGlVpm9TUVNlsNp06dcqSmDzpySefVHR0tKfD8JgOHTpowYIFNd7P0qVLNWTIkJoH5EGHDh2SzWZTenr6Fdvm5+crJCRER48erf3AAEDkVHUROZUzcipyqkvIqRoGilLwCmPGjNH+/fsd897yxyonJ0fDhg2rUtvaSrau9GY+c+ZM3XPPPdXe78KFC5WcnOyYHzRokB566CHXgqyhupCoTZs2TSkpKVVqW5vP36oktjVR0cnMF198ofvvv79G+z537pyeeOIJzZgxo0b78SbBwcEaN25cg+ozAM8ip3IdOZU1yKnIqVxBTuW9KErBKwQEBCgkJMTTYVRbWFiY7Ha7p8Oo1Nq1a/WrX/2q2tsFBQVV6ZPWhqJZs2Zq3bq1p8Nw2fnz52u0fZs2bdSkSZMa7eOf//ynAgMDdcMNN9RoP95m4sSJeu211/TDDz94OhQADQA5Ve0hp3IPcipyKleRU3kpA3jAv/71LxMUFGQuXrxojDFm165dRpL5wx/+4Ghz7733mrvvvtsYY8zy5ctNUFCQ4/+SnKbly5cbY4yRZJYsWWJGjRplAgICTKdOnczatWsrjWXFihWmb9++plmzZiY0NNTcddddJi8vz7H+hx9+MGPHjjXBwcHG39/fdOrUySxbtswYY0xxcbGZPHmyCQsLM3a73bRr18489dRTjm0lmXfeeeeKbdu3b+/Un/bt2xtjjMnMzDS/+tWvTEhIiGnatKnp16+f2bhxo1P87du3N3/5y1/MxIkTTbNmzUxERIR58cUXnWK4fBo4cKBjXXZ2tvHz8zOnT582jzzyiBk+fLhj3fz5840k88EHHziWXXPNNWbJkiXGGGPGjx9vRo4c6fj/zx8nKyvLbNq0yUgyH330kenbt68JCAgwsbGxZt++fU59eP75503Hjh1N48aNTZcuXcyKFSsc67Kysowks2vXLseykydPGklm06ZNjvWXT+PHjy/3WOfn55s777zTtG3b1gQEBJju3bub119/3anNW2+9Zbp37278/f1Nq1atzODBg01hYaExxphNmzaZX/ziF6ZJkyYmKCjIDBgwwBw6dMgYY8yMGTNMr169HPupqG1lz9+5c+ea7t27myZNmpirr77aPPjgg+bMmTOOfV56Haxfv95ce+21pmnTpiY+Pt4cO3bMEcPP971p06Zyx2LgwIFm8uTJZurUqaZ169Zm0KBBV4zh0vG8fJoxY4Yx5qfn4fz58x37P3z4sPnVr35lmjZtapo3b25Gjx5tcnNzy43lkuHDh5tp06Y5LatszI0xZs2aNaZ3797GbrebyMhI8+STT5oLFy441p88edLcf//9JiQkxNjtdnPdddeZf/3rX471//znP023bt2Mn5+fad++vXn22WedHv9Kry9jjNm6dauJjo42drvd9O3b16xevdrpOVvZe8glkZGR5uWXX650fACgPORU5FSXI6dabowhpyKnIqfyJhSl4BGnTp0yPj4+5osvvjDGGLNgwQITHBxsYmJiHG06derk+GN9eQJ19uxZ88gjj5jrrrvO5OTkmJycHHP27FljzE/JwtVXX21ef/11c+DAAfP73//eNGvWzJw4caLCWJYuXWrWrVtnDh48aNLS0kxsbKwZNmyYY/3kyZNNdHS0+eKLL0xWVpbZuHGjeffdd40xxsyZM8dERESYTz/91Bw6dMj8+9//dvqDfHkCVVnb77//3vGHNCcnx3z//ffGGGPS09PN4sWLzddff232799vHn/8cePv728OHz7seIz27dubVq1amUWLFpkDBw6YpKQk4+Pj40hStm3b5khicnJynMbiueeeM0OGDDHGGPPuu+86JbWjRo0ywcHBjqT26NGjRpI5cOCAMcY5gTp16pSJjY01kyZNchyTixcvOv7gxsTEmNTUVLNnzx5z0003mQEDBjhiWL16tWncuLFZtGiRycjIMHPnzjW+vr7m448/NsZcOYG6ePGiefvtt40kk5GRYXJycsypU6fKPdZHjx41c+bMMbt27TIHDx40f/vb34yvr6/ZunWrMcaYY8eOmUaNGpl58+aZrKws89VXX5lFixaZM2fOmAsXLpigoCAzbdo0k5mZab755huTnJzsOBaXJ1CVta3s+Tt//nzz8ccfm6ysLJOSkmKioqLMgw8+6Ih/+fLlpnHjxiYuLs588cUXZseOHaZr165m7Nixxhhjzpw5Y+644w4zdOhQx76Li4vLHYuBAweaZs2amUcffdTs27fP8XypLIbi4mKzYMECExgY6Nj/peTq8gSqpKTEREdHmxtvvNFs377dfP7556Zv375OyXt5goKCzMqVKx3zVxrzTz/91AQGBprk5GRz8OBBs2HDBtOhQwfz5JNPOuK4/vrrzXXXXWc2bNhgDh48aP71r3+ZdevWGWOM2b59u/Hx8TGzZs0yGRkZZvny5SYgIMCR0F7qV2WvrzNnzpg2bdqYsWPHmt27d5t//etfpmPHjk7P2creQy4ZM2ZMhYk/AFSGnIqc6hJyKnKqS8ipxlc6PqhbKErBY/r06WPmzJljjPnpj/Vf/vIX4+fnZ86cOeP4Y71//35jjHMCZUzZT1AukWQef/xxx3xhYWGZT6au5IsvvjCSHH8YRowYYSZOnFhu2//93/81v/zlL01paWm56y9PoKrTtjLXXXed+fvf/+6Yb9++vbnnnnsc86WlpSYkJMS88MILxpjyE5BLbr31VvPcc88ZY35KSi4ltaWlpaZVq1YmKSnJkdS++uqr5qqrrnJse3kCZcxPf5CnTp3qtP/LP9W75P333zeSzI8//miMMWbAgAFm0qRJTtuNHj3a3HbbbRXGf3kCdfnjnDx5spKRK9/w4cPNI488YowxZseOHUaS06dGl5w4ccJIMqmpqeXu5/LnZHXaVuatt94yrVu3dsxf+kQwMzPTsWzRokUmNDTUMf/z41KRgQMHmt69e7sUw+WvxUsuT6A2bNhgfH19TXZ2tmP9nj17jCSzbdu2ch/n0jH99NNPHcuuNI6DBw92+hTdGGP+8Y9/mPDwcGOMMR9++KHx8fExGRkZ5W4/duxYc+uttzote/TRR023bt2c+lXZ6+vFF180rVu3djyfjTHmhRdecHrOVvYecsnDDz/s+GQVAKqLnKritpUhpyKnIqf6CTkVPIl7SsFjBg4cqNTUVBlj9O9//1u33367unbtqs2bN+uTTz5R27Zt1blz52rvt2fPno7/N23aVIGBgfr+++8rbL9jxw6NGDFC7dq1U/PmzTVw4EBJUnZ2tiTpwQcf1MqVKxUdHa3HHntMW7ZscWw7YcIEpaenKyoqSr///e+1YcOGCh+nOm0vKSws1LRp09S1a1e1aNFCzZo10969ex2xlddnm82msLCwSvssSQUFBfrkk08c9z5o0aKFevXqpdTUVH399dfy8/PT/fffr127dqmwsFCffPKJY2yq6/L4wsPDJckR3969e8t83/2GG27Q3r17XXqsypSUlGj27Nnq0aOHWrVqpWbNmunDDz90jGevXr00ePBg9ejRQ6NHj9aSJUt08uRJSVKrVq00YcIExcfHa8SIEVq4cKFycnLKfZzqtL3cRx99pMGDB+uqq65S8+bN9Zvf/EYnTpzQ2bNnHW2aNGmia665xjEfHh5+xWNdkb59+7oUw5Xs3btXERERioiIcCzr1q2bWrRoUeFx/fHHHyVJ/v7+jmVXGscvv/xSs2bNUrNmzRzTpEmTlJOTo7Nnzyo9PV1XX321unTpUmGc5T33Dhw4oJKSEseyyl5fe/fuVc+ePZ3ijo2NddpnZe8hlwQEBFRrjAHgcuRU5FQSOdXlyKnIqeA9KErBYwYNGqTNmzfryy+/VOPGjXXttddq0KBBSk1NrdEf68aNGzvN22w2lZaWltu2qKhI8fHxCgwM1GuvvaYvvvhC77zzjqT/3KRw2LBhOnz4sB5++GEdO3ZMgwcP1rRp0yRJffr0UVZWlmbPnq0ff/xRd9xxh/77v/+73MeqTttLpk2bpnfeeUdPPfWU/v3vfys9PV09evQocwPF6vT5kg8++EDdunVz+iP38/Fv1aqVU1LrjmNis9kk6YrxXeLj89PblDHGsezChQsuxTFnzhwtXLhQf/jDH7Rp0yalp6crPj7eMZ6+vr7auHGjY2z+/ve/KyoqSllZWZKk5cuXKy0tTQMGDNCqVavUpUsXff755+U+VnXaSj/9os//+3//Tz179tTbb7+tHTt2aNGiRZKcb5hZ3rG+fGyqo2nTpi7FUBtat24tm83mSFgvqWwcCwsLNXPmTKWnpzumr7/+WgcOHJC/v78CAgLcEpsrr6/LVfYecskPP/ygNm3auCVeAA0PORU5VVWQU5FTkVOhLqIoBY+56aabdObMGc2fP9/xh/nSH/DU1FQNGjSowm39/Pycqu6u2rdvn06cOKGnn35aN910k6699tpyPyFp06aNxo8fr1dffVULFizQSy+95FgXGBioMWPGaMmSJVq1apXefvvtCn/xobK2jRs3LtOnzz77TBMmTNCvf/1r9ejRQ2FhYTp06FC1+ujn5ydJZfa9du1ajRw50mnZwIEDtXnzZqWkpDjGf9CgQXrjjTe0f//+WjkmXbt21Weffea07LPPPlO3bt0kyfFH5fJPc37+U8wV9fHnPvvsM40cOVL33HOPevXqpY4dOzr9LLb00x/HG264QTNnztSuXbvk5+fnSKolqXfv3kpMTNSWLVvUvXt3vf766xU+XkVtyxurHTt2qLS0VHPnztX111+vLl266NixY5X2pzw1eW1UJYaq7L9r1646cuSIjhw54lj2zTff6NSpU47jWl7c3bp10zfffFNmXUXj2KdPH2VkZKhTp05lJh8fH/Xs2VNHjx4tc4wvj7O8516XLl3k6+tbaR8v38dXX32lc+fOOZaVlyhX9h4iSbt371bv3r2r9JgA8HPkVORUEjnVJeRU5FTkVN6FohQ8pmXLlurZs6dee+01xx/mm2++WTt37tT+/fsr/QSpQ4cOysrKUnp6uvLz81VcXOxSDO3atZOfn5/+/ve/69tvv9W7776r2bNnO7WZPn261q5dq8zMTO3Zs0fvvfeeunbtKkmaN2+e3njjDe3bt0/79+/XW2+9pbCwsHJ/1vdKbTt06KCUlBTl5uY6Ptno3LmzVq9erfT0dH355ZcaO3ZstT5NkKSQkBAFBARo/fr1ysvL0+nTp3Xx4kV98MEHZX62+Oabb9aZM2f03nvvOSVQr732msLDwyu8ZPdS/Fu3btWhQ4eUn59f5TgfffRRJScn64UXXtCBAwc0b948rV692vGpR0BAgK6//no9/fTT2rt3rz755BM9/vjjTvto3769bDab3nvvPR0/flyFhYXlPlbnzp21ceNGbdmyRXv37tX//M//KC8vz7F+69ateuqpp7R9+3ZlZ2dr9erVOn78uLp27aqsrCwlJiYqLS1Nhw8f1oYNG3TgwAHHc+FyV2pb3vO3U6dOunDhguO5+I9//EOLFy+u0hherkOHDvrqq6+UkZGh/Pz8an0CWpUYOnTooMLCQqWkpCg/P7/cy6Pj4uLUo0cP3X333dq5c6e2bdumcePGaeDAgerXr1+Fjx8fH6/Nmzc75q80jtOnT9eKFSs0c+ZM7dmzR3v37tXKlSsdz4+BAwfq5ptv1n/9139p48aNysrK0gcffKD169dLkh555BGlpKRo9uzZ2r9/v1555RU999xzZT5xq8zYsWNls9k0adIkffPNN1q3bp2effZZpzaVvYdI0tmzZ7Vjxw4NGTKkyo8LAJcjpyKnksipyKn+g5yKnMqrePKGVsDUqVONJLN3717Hsl69epmwsDCndj+/EeC5c+fMf/3Xf5kWLVqU+fnin9/YMigoyOmXH37u9ddfNx06dDB2u93Exsaad9991+mGerNnzzZdu3Y1AQEBplWrVmbkyJHm22+/NcYY89JLL5no6GjTtGlTExgYaAYPHmx27tzp2Pfl8Vyp7bvvvms6depkGjVq5Pj54qysLHPLLbeYgIAAExERYZ577rkyN7/8+c/GXhrDSz8ra4wxS5YsMREREcbHx8cMHDjQfPTRR+bqq68udzx+Pv4nTpwwNpvN3HnnnU7tfn7zx4yMDHP99debgICAMj9ffPnNMi/9VHVWVpZjWWU/X2yMMd98842JjY01AQEBJjo62mzYsKHMT/POmjXLhIWFGZvNVuEvbpw4ccKMHDnSNGvWzISEhJjHH3/cjBs3ztGPb775xsTHx5s2bdoYu91uunTp4rgBam5urhk1apQJDw93/NTt9OnTTUlJiTHG+UabV2pb0fN33rx5Jjw83AQEBJj4+HizYsUKp/Er74aY77zzjrn8rfz77783t956q2nWrNkVf7745zdRrUoMxhjzwAMPmNatW7v954v37NljAgICHL/0c6VxNMaY9evXmwEDBpiAgAATGBho+vfvb1566SXH+hMnTpiJEyea1q1bG39/f9O9e3fz3nvvOdZf+vnixo0bm3bt2jluFHxJVV5faWlpplevXsbPz89ER0c7frmoKu8hxvz0HhQVFVXp2ADAlZBTkVMZQ05FTvUTcip4E5sxLn5xFoDX+v3vf6+LFy/q+eef93QogJPRo0erT58+SkxM9HQolrn++uv1+9//XmPHjvV0KACAaiKnQl1FTgVvwdf3gAaoe/fuevDBBz0dBlDGnDlz1KxZM0+HYZn8/HzdfvvtuuuuuzwdCgDABeRUqKvIqeAtuFIKAAAAAAAAluNKKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALPf/ATJyrm6CHFTfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average speedup ratio:  0.6675987414759067\n",
      "Average time with assistant:  3.4167099459008092\n",
      "Average time without assistant:  5.466208314115093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▍                                                            | 10/105 [01:09<10:56,  6.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m max_new_tokens \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 12\u001b[0m test_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search_assistant_pld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcode_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdraft_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m              \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m              \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStoppingCriteriaList\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMaxLengthCriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43massistant_prompt_matching_window_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43massistant_prompt_candidate_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43massistant_draft_candidate_rounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_draft_num_candidate_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m              \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m              \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprint_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     29\u001b[0m time_taken[lt][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 92\u001b[0m, in \u001b[0;36mgreedy_search_assistant_pld\u001b[0;34m(self, input_ids, code_ids, assistant_model, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, assistant_prompt_matching_window_size, assistant_prompt_candidate_tokens, assistant_draft_candidate_rounds, max_draft_num_candidate_tokens, print_output, **model_kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(candidate_input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcandidate_kwargs)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m new_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39mcandidate_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :]  \u001b[38;5;66;03m# excludes the input prompt if present\u001b[39;00m\n\u001b[1;32m    101\u001b[0m selected_tokens \u001b[38;5;241m=\u001b[39m new_logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1034\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1031\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:686\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    685\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 686\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:258\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lt in lookup_tokens:\n",
    "    for row in tqdm(ds):\n",
    "        input_text = \"## Code Before:\\n{code_text}\\n## Instruction: {question}\\n## Code After:\\n\".format(code_text=row['before'], question=row['instruction_descriptive'])\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(model.device)\n",
    "        code_ids = tokenizer(row['before'], return_tensors=\"pt\").input_ids[0].tolist()\n",
    "            \n",
    "        max_new_tokens = inputs['input_ids'].shape[-1] + 300\n",
    "    \n",
    "        start_time = time.perf_counter()\n",
    "        test_out = model.greedy_search_assistant_pld(inputs.input_ids,\n",
    "                        code_ids,\n",
    "                        draft_model,\n",
    "                      attention_mask = inputs.attention_mask,\n",
    "                      stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=len(inputs.input_ids[0]) + max_new_tokens)]),\n",
    "                    assistant_prompt_matching_window_size = 5,\n",
    "                    assistant_prompt_candidate_tokens = lt,\n",
    "                    assistant_draft_candidate_rounds = 4,\n",
    "                    max_draft_num_candidate_tokens = 1000,\n",
    "                      use_cache=True, \n",
    "                      pad_token_id=tokenizer.pad_token_id,\n",
    "                      eos_token_id=tokenizer.eos_token_id,\n",
    "                    print_output=False,\n",
    "                    seed=10\n",
    "                )\n",
    "        end_time = time.perf_counter()\n",
    "    \n",
    "        time_taken[lt][\"with_assistant\"].append(end_time - start_time)\n",
    "        outputs[lt][\"with_assistant\"].append(tokenizer.batch_decode(test_out))\n",
    "    \n",
    "        start_time = time.perf_counter()\n",
    "        test_out = model.greedy_search_pld(inputs.input_ids,\n",
    "                      attention_mask = inputs.attention_mask,\n",
    "                      stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=len(inputs.input_ids[0]) + max_new_tokens)]),\n",
    "                    draft_matching_window_size = 10,\n",
    "                    draft_num_candidate_tokens = lt,\n",
    "                      use_cache=True, \n",
    "                      pad_token_id=tokenizer.pad_token_id,\n",
    "                      eos_token_id=tokenizer.eos_token_id,\n",
    "                     print_output=False,\n",
    "                    seed=10\n",
    "                )\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        time_taken[lt][\"without_assistant\"].append(end_time - start_time)\n",
    "        outputs[lt][\"without_assistant\"].append(tokenizer.batch_decode(test_out))\n",
    "    \n",
    "        # print(time_taken[lt][\"with_assistant\"][-1], time_taken[lt][\"without_assistant\"][-1])\n",
    "    print(\"Analysis for lookup tokens: \", lt)\n",
    "    show_token_split_graphs(time_taken[lt], token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64a56e-a855-4f17-9567-c5b88e14c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal for each\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = np.array(token_count)  \n",
    "r = np.array(list(range(len(z))))\n",
    "subsets = [r[z < 250], r[(z >= 250) & (z < 500)], r[(z >= 500) & (z < 1000)], r[z >= 1000]]\n",
    "ssnames  = [\"less than 250\", \"250 to 500\", \"500 to 1000\", \"over 1000\"]\n",
    "for ssname, subset in zip(ssnames, subsets):\n",
    "\n",
    "    sratio = []\n",
    "\n",
    "    for idx in subset:\n",
    "        # print(idx)\n",
    "        best_without_assistant = 1000000\n",
    "        best_with_assistant = 10000000\n",
    "    \n",
    "        best_lookup_without_assistant = 0\n",
    "        best_lookup_with_assistant = 0\n",
    "\n",
    "        for lt in lookup_tokens:\n",
    "            if time_taken[lt][\"without_assistant\"][idx] < best_without_assistant:\n",
    "                best_without_assistant = time_taken[lt][\"without_assistant\"][idx]\n",
    "                best_lookup_without_assistant = lt\n",
    "            if time_taken[lt][\"with_assistant\"][idx] < best_without_assistant:\n",
    "                best_with_assistant = time_taken[lt][\"with_assistant\"][idx]\n",
    "                best_lookup_with_assistant = lt\n",
    "\n",
    "    \n",
    "        sratio.append(best_with_assistant/best_without_assistant)\n",
    "        if sratio[-1] > 1:\n",
    "            print(\"Without assistant : \", best_without_assistant, \" lookup val: \",  best_lookup_without_assistant, \" With assistant: \", best_with_assistant,\" lookup val: \", best_lookup_with_assistant, \"<- greater\" if best_with_assistant/best_without_assistant > 1 else \"\")\n",
    "    plt.title(ssname)\n",
    "    plt.hist(sratio, bins=80)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1571f-9dea-4ee9-8ad8-659d843c63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(time_taken['with_assistant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef3a28-dbe6-43af-b0ae-bfe5af3c0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(time_taken['without_assistant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f2040-4f62-4030-83a2-06a637889756",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "assisted_sum = 0\n",
    "non_assisted_sum = 0\n",
    "for idx, (i, j) in enumerate(zip(time_taken['with_assistant'], time_taken['without_assistant'])):\n",
    "    ratios.append(i / j)\n",
    "    if i / j > 1:\n",
    "        print(outputs['with_assistant'][idx][0])\n",
    "        if not(outputs['with_assistant'][idx][0] == outputs['without_assistant'][idx][0]):\n",
    "            print(\"ERROR - with assistant and without assistant have different results. Without assistant:\\n\")\n",
    "            print(outputs[\"without_assistant\"][idx][0])\n",
    "        print(\"============\")\n",
    "    else:\n",
    "        assisted_sum += i\n",
    "        non_assisted_sum += j\n",
    "print(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4f8d5-e8b7-4eab-86fb-2c779fd5a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "count = 0\n",
    "for wa, woa in zip(outputs['with_assistant'], outputs['without_assistant']):\n",
    "    if not(wa[0] == woa[0]):\n",
    "        count += 1\n",
    "        print(\"Discrepancy: \")\n",
    "        print(\"\\n\".join(difflib.unified_diff(woa[0].splitlines(), wa[0].splitlines())))\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38371787-d786-44db-b054-b5a4861058b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assisted_sum, non_assisted_sum, assisted_sum/non_assisted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567176-474d-46f5-9491-66505503ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ratios, bins=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b708e7-7bb3-4c4f-92c4-71947a14a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_token_split_graphs(time_taken, token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07238b5-68fc-4063-abcd-c465438ccf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots\n",
    "plt.scatter(token_count, time_taken[80][\"with_assistant\"], color='blue', label='w/ assistant')\n",
    "plt.scatter(token_count, time_taken[80][\"without_assistant\"], color='red', label='no assistant')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('Code tokens')\n",
    "plt.ylabel('Time taken')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598b1e-8a2b-4aba-987c-898ee88ce477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
